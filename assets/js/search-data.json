{
  
    
        "post0": {
            "title": "Using ML to win FPL",
            "content": "Using ML to get better at FPL . Background . 2020 was a particularly difficult year for everyone, with so much suffering around the world &amp; life becoming still for everyone stuck in their homes due to lockdowns. As a sports lover, I found it particularly difficult to get used to a life without any live sport. Summers in India are particularly packed with excitement of home test series at the start of the year and then IPL for the months of April &amp; May. Without access to any live sport, I turned to OTT platforms and started watching documentaries around football teams like Man City, Leeds United, Tottenham Hotspur, Sunderland etc. I finished all of them in no time and though I’ve been a cricket fan most of my life &amp; watching football for me meant only international competitions like World Cup &amp; Euros, I started getting attracted to club football. . As the spread of Covid started reducing around the world, football was the first sport to break through the shackles &amp; premier league football resumed around the month of July. I got hooked to the sport and at the same time also got introduced to the world of Fantasy Football. I decided to give it a shot with new season beginning in September. Because I was still very new to football my knowledge around players capabilities in PL was still very limited, that led me to make several poor decisions. I also found myself getting biased around clubs that I liked &amp; filling squad with players from those clubs. This led to a poor showing after the first few gameweeks of FPL. I decided to put my skillset of data analysis to work and use it to compensate for my lack of understanding of PL and understand how different players compare against each other &amp; make transfer decisions backed by data. . Gathering Data . Following are the list of data sources used by me for the analysis . Vaastav FPL Github - This I think is the best available data repository for FPL containing historical data around players &amp; team performances in FPL going back several years and gets refreshed on a weekly basis. Data is available here | FPL API - I used FPL API to get info around upcoming fixtures &amp; status of players fitness for a gameweek. Details around how to access the API can be found here | FivethirtyEight scores prediction - I really like Nate Silver’s fivethirtyeight.com]which uses analytics &amp; data science to predict outcomes of several real life events. They also make predictions around expected score for games in PL as well. I use this dataset capture level of difficulty of a fixture &amp; scores prediction | Data Overview . Our base dataset for this analysis is the Github repository mentioned above. It contains various data points around a player’s performance in a particular match as shown below - . . We combine the base datasets with additional data points from the FPL API &amp; Fivethirtyeight datasets. Once we have the data ready, the first thing we do is to look at distribution of points scored by players during a game week. As the chart below suggests, huge majority of players score less than or equal to 2 points in a game week. Events providing returns like assists, goals &amp; clean sheets are quite rare. High number of players scoring zeros could be attributed to the fact that all premier league have big squads of around 25 players and only about 12-13 of them feature in a game. Since the distribution of points scored by players for more than 2 points is quite scattered, its quite difficult to actually predict the exact number of points scored by a player. . Let’s now look at how the proportion of blanking(&lt;=2 pts) and not blanking(2+points) looks by player position. Goalkeepers are most likely to blank based on the chart below, seems logical as well since only way GKs generally gain points is by maintaining clean sheets. For every other position, the proportions are quite similar. . After taking a look at the above data points, I decided that it will be a better idea to build a classification model rather than a regression model for this exercise. The objective of the model would be to identify players who are most likely to score 2+points in a week. Since most players score less than 2 points in a week, this would be an example of imbalanced classification problem. We’ll be building tree based classifiers for this problem. . Feature Engineering . Quality of predictions for any model is directly correlated to the quality of features being fed into the model. I found the overall quality of data to be very rich &amp; clean for this project, therefore lot of variables available in the raw datasets can directly be used as features. On top of that I added several features on my end to capture form &amp; opponent strengths into the model. After going through several iterations of model training on added features, here are the list of features I came up with - . Player Performance . Influence, Creativity &amp; Threat metrics | Rolling average of points scored during last four weeks | Position of a player | Player’s contribution to team’s total points | Rolling average of minutes played during last four weeks | Goals scored, assists &amp; clean sheets kept | Yellow &amp; Red Cards | Number of incoming transfers by FPL managers during a game week | . Team Performance . Diff. between team &amp; opponent’s position in the points table | Team’s form over last four weeks | Home or away fixture | Projected scores from fivethirtyeight | Total points scored by all players in the team | Penetrations into opponent’s box &amp; number of penetrations allowed | . Model Design . My workflow has been designed in such a way that it uses historical data for the entire season until the latest gameweek for training the model &amp; then makes prediction for the upcoming week. Predictions includes list of 11 players who are most likely to score more than 2 points during the gameweek. The project is deployed as a pipeline that runs every week and uses historical data till the latest game week and makes prediction for the upcoming game week. . Model Development . As seen in the data earlier majority of the players during a particular gameweek tend to blank(score less than or equal to 2 points for appearance). Since football is a low scoring sport &amp; events like goals etc. can be quite random, it is very hard to predict the exact number of points scored by a player during a game week. Therefore I turned this into a 2 class classification problem where i’m just trying to predict if a player would blank in a particular gameweek or score more than 2+ points. . I decided to train tree based ensemble models using Random Forests &amp; XGBoost and used a weighted average of the predictions used by both the models. The final output of model is a dataset with probability of each player not blanking during the upcoming game week. Here is the feature importance plot for the random forest model - . As we all know the 2020-21 season been a pretty weird one with teams going through runs of good &amp; bad forms. The model seems to recognize that as well &amp; the features with rolling average of last four weeks on points scored, ICT index etc. tend to have a lot of importance. This model in particular tends to answer the classic conundrum of FPL managers - form vs fixtures in favor of form. . This model had an overall accuracy of 78%, but given that this is an imbalanced classification problem and we’re interested in accurately identifying top 11 players who are likely to score, we’re more interested in the true positive rate of the model. . . . The above charts show us that predicted probability distribution is heavily skewed to the left and very few players have predicted probability over 0.5. The AUC for ROC curve is 0.75 and the True Positive Rate is 70%. This is not bad for an initial model but definitely room for improvement in future iterations. . Output . The final output of the model is a list of 11 players who are most likely to score 2+points during the upcoming game week. The workflow runs for every game week and the output predictions are available on the Streamlit website created here. . I also look at points scored in previous game weeks by my team vs the actual dream team for the week &amp; average score for the game week. So far we can say that the team predicted by the model is doing slightly better than the average human on points scored every game week. Looking at the predictions for the six game weeks the model has been running, model team scored 249 points vs sum of average score of 239 pts. . Hope is that model will continue to improve in its predictions through the season as it has access to higher volume of training data. . Code for the entire project can be found here . Next Steps &amp; Improvement . This entire project was taken up by me as a Christmas project to understand PL football better &amp; learn to use Streamlit for dashboarding. During the development of project I identified a few things that could be better - . Gather different metrics for attacking &amp; defensive footballers and train different models for each | Use Linear Programming to optimize the maximum points from the predicted team while ensuring that team budget doesn’t cross 100M pounds. I’ll be looking to work further on this &amp; hopefully improve the performance of this model. |",
            "url": "https://arpitsolanki.github.io/fastpagetest/2021/02/06/Using-ML-to-win-FPL.html",
            "relUrl": "/2021/02/06/Using-ML-to-win-FPL.html",
            "date": " • Feb 6, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "BCG - COVID-19 AI Challenge - Hack 2",
            "content": "Table of Contents - . Importing the raw datasets &amp; basic overview of datasets | Potential Areas of Analysis | Status of Covid Pandemic Across the world | BCG - Impact of Vaccination on Covid-19 | Spain vs Portugal | Ireland - Cork vs Derry | East Germany vs West Germany | . Importing the Raw Datasets . The Competiton provides the following files - . covid_data.csv- Contains information about the daily Covid related Confirmed Cases &amp; Deaths for all countries across the globe, sourced from Our World in Data and contains data till 20 June . bcg_world_atlas.csv - Contains the information about BCG policies across countries, start &amp; end date of BCG vaccination, BCG strain used etc. . germany_province_data.csv - Contains information Covid related cases across Germany. . In addition to these files I also came gathered some datasets from the internet based on the questions that I was looking to answer through my analysis- . bcg_pnas.csv - Dataset used for PNAS research containing details on BCG Coverage and minimum and maximum age groups vaccinated across European countries. . unicef_bcg_coverage.csv - Dataset obtained from UNICEF data warehouse providing stats on BCG coverage from 1980-1920 by country . ireland_data.csv - Contains information about the covid cases in Ireland across different counties . spain_age_group.csv - Contains information about the covid cases in Spain for different age groups, contains stats like Hospitalization, ICU &amp; Deaths across age groups. . portugal_age_group.csv - Contains information Covid deaths in Portugal across different age groups. Sourced from Wikipedia . covid_de.csv - Contains information Covid stats acorss different german provinces . stringency_index.csv - Contains Daily Stringency Index for countries, derived from strictness of lockdown &amp; social distancing measures enforced by countries . # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python # For example, here&#39;s several helpful packages to load import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) import glob from datetime import datetime import plotly.express as px import datetime from scipy import stats import re from plotly.subplots import make_subplots import plotly.graph_objects as go from sklearn.tree import DecisionTreeRegressor from sklearn.ensemble import RandomForestRegressor from sklearn.model_selection import train_test_split from sklearn.metrics import confusion_matrix # Input data files are available in the read-only &quot;../input/&quot; directory # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory import os # for dirname, _, filenames in os.walk(&#39;/kaggle/input/johnshopkinscovid/csse_covid_19_data/csse_covid_19_daily_reports/&#39;): # for filename in filenames: # print(os.path.join(dirname, filename)) # You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using &quot;Save &amp; Run All&quot; # You can also write temporary files to /kaggle/temp/, but they won&#39;t be saved outside of the current session covid_data=pd.read_csv(&#39;/kaggle/input/hackathon/task_2-owid_covid_data-21_June_2020.csv&#39;)#OWID Covid cases data till 20 June germany_province_data=pd.read_csv(&#39;/kaggle/input/hackathon/task_2-Gemany_per_state_stats_20June2020.csv&#39;,thousands=&#39;,&#39;)#Covid stats for Germany provinces #tb_data=pd.read_csv(&#39;/kaggle/input/hackathon/task_2-Tuberculosis_infection_estimates_for_2018.csv&#39;) bcg_world_atlas=pd.read_csv(&#39;/kaggle/input/hackathon/BCG_world_atlas_data-2020.csv&#39;)#BCG World Atlas dataset #pop_age_group=pd.read_csv(&#39;/kaggle/input/country-population-by-age-group/population-by-broad-age-group.csv&#39;) spain_age_group=pd.read_csv(&#39;/kaggle/input/portugal-spain-covid-cases-by-age-group/spain_cases_age_group.csv&#39;,thousands=&quot;,&quot;)#Covid cases by age group in Spain portugal_age_group=pd.read_csv(&#39;/kaggle/input/portugal/portugal_cases_age_group.csv&#39;)#Covid cases by age group in Portugal #ni_ireland_covid_data=pd.read_csv(&#39;/kaggle/input/ireland-covid-data/Covid_19_Northern_Ireland_Daily_Indicators.csv&#39;,parse_dates=True, dayfirst=True) ireland_data=pd.read_csv(&#39;/kaggle/input/ireland-covid-data/ireland_cso_data.csv&#39;)#Covid stats from Ireland counties bcg_pnas=pd.read_csv(&#39;../input/pnas-bcg-data/bcg_data_pnas_europe.csv&#39;)#BCG Coverage dataset for Europe from PNAS de_covid_data=pd.read_csv(&#39;/kaggle/input/covid19-tracking-germany/covid_de.csv&#39;)#Germany covid related stats unicef_bcg_coverage=pd.read_csv(&#39;../input/unicef-bcg-coverage/unicef_bcg_data.csv&#39;)#UNICEF BCG coverage related stats stringency_index=pd.read_csv(&#39;../input/owid-covid-stringency-index/covid-stringency-index.csv&#39;) . Potential Areas of Analysis . Given all the datasets that are available to us, we can look to answer the following questions - . How does Daily Covid Cases &amp; Deaths look across different countries in the World? | How does Covid Fatality Rate changes across countries? How does Fatality Rate vary with testing rates? | How are different variables like Population Density, Diabetes &amp; Cardiovascular disease prevalence, Income status, Number of hospital beds etc. related to Covid deaths in countries? | Is there a difference in Mortality Rate for countries based on Mandatory status of BCG Vaccine? | Which are the commonly used BCG vaccines across the world. How does Mortality rate vary across different BCG strains being used? | Is the Fatality Rate consistent across BCG mandatory countries? If its different what could explain the difference in Fatality Rates? | How does Covid rate vary across two neighboring counties in Ireland with different coverage for BCG Vaccine? | How does impact of Covid vary across Spain &amp; Portugal, neighboring countries with difference in BCG vaccine policy? | Does BCG vaccine provide Covid protection in individuals belonging to higher age groups? | How does impact of Covid vary across East &amp; West Germany provinces, both having different vaccination policies being implemented post 1950? | . Status of Covid-19 Pandemic Across the World . The OWID Covid Datset available to us provide daily covid stats across all countries in the world till 20 June. We will start out by performing some exploratory analysis on the dataset and trying to understand the spread of Covid-19 Pandemic and how different regions in the world have been impacted by it. . bcg_world_atlas = bcg_world_atlas.rename(columns={&#39;Contry Name (Mandatory field)&#39;: &#39;location&#39;, &#39;Is it mandatory for all children?&#39;: &#39;mandatory&#39;}) bcg_world_atlas_col=bcg_world_atlas[[&#39;location&#39;,&#39;mandatory&#39;,&#39;BCG Strain &#39;]] bcg_world_atlas_col[&#39;mandatory&#39;]=bcg_world_atlas_col[&#39;mandatory&#39;].fillna(&#39;Unknown&#39;) bcg_world_atlas_col bcg_world_atlas_col[&#39;BCG Strain &#39;]=bcg_world_atlas_col[&#39;BCG Strain &#39;].fillna(&#39;NA&#39;) bcg_world_atlas_col.loc[bcg_world_atlas_col[&#39;BCG Strain &#39;].str.contains(&#39;Danish|Staten|SSI&#39;,regex=True),&#39;BCG Strain &#39;]=&#39;Danish&#39; bcg_world_atlas_col.loc[bcg_world_atlas_col[&#39;BCG Strain &#39;].str.contains(&#39;Japan|Tokyo&#39;,regex=True),&#39;BCG Strain &#39;]=&#39;Japan&#39; bcg_world_atlas_col.loc[bcg_world_atlas_col[&#39;BCG Strain &#39;].str.contains(&#39;Pasteur&#39;,regex=True),&#39;BCG Strain &#39;]=&#39;Pasteur&#39; . /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy This is separate from the ipykernel package so we can avoid doing imports until /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy /opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy self._setitem_with_indexer(indexer, value) /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy import sys /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy if __name__ == &#39;__main__&#39;: . stringency_index[&#39;Date&#39;]= pd.to_datetime(stringency_index[&#39;Date&#39;]) stringency_index.columns=[&#39;location&#39;,&#39;code&#39;,&#39;Date&#39;,&#39;stringency_index&#39;] covid_data[&#39;date&#39;]=pd.to_datetime(covid_data[&#39;date&#39;]).dt.date covid_data[&#39;Fatality_Rate&#39;]=covid_data[&#39;total_deaths&#39;]/covid_data[&#39;total_cases&#39;] covid_data_no_world=covid_data.loc[covid_data[&#39;iso_code&#39;]!=&#39;OWID_WRL&#39;] fig = px.line(covid_data_no_world, x=&quot;date&quot;, y=&quot;total_cases&quot;, color=&#39;location&#39;) fig.update_layout(title_text=&#39;Total Covid confirmed Cases &#39;,xaxis_title_text=&#39;date&#39;,yaxis_title_text=&#39;Total Cases&#39;,width=800,height=400) fig.show() fig = px.line(covid_data_no_world, x=&quot;date&quot;, y=&quot;total_deaths&quot;, color=&#39;location&#39;) fig.update_layout(title_text=&#39;Total Covid Deaths&#39;,xaxis_title_text=&#39;date&#39;,yaxis_title_text=&#39;Daily New Cases&#39;,width=800,height=400) fig.show() . The above line chart is from start of the year till 20 June. Two countries - US &amp; Brazil clearly stand out above everyone else regarding the growth in the number of cases. US, Brazil as well as few European countries like UK, France &amp; Spain have very high death counts. Double clicking on the country names above allows us to have a look at Covid Cases and Deaths for individual countries . covid_data_no_world=covid_data.loc[covid_data[&#39;iso_code&#39;]!=&#39;OWID_WRL&#39;] fig = px.choropleth(covid_data_no_world, locations=&quot;iso_code&quot;, color=&quot;total_deaths&quot;, # Death is a column of gapminder hover_name=&quot;location&quot;, # column to add to hover information color_continuous_scale=px.colors.sequential.Plasma) fig.update_layout(title=&#39;Covid Deaths across Countries&#39;) fig.show() . Following things can be observed from the chart above - . North America - US has the highest number of deaths across the world. Apart from US, Mexico seems to have been hit hard as well from Covid, Canada seems to have lower number of deaths compared to US &amp; Mexico | South America Brazil has been impacted worse than any other country in South America . | Europe - There is a big difference in number of deaths across Eastern &amp; Western European countries. Most of the Western European countries seem to have very high number of deaths, with the exception of Portugal &amp; Ireland. Among the Eastern European countries, Russia has high number of deaths . | Asia - India &amp; Iran stand out as the countries with highest number of deaths. China - the epicentre of Covid, seems to have fallen behind other countries in Asia . | Africa - The entire continent seems to be fairly consistent in terms of low deaths being reported, it could potentially be due to deaths not being tracked due to low testing numbers. It could also be due to lesser travel to African countries from initial hubs of Covid . | . covid_data_no_world_jun=covid_data_no_world.loc[covid_data_no_world[&#39;date&#39;]==datetime.date(year=2020,month=6,day=20)] covid_data_no_world_2000=covid_data_no_world_jun.loc[covid_data_no_world[&#39;total_cases&#39;]&gt;=10000] fig = px.scatter(covid_data_no_world_2000, x=&quot;total_cases_per_million&quot;, y=&quot;Fatality_Rate&quot;,log_x=True, color=&quot;continent&quot;,hover_name=&quot;location&quot;,text=&quot;location&quot;) fig.update_traces(textposition=&#39;top center&#39;) fig.update_layout( height=600, title_text=&#39;Total Cases vs Fatality Rate&#39;, yaxis_tickformat = &#39;%&#39; ) fig.show() . tests=covid_data_no_world_2000.loc[covid_data_no_world_2000[&#39;total_tests&#39;].notna()] fig = px.scatter(tests, x=&quot;total_cases_per_million&quot;, y=&quot;Fatality_Rate&quot;,log_x=True,size=&#39;total_tests_per_thousand&#39;, color=&quot;continent&quot;,hover_name=&quot;location&quot;,text=&quot;location&quot;,size_max=60) fig.update_traces(textposition=&#39;top center&#39;) fig.update_layout( height=600, title_text=&#39;Total Cases vs Fatality Rate - Bubble size indicates tests_per_thousand&#39;, yaxis_tickformat = &#39;%&#39; ) fig.show() . Following things emerge from above scatter plots - . Big number of countries seem to have Fatality Rate between 0-5% | European countries of Belgium, UK, France, Netherlands &amp; Italy stand out of the pack when it comes to Fatality Rate. Belgium has a Fatality Rate of 15% - which means that out of every 100 Covid patients - 15 end up dying, which is much higher than rest of the world | Mexico has the highest Fatality Rate in North America i.e. more than 10%, which is much higher than death rate for United States | Ecuador has the highest Fatality Rate in South America, more than 10% | Middle East countries like Qatar, Bahrain &amp; Saudi Arabia have the highest tests conducted per million | Testing stats are available only for Nigeria &amp; South Africa in the African continent. For South America, these numbers are only available for Peru, Chile &amp; Colombia | . There seems to be a trend emerging that high income countries also tend to have higher number of Covid related deaths compared to lower income countries. Lower Income countries like Nigeria, India, Pakistan, Peru etc. have lower number of tests as well lower Fatality rates being reported . Let us now look at correlation between covid deaths and different country level variables available in the OWID dataset to understand which factors have a high correlation with covid deaths. . import seaborn as sns covid_data_sel=covid_data_no_world_jun[[&#39;date&#39;,&#39;total_cases&#39;,&#39;total_deaths&#39;,&#39;Fatality_Rate&#39;,&#39;total_cases_per_million&#39;,&#39;gdp_per_capita&#39;,&#39;diabetes_prevalence&#39;,&#39;total_tests&#39;,&#39;total_tests_per_thousand&#39;,&#39;population_density&#39;,&#39;population&#39;,&#39;median_age&#39;,&#39;aged_65_older&#39;,&#39;hospital_beds_per_thousand&#39;,&#39;total_tests&#39;,&#39;total_tests_per_thousand&#39;,&#39;stringency_index&#39;,&#39;population_density&#39;]] covid_data_sel[&#39;total_tests&#39;]=covid_data_sel[&#39;total_tests&#39;].fillna(0) #covid_data_sel[&#39;Test Positivity Rate&#39;]=covid_data_sel[&#39;total_cases&#39;]/covid_data_sel[&#39;total_tests&#39;] covid_data_sel_cor=covid_data_sel.fillna(covid_data_sel.mean()) corr = covid_data_sel_cor.corr(method=&#39;spearman&#39;) corr ax = sns.heatmap(corr,linewidths=.5,cmap=&#39;YlGnBu&#39;) . /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy /opt/conda/lib/python3.7/site-packages/pandas/core/generic.py:6245: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy /opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:4153: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy . Since the trend for Covid cases in most countries is non-linear, it may not make sense to look at Linear Pearson&#39;s Correlation. Instead we took a look at the Spearman&#39;s correlation and looked at correlation between Covid related cases and other variables available in the base dataset. There are not too many strong correlation relationsips emerge from this analysis. Following are some of the only strong correlation variables I was able to obseve - . gdp_per_capita also had a strong correation with total_tests_per_thousand, indicating that maybe only countries with huge resources are able to test extensively. Poorer countries may not be able to test a lot and could be underreporting the total number of cases | gdp_per_capita also had a strong correlation with median_age, meaning that these countries also had significantly older population. My assumption is that most of these are European countries with older population | median_age is strongly correlated with hospital_beds_per_thousand, showing that countries with older population also have greater healthcare resources at their disposal | Fatality_Rate isn&#39;t strongly correlated with any of the other variables available in the dataset | . Let us look at how Fatality Rates for Covid varies across different countries. . covid_data_no_world_jun_rel=covid_data_no_world_jun.loc[covid_data_no_world_jun[&#39;total_cases&#39;]&gt;1000] covid_data_no_world_jun_rel_sort=covid_data_no_world_jun_rel.sort_values(&#39;Fatality_Rate&#39;,ascending=False) max_fat=covid_data_no_world_jun_rel_sort.head(5) min_fat=covid_data_no_world_jun_rel_sort.tail(5) max_fat fig = make_subplots(rows=1, cols=2,subplot_titles=(&quot;Maximum Fatality Rate&quot;, &quot;Minimum Fatality Rate&quot;)) fig.add_trace( go.Bar(x=max_fat[&#39;location&#39;], y=max_fat[&#39;Fatality_Rate&#39;],name=&#39;Countries&#39;), row=1, col=1 ) fig.add_trace( go.Bar(x=min_fat[&#39;location&#39;], y=min_fat[&#39;Fatality_Rate&#39;],name=&#39;Countries&#39;), row=1, col=2 ) fig.update_layout(height=400, width=800, title_text=&quot;Countries with highest &amp; lowest Fatality Rate&quot;,yaxis_tickformat = &#39;%&#39;) fig.show() . In the chart above we have plotted top 5 countries with the highest &amp; lowest fatality rates due to Covid. Interestingly the countries with highest fatality rate all belong to Europe and the countries with lowest fatality rate all belong to Asia. In the upcoming steps within the notebook it would also be interesting to look at the status of BCG vaccine administration in these countries. Let&#39;s also look at daily progression of cases in these countries through a line chart. . covid_data_no_world fig = go.Figure() country_list=[&#39;France&#39;,&#39;Belgium&#39;,&#39;Italy&#39;,&#39;United Kingdom&#39;,&#39;Hungary&#39;] for i in range(5): fig.add_trace( go.Scatter(x=covid_data_no_world[covid_data_no_world[&#39;location&#39;]==country_list[i]][&#39;date&#39;], y=covid_data_no_world[covid_data_no_world[&#39;location&#39;]==country_list[i]][&#39;Fatality_Rate&#39;],name=country_list[i]), ) fig.update_layout(title=&#39;Countries with Highest Fatality Rates&#39;,yaxis_tickformat = &#39;%&#39;,height=400) fig.show() fig1=go.Figure() country_list=[&#39;Uzbekistan&#39;,&#39;Bahrain&#39;,&#39;Nepal&#39;,&#39;Qatar&#39;,&#39;Singapore&#39;] for i in range(5): fig1.add_trace( go.Scatter(x=covid_data_no_world[covid_data_no_world[&#39;location&#39;]==country_list[i]][&#39;date&#39;], y=covid_data_no_world[covid_data_no_world[&#39;location&#39;]==country_list[i]][&#39;Fatality_Rate&#39;],name=country_list[i],mode=&#39;lines&#39;), ) fig1.update_layout(title=&#39;Countries with Lowest Fatality Rates&#39;,yaxis_tickformat = &#39;%&#39;,height=400) fig1.show() . For the countries with the highest fatality rates, Italy saw the spike in caes first, around 1st week of April reportedly due to incoming travelers from China. The other countries witnessed start of spike around mid-April. The Fatality rate continued to increase in May and eventually settled around 1st week of June. All these countries saw Fatality Rates well in excess of 10%. . For the countries with lowest fatality rates, even at the spikes the fatality rate was around 1%, much lower than the countries mentioned earlier. These countries saw a short spike post which the fatality rate went down steeply to less than 1%. Most of these countries are small with very small population numbers. . Impact of BCG Vaccination on Covid-19 . After having gained some initial understanding of the spread of Covid-19 pandemic across the globe, let&#39;s start taking a deeper look at the BCG World Atlas dataset and begin understanding the prevalence of BCG vaccine across the globe and whether it has any effect on developing immunity against Covid-19. . . As shown in the image above - most of countries in Africa, South America &amp; Asia have current BCG vaccination policy for all their citizens. Majority of European countries had a national vaccination policy but since then have moved away from it - either due to unavailablity of vaccine due to global shortage or low incidence rates of TB . unicef_bcg_data=unicef_bcg_coverage[[&#39;Geographic area&#39;,&#39;TIME_PERIOD&#39;,&#39;OBS_VALUE&#39;]] unicef_bcg_data.columns=[&#39;location&#39;,&#39;year&#39;,&#39;% BCG Coverage&#39;] country_continent=covid_data[[&#39;location&#39;,&#39;continent&#39;]].drop_duplicates(keep=&#39;first&#39;) unicef_bcg_data_continent=pd.merge(unicef_bcg_data,country_continent,how=&#39;inner&#39;) #unicef_bcg_data_continent unicef_bcg_data_2015=unicef_bcg_data_continent.loc[unicef_bcg_data_continent[&#39;year&#39;]==2015] #unicef_bcg_data_2015 fig = px.histogram(unicef_bcg_data_2015, x=&quot;% BCG Coverage&quot;,title=&#39;Distribution of BCG coverage in 2015 across Countries&#39;,height=400) fig.show() unicef_bcg_data_2015[unicef_bcg_data_2015[&#39;% BCG Coverage&#39;]&lt;=60] unicef_bcg_data_continent_gp=unicef_bcg_data_continent.groupby([&#39;continent&#39;,&#39;year&#39;]).agg({&#39;% BCG Coverage&#39;:&#39;median&#39;}).reset_index() fig = px.line(unicef_bcg_data_continent_gp, x=&quot;year&quot;, y=&quot;% BCG Coverage&quot;, title=&#39;BCG Coverage trends by Continent&#39;,color=&#39;continent&#39;) fig.show() . One of the things we need to look at is the coverage rate for BCG vaccines - the number of newborn infants who are administered this vaccine. I managed to find a dataset on the UNICEF website which provided stats on % BCG Coverage by country from the year 1980. It seems like by 2015 majority of the countries had more than 90% coverage regarding BCG vaccine, which means that countries which had mandeated the use of BCG vaccine were able to implement their policies effectively. There were few outliers as well, countries with vaccination coverage rate less than 60%, these countries were typically in Europe, vaccine shortages could have been one reason for the coverage to have dropped. . I also looked at the trends on BCG coverage across continents by looking at the median values for BCG coverage. These values were pretty low in the early 1980s all across the world except for Europe, however it did pick up by 1990s and has stayed up ever since. . country_continent=covid_data[[&#39;location&#39;,&#39;continent&#39;]] country_continent=country_continent.drop_duplicates(subset=[&#39;location&#39;], keep=&#39;first&#39;) bcg_world_atlas[&#39;BCG Strain &#39;]=bcg_world_atlas[&#39;BCG Strain &#39;].fillna(&#39;NA&#39;) bcg_world_atlas_country=pd.merge(bcg_world_atlas,country_continent,how=&quot;left&quot;,left_on=&#39;location&#39;,right_on=&#39;location&#39;) #bcg_world_atlas_country[&#39;BCG Strain &#39;].str.contains(&#39;Danish&#39;) bcg_world_atlas_country.loc[bcg_world_atlas_country[&#39;BCG Strain &#39;].str.contains(&#39;Danish|Staten|SSI&#39;,regex=True),&#39;BCG Strain &#39;]=&#39;Danish&#39; bcg_world_atlas_country.loc[bcg_world_atlas_country[&#39;BCG Strain &#39;].str.contains(&#39;Japan|Tokyo&#39;,regex=True),&#39;BCG Strain &#39;]=&#39;Japan&#39; bcg_world_atlas_country.loc[bcg_world_atlas_country[&#39;BCG Strain &#39;].str.contains(&#39;Pasteur&#39;,regex=True),&#39;BCG Strain &#39;]=&#39;Pasteur&#39; # # #bcg_world_atlas_country.loc[gp[&#39;BCG Strain&#39;].str.contains(&#39;Danish&#39;|&#39;Staten&#39;),&#39;BCG Strain&#39;]=&#39;Danish&#39; gp=bcg_world_atlas_country.groupby([&#39;BCG Strain &#39;,&#39;continent&#39;]).agg({&#39;location&#39;:&#39;nunique&#39;}).reset_index(drop=False) gp.columns=[&#39;BCG Strain&#39;,&#39;continent&#39;,&#39;location&#39;] gp.sort_values(&#39;location&#39;,ascending=False,inplace=True) gp = gp[gp[&#39;BCG Strain&#39;]!=&#39;NA&#39;] k=gp.pivot(index=&#39;BCG Strain&#39;, columns=&#39;continent&#39;, values=&#39;location&#39;).reset_index() k.fillna(0, inplace=True) k[&#39;total&#39;]=k.iloc[:,1:6].sum(axis=1) k.sort_values(&#39;total&#39;,ascending=False).head(5) . continent BCG Strain Africa Asia Europe North America Oceania South America total . 9 Danish | 7.0 | 4.0 | 16.0 | 2.0 | 1.0 | 2.0 | 30.0 | . 18 Japan | 1.0 | 7.0 | 3.0 | 1.0 | 0.0 | 0.0 | 12.0 | . 23 Pasteur | 2.0 | 2.0 | 3.0 | 1.0 | 0.0 | 2.0 | 8.0 | . 27 Serum Institute of India | 1.0 | 2.0 | 0.0 | 0.0 | 0.0 | 0.0 | 3.0 | . 22 Moscow | 0.0 | 0.0 | 2.0 | 0.0 | 0.0 | 0.0 | 2.0 | . There are a lot of different strains being used across the globe - within the dataset sometimes the same strain is mentioned under different names, so we have aggregated all of them under one name. Danish strain is the most common BCG strain used across the globe. As many as 16 countries in Europe used Danish strain, it was also used in all the other countries. Japanese, Pasteur, Serum Institute of India and Moscow are some of the other strains. . We will now be looking at fatality rates in countries based on the status of BCG vaccine administration within the country. As the BCG world atlas data is incomplete, we will classify countries into three groups . BCG Mandatory Yes - Countries where BCG vaccination is mandatory for all | BCG Mandatory No - Countries where BCG vaccination is not mandatory and is only being given to certian high risk populations | BCG Status Unknown - Countries for which data on mandatory status is not available in BCG World Atlas . We will now be diving deeper into the BCG Mandatory Yes and BCG Mandatory No groups and looking at fatality rates within these countries . | . bcg_world_atlas = bcg_world_atlas.rename(columns={&#39;Contry Name (Mandatory field)&#39;: &#39;location&#39;, &#39;Is it mandatory for all children?&#39;: &#39;mandatory&#39;}) bcg_world_atlas_col=bcg_world_atlas[[&#39;location&#39;,&#39;mandatory&#39;,&#39;BCG Strain &#39;]] bcg_world_atlas_col[&#39;mandatory&#39;]=bcg_world_atlas_col[&#39;mandatory&#39;].fillna(&#39;Unknown&#39;) bcg_world_atlas_col bcg_world_atlas_col[&#39;BCG Strain &#39;]=bcg_world_atlas_col[&#39;BCG Strain &#39;].fillna(&#39;NA&#39;) bcg_world_atlas_col.loc[bcg_world_atlas_col[&#39;BCG Strain &#39;].str.contains(&#39;Danish|Staten|SSI&#39;,regex=True),&#39;BCG Strain &#39;]=&#39;Danish&#39; bcg_world_atlas_col.loc[bcg_world_atlas_col[&#39;BCG Strain &#39;].str.contains(&#39;Japan|Tokyo&#39;,regex=True),&#39;BCG Strain &#39;]=&#39;Japan&#39; bcg_world_atlas_col.loc[bcg_world_atlas_col[&#39;BCG Strain &#39;].str.contains(&#39;Pasteur&#39;,regex=True),&#39;BCG Strain &#39;]=&#39;Pasteur&#39; . /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy /opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy . #bcg_world_atlas_col.loc[bcg_world_atlas_col[&#39;mandatory&#39;]==&#39;Unknown&#39;,&#39;mandatory&#39;]=&#39;Z&#39; bcg_world_atlas_col=bcg_world_atlas_col.sort_values(&#39;mandatory&#39;,ascending=True) bcg_world_atlas_col_unique=bcg_world_atlas_col.drop_duplicates(subset=[&#39;location&#39;],keep=&#39;first&#39;) #bcg_world_atlas_col.loc[bcg_world_atlas_col[&#39;mandatory&#39;]==&#39;Z&#39;,&#39;mandatory&#39;]=&#39;Unknown&#39; covid_data_no_world.loc[covid_data_no_world[&#39;location&#39;]==&#39;United States&#39;,&#39;location&#39;]=&#39;United States of America&#39; bcg_world_atlas_col_unique.loc[bcg_world_atlas_col_unique[&#39;location&#39;]==&#39;France&#39;,&#39;mandatory&#39;]=&#39;no&#39; covid_data_no_world_bcg=pd.merge(left=covid_data_no_world,right=bcg_world_atlas_col_unique,how=&#39;inner&#39;) covid_data_no_world_bcg.groupby([&#39;mandatory&#39;]).agg({&#39;location&#39;:&#39;nunique&#39;}).reset_index() . /opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy . mandatory location . 0 Unknown | 46 | . 1 no | 26 | . 2 yes | 103 | . covid_data_no_world_bcg[covid_data_no_world_bcg[&#39;mandatory&#39;]==&#39;Unknown&#39;][&#39;location&#39;].unique() #covid_data_no_world_bcg.location.unique() . array([&#39;Andorra&#39;, &#39;Anguilla&#39;, &#39;Antigua and Barbuda&#39;, &#39;Argentina&#39;, &#39;Aruba&#39;, &#39;Azerbaijan&#39;, &#39;Bahrain&#39;, &#39;Bermuda&#39;, &#39;Brazil&#39;, &#39;Cayman Islands&#39;, &#39;Curacao&#39;, &#39;Cyprus&#39;, &#39;Ecuador&#39;, &#39;Equatorial Guinea&#39;, &#39;Eritrea&#39;, &#39;Estonia&#39;, &#39;Ethiopia&#39;, &#39;Fiji&#39;, &#39;French Polynesia&#39;, &#39;Gabon&#39;, &#39;Georgia&#39;, &#39;Ghana&#39;, &#39;Gibraltar&#39;, &#39;Grenada&#39;, &#39;Guam&#39;, &#39;Iceland&#39;, &#39;Isle of Man&#39;, &#39;Kosovo&#39;, &#39;Lebanon&#39;, &#39;Liechtenstein&#39;, &#39;Luxembourg&#39;, &#39;Monaco&#39;, &#39;Montserrat&#39;, &#39;New Caledonia&#39;, &#39;Northern Mariana Islands&#39;, &#39;Puerto Rico&#39;, &#39;San Marino&#39;, &#39;Somalia&#39;, &#39;South Africa&#39;, &#39;South Sudan&#39;, &#39;Suriname&#39;, &#39;Trinidad and Tobago&#39;, &#39;Venezuela&#39;, &#39;Vietnam&#39;, &#39;Zambia&#39;, &#39;Zimbabwe&#39;], dtype=object) . k=covid_data_no_world_bcg.groupby([&#39;date&#39;,&#39;mandatory&#39;]).agg({&#39;total_deaths&#39;:[&#39;sum&#39;],&#39;total_cases&#39;:[&#39;sum&#39;]}).reset_index() k.columns=[&#39;date&#39;,&#39;mandatory&#39;,&#39;total_deaths&#39;,&#39;total_cases&#39;] k[&#39;Fatality_Rate&#39;]=k[&#39;total_deaths&#39;]/k[&#39;total_cases&#39;] fig = px.line(k, x=&quot;date&quot;, y=&quot;Fatality_Rate&quot;, color=&#39;mandatory&#39;) fig.update_layout(title_text=&#39;Comparison of Fatality Rate by BCG Vaccine Status&#39;,yaxis_tickformat = &#39;%&#39;) fig.show() yes_sample=covid_data_no_world_bcg.loc[(covid_data_no_world_bcg[&#39;mandatory&#39;].isin([&#39;yes&#39;]))&amp;(covid_data_no_world_bcg[&#39;date&#39;]==datetime.date(year=2020,month=6,day=20))] no_sample=covid_data_no_world_bcg.loc[(covid_data_no_world_bcg[&#39;mandatory&#39;].isin([&#39;no&#39;]))&amp;(covid_data_no_world_bcg[&#39;date&#39;]==datetime.date(year=2020,month=6,day=20))] yes_sample=yes_sample[&#39;Fatality_Rate&#39;] no_sample=no_sample[&#39;Fatality_Rate&#39;] #yes_sample stats.ttest_ind(yes_sample,no_sample) . Ttest_indResult(statistic=-4.773658018161817, pvalue=4.929853987010903e-06) . The above chart shows the difference in fatality rates between different BCG countries over time. Its interesting that there is a big difference between countries based on their BCG status. Around June 20, non-BCG Mandatory countries had a combined Fatality Rate of 7% compared to the Fatality Rate of 3% for countries where BCG is Mandatory. However lot of countries where BCG isn&#39;t mandatory are in Europe &amp; North America, countries with low prevalence for TB and also having reported high number of fatalities. . Also the Fatality Rate in BCG Mandatory countries remained flat from the start, there was no huge spike being observed, however for non-BCG Mandatory countries there was a continous rise in Fatality Rate before it stablized around June. . We also performed a t-test to see if the difference between Fatality Rates between BCG mandatory countries was due to chance. P Value turned out to be &lt;0.05, indicating the statistical significance of the result. However we could not be sure if the underlying population of the two groups is similar, given the difference in demographics, income, testing etc. . It would not be wise to just look at the above line chart and make a conclusion that lower Fatality Rate in BCG mandatory countries is due to the vaccine. There could be other demographic, social &amp; economic factors that could be responsible for low spread, and it could also be the case that these countries are under-reporting covid cases and deaths due to lack of testing infrastructure. . covid_data_no_world_bcg_1000=covid_data_no_world_bcg.loc[(covid_data_no_world_bcg[&#39;total_cases&#39;]&gt;=1000)&amp;(covid_data_no_world_bcg[&#39;date&#39;]==datetime.date(year=2020,month=6,day=20))] bcg_yes_no_comp=covid_data_no_world_bcg_1000.groupby(&#39;mandatory&#39;).agg({&#39;population&#39;:&#39;median&#39;,&#39;total_cases&#39;:&#39;median&#39;,&#39;total_cases_per_million&#39;:&#39;median&#39;,&#39;total_tests&#39;:&#39;median&#39;,&#39;total_tests_per_thousand&#39;:&#39;median&#39;,&#39;extreme_poverty&#39;:&#39;mean&#39;,&#39;diabetes_prevalence&#39;:&#39;mean&#39;,&#39;cvd_death_rate&#39;:&#39;median&#39;,&#39;hospital_beds_per_thousand&#39;:&#39;mean&#39;,&#39;Fatality_Rate&#39;:&#39;median&#39;,&#39;aged_65_older&#39;:&#39;median&#39;,&#39;life_expectancy&#39;:&#39;mean&#39;,&#39;female_smokers&#39;:&#39;mean&#39;,&#39;male_smokers&#39;:&#39;mean&#39;}) bcg_yes_no_comp . population total_cases total_cases_per_million total_tests total_tests_per_thousand extreme_poverty diabetes_prevalence cvd_death_rate hospital_beds_per_thousand Fatality_Rate aged_65_older life_expectancy female_smokers male_smokers . mandatory . Unknown 10666452 | 4084.5 | 1151.6960 | 307256.0 | 153.8975 | 10.633333 | 7.472632 | 202.8120 | 2.707647 | 0.020053 | 6.0180 | 71.266842 | 10.223077 | 25.638462 | . no 10566019 | 18762.0 | 2023.6715 | 424426.5 | 54.0630 | 4.460000 | 6.878750 | 128.3195 | 3.666478 | 0.051027 | 18.5440 | 79.944583 | 20.456522 | 27.139130 | . yes 12475705 | 11392.5 | 639.0250 | 553737.0 | 21.0040 | 10.298077 | 7.968824 | 260.8695 | 2.806065 | 0.026144 | 6.3355 | 72.674853 | 8.469091 | 35.805660 | . We now look at some of the economic and demographics related variables to understand differences between BCG &amp; non-BCG countries. We only included at countries with more than 1000 cases for this analysis. Following are the observations - . Non-BCG countries had twice as many total_tests_per_thousand compared to BCG countries | BCG countries had twice the value of extreme_poverty compared to non-BCG countries | BCG countries had twice the value of cvd_death_rate(Cardiovascular Death Rate) showing higher percentage of citizens in these countries were vulnerable to heart diseases | Non-BCG countries had higher hospital_beds_per_thousand | Non-BCG countries had thrice the value of aged_65_older, showing that these countries had higher percentage of vulnerable population | . These pointers clearly show that its not wise to make the claim that BCG Mandatory countries have lower Fatality Rates solely due to the vaccine, there are other factors at work here such as lower tesing, lower percentage of older population etc. which could be the reason for lower number of deaths here. A thorough hypothesis testing and regression analysis would allow us to determine the contribution of BCG vaccine status in the Fatality rate for the country. . tests=covid_data_no_world_bcg_1000.loc[covid_data_no_world_bcg_1000[&#39;total_tests&#39;].notna()] tests=tests.loc[covid_data_no_world_bcg_1000[&#39;mandatory&#39;].notna()] fig = px.scatter(tests, x=&quot;total_cases_per_million&quot;, y=&quot;Fatality_Rate&quot;,log_x=True,size=&#39;total_tests_per_thousand&#39;, color=&quot;mandatory&quot;,hover_name=&quot;location&quot;,text=&quot;location&quot;,size_max=60) fig.update_traces(textposition=&#39;top center&#39;) fig.update_layout( height=600, title_text=&#39;BCG Status - Total Cases vs Fatality Rate - Bubble Size indicates total_tests_per_thousand&#39;, yaxis_tickformat = &#39;%&#39; ) fig.show() . We also look at spread of cases within individual countries through total_cases_per_million as well as fatality_rate broken out by BCG status for the countries- . Non-BCG mandatory countries like Canada, Greece, Switzerland, France etc have a higher fatality rate than other countries | total_tests_per_million seems to be even across BCG Mandatory &amp; non-mandatory countries with some BCG mandatory countries having higher tests. This includes Bahrain &amp; Qatar in the Middle East | total_cases_per_million also seems to be even across BCG Mandatory &amp; non-mandatory countries | . fig = px.violin(covid_data_no_world_bcg_1000, x=&#39;mandatory&#39;, color=&#39;mandatory&#39;,y=&#39;Fatality_Rate&#39;,box=True) fig.update_layout(template=&#39;seaborn&#39;,title=&#39;Distribution of Fatality Rate for Countries divided by BCG Status&#39;,legend_title_text=&#39;State&#39;,yaxis_tickformat = &#39;%&#39;) fig.show() . The Violin plot above allows us to look at the distribution of individual countries Fatality Rate based on different categories of BCG vaccine status. This data provides a snapshot of 20 June. The median fatality rate for BCG mandatory countries is 3% compared to 5% for non-BCG mandatory countries. We see that even within BCG mandatory countries there are countries with higher than 10% Fatality Rate, we would need to dive deeper into data for those countries to understand what were the factors for high Fatality Rate. . bcg_yes=covid_data_no_world_bcg_1000.loc[covid_data_no_world_bcg_1000[&#39;mandatory&#39;]==&#39;yes&#39;] fig = px.violin(bcg_yes, x=&#39;BCG Strain &#39;,y=&#39;Fatality_Rate&#39;,box=True) fig.update_layout(template=&#39;seaborn&#39;,title=&#39;Distribution of Fatality Rate for Countries divided by BCG Strain&#39;,legend_title_text=&#39;State&#39;,yaxis_tickformat = &#39;%&#39;) fig.show() . We also looked at Fatality Rates for different strains of BCG vaccine to understand the efficacy of these vaccines. To be able to provide a reliable estimate of Fatality Rate against these strains, we only included the countries where BCG vaccine was mandatory to only include countries where the protection offered from these vaccines would be complete. At an initial glance, there is not much difference observed between different strains, however the Serum Institute of India &amp; Japan strains seem to have lower Fatality rates of around 2%, which is ~1-2% lower than other strains. . bcg_pnas_col=bcg_pnas[[&#39;Country&#39;,&#39;Age oldest vaccinated&#39;,&#39;BCG Coverage&#39;]] bcg_merge=pd.merge(bcg_pnas_col,covid_data_no_world_bcg_1000,left_on=&#39;Country&#39;,right_on=&#39;location&#39;,how=&#39;inner&#39;) fig = px.scatter(bcg_merge, x=&quot;Age oldest vaccinated&quot;, y=&quot;Fatality_Rate&quot;, trendline=&quot;ols&quot;,hover_name=&quot;location&quot;,text=&quot;location&quot;) fig.update_traces(textposition=&#39;top center&#39;) fig.update_layout( height=300, title_text=&#39;Age Oldest Vaccinated vs Fatality Rate&#39;, yaxis_tickformat = &#39;%&#39; ) fig.show() results = px.get_trendline_results(fig) results.px_fit_results.iloc[0].summary() . OLS Regression Results Dep. Variable: y | R-squared: 0.251 | . Model: OLS | Adj. R-squared: 0.220 | . Method: Least Squares | F-statistic: 8.038 | . Date: Fri, 24 Jul 2020 | Prob (F-statistic): 0.00915 | . Time: 17:07:16 | Log-Likelihood: 51.518 | . No. Observations: 26 | AIC: -99.04 | . Df Residuals: 24 | BIC: -96.52 | . Df Model: 1 | | . Covariance Type: nonrobust | | . | coef std err t P&gt;|t| [0.025 0.975] . const 0.1133 | 0.021 | 5.422 | 0.000 | 0.070 | 0.156 | . x1 -0.0009 | 0.000 | -2.835 | 0.009 | -0.002 | -0.000 | . Omnibus: 2.627 | Durbin-Watson: 2.457 | . Prob(Omnibus): 0.269 | Jarque-Bera (JB): 1.243 | . Skew: 0.429 | Prob(JB): 0.537 | . Kurtosis: 3.641 | Cond. No. 207. | . Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified. We also looked at the PNAS dataset available here - https://www.pnas.org/content/early/2020/07/07/2008410117 . It provides the age of oldest vaccinated person in a country based on the BCG vaccine start date. This data is available for European countries only. We will be looking to see if greater length of vaccination provides greater protection against Covid. . The R Squared was low at 0.25, however it could be due to how data is distributed as well. Few data transformations may result to this number being higher | Countries in Europe that do not have any BCG vaccination policy have the highest Fatality Rate - Belgium &amp; Netherlands | Majority of the East Europe countries lie in the 60-80 bracket and enjoy lower fatality rates compared to the Western Europe countries | . This piece of analysis might be a bit incomplete as we haven&#39;t looekd at youngest vaccinated, as some countries like Sweden started vaccination early in 1945 but stopped it around 1975. I will be looking at this a bit deeper in future versions of the notebook. . bcg_yes=covid_data_no_world_bcg.loc[covid_data_no_world_bcg[&#39;mandatory&#39;]==&#39;yes&#39;] bcg_fat_max=bcg_yes.loc[bcg_yes[&#39;date&#39;]==datetime.date(year=2020,month=6,day=20)] bcg_fat_max=bcg_fat_max.loc[bcg_fat_max[&#39;total_cases&#39;]&gt;=1000] bcg_fat_max=bcg_fat_max.sort_values(&#39;Fatality_Rate&#39;,ascending=False) head=bcg_fat_max.head(5) #head bcg_no=covid_data_no_world_bcg.loc[covid_data_no_world_bcg[&#39;mandatory&#39;]==&#39;no&#39;] bcg_no_fat_max=bcg_no.loc[bcg_no[&#39;date&#39;]==datetime.date(year=2020,month=6,day=20)] bcg_no_fat_max=bcg_no_fat_max.loc[bcg_no_fat_max[&#39;total_cases&#39;]&gt;=1000] bcg_no_fat_max=bcg_no_fat_max.sort_values(&#39;Fatality_Rate&#39;,ascending=False) . bcg_fatality_top5=covid_data_no_world_bcg[covid_data_no_world_bcg[&#39;location&#39;].isin([&#39;Hungary&#39;,&#39;Mexico&#39;,&#39;Algeria&#39;,&#39;Ireland&#39;,&#39;Niger&#39;])] fig = px.line(bcg_fatality_top5, x=&quot;date&quot;, y=&quot;Fatality_Rate&quot;, color=&#39;location&#39;) fig.update_xaxes(nticks=10) fig.update_layout(title=&#39;BCG Mandatory Status Countries - Highest Fatality Rate&#39;,yaxis_tickformat = &#39;%&#39;,height=400) fig.show() bcg_fatality_bottom5=covid_data_no_world_bcg[covid_data_no_world_bcg[&#39;location&#39;].isin([&#39;Oman&#39;,&#39;Maldives&#39;,&#39;Qatar&#39;,&#39;Nepal&#39;,&#39;Singapore&#39;])] fig = px.line(bcg_fatality_bottom5, x=&quot;date&quot;, y=&quot;Fatality_Rate&quot;, color=&#39;location&#39;) fig.update_layout(title=&#39;BCG Mandatory Status Countries - Lowest Fatality Rate&#39;,yaxis_tickformat = &#39;%&#39;,height=400) fig.show() . bcg_fatality_top5.groupby(&#39;location&#39;).agg({&#39;total_cases&#39;:&#39;max&#39;,&#39;total_cases_per_million&#39;:&#39;median&#39;,&#39;population&#39;:&#39;median&#39;,&#39;total_tests&#39;:&#39;max&#39;,&#39;total_tests_per_thousand&#39;:&#39;max&#39;,&#39;extreme_poverty&#39;:&#39;mean&#39;,&#39;diabetes_prevalence&#39;:&#39;mean&#39;,&#39;cvd_death_rate&#39;:&#39;median&#39;,&#39;hospital_beds_per_thousand&#39;:&#39;mean&#39;,&#39;Fatality_Rate&#39;:&#39;median&#39;,&#39;aged_65_older&#39;:&#39;median&#39;,&#39;life_expectancy&#39;:&#39;mean&#39;,&#39;female_smokers&#39;:&#39;mean&#39;,&#39;male_smokers&#39;:&#39;mean&#39;}) . total_cases total_cases_per_million population total_tests total_tests_per_thousand extreme_poverty diabetes_prevalence cvd_death_rate hospital_beds_per_thousand Fatality_Rate aged_65_older life_expectancy female_smokers male_smokers . location . Algeria 11631.0 | 10.3530 | 43851043 | NaN | NaN | 0.5 | 6.73 | 278.364 | 1.90 | 0.074858 | 6.211 | 76.88 | 0.7 | 30.4 | . Hungary 4094.0 | 278.2510 | 9660350 | 233742.0 | 24.196 | 0.5 | 7.55 | 278.296 | 7.02 | 0.109932 | 18.577 | 76.88 | 26.8 | 34.8 | . Ireland 25374.0 | 398.9635 | 4937796 | 386572.0 | 78.288 | 0.2 | 3.28 | 126.459 | 2.96 | 0.056432 | 13.928 | 82.30 | 23.0 | 25.7 | . Mexico 175202.0 | 8.0935 | 128932753 | 405823.0 | 3.148 | 2.5 | 13.06 | 152.783 | 1.38 | 0.093485 | 6.857 | 75.05 | 6.9 | 21.4 | . Niger 1035.0 | 31.5200 | 24206636 | NaN | NaN | 44.5 | 2.42 | 238.339 | 0.30 | 0.057368 | 2.553 | 62.42 | 0.1 | 15.4 | . bcg_fatality_bottom5.groupby(&#39;location&#39;).agg({&#39;total_cases&#39;:&#39;max&#39;,&#39;total_cases_per_million&#39;:&#39;median&#39;,&#39;population&#39;:&#39;median&#39;,&#39;total_tests&#39;:&#39;max&#39;,&#39;total_tests_per_thousand&#39;:&#39;max&#39;,&#39;extreme_poverty&#39;:&#39;mean&#39;,&#39;diabetes_prevalence&#39;:&#39;mean&#39;,&#39;cvd_death_rate&#39;:&#39;median&#39;,&#39;hospital_beds_per_thousand&#39;:&#39;mean&#39;,&#39;Fatality_Rate&#39;:&#39;median&#39;,&#39;aged_65_older&#39;:&#39;median&#39;,&#39;life_expectancy&#39;:&#39;mean&#39;,&#39;female_smokers&#39;:&#39;mean&#39;,&#39;male_smokers&#39;:&#39;mean&#39;}) . total_cases total_cases_per_million population total_tests total_tests_per_thousand extreme_poverty diabetes_prevalence cvd_death_rate hospital_beds_per_thousand Fatality_Rate aged_65_older life_expectancy female_smokers male_smokers . location . Maldives 2187.0 | 689.1235 | 540542 | 37491.0 | 69.358 | NaN | 9.19 | 164.905 | NaN | 0.000873 | 4.120 | 78.92 | 2.1 | 55.0 | . Nepal 8605.0 | 0.1720 | 29136808 | 133377.0 | 4.578 | 15.0 | 7.26 | 260.797 | 0.3 | 0.000000 | 5.809 | 70.78 | 9.5 | 37.8 | . Oman 28566.0 | 31.2340 | 5106622 | NaN | NaN | NaN | 12.61 | 266.342 | 1.6 | 0.004483 | 2.355 | 77.86 | 0.5 | 15.6 | . Qatar 86488.0 | 199.9265 | 2881060 | 317694.0 | 110.270 | NaN | 16.52 | 176.690 | 1.2 | 0.000724 | 1.307 | 80.23 | 0.8 | 26.9 | . Singapore 41833.0 | 99.3105 | 5850343 | 340894.0 | 58.269 | NaN | 10.99 | 92.243 | 2.4 | 0.000659 | 12.922 | 83.62 | 5.2 | 28.3 | . Diving deeper into the results of the violin plot above - we looked at the BCG Mandatory countries and identified the countries with lowest and highest fatality rates. Algeria, Hungary, Ireland, Mexico &amp; Niger were some of the countries with highest fatality rates, although out of these 5, except for Mexico all the countries had quite lower number of total cases. Mexico had around 175k cases and 12% Fatality Rate, which seems to be still rising. Except for Hungary and Mexico, the Fatality Rate seems to have stabilized. . Mexico seems to have a much higher prevalence of Diabetes at 13.06 compared to other countries here, although it had lower Cardiovascular death rate compared to other countries | Mexico had very low tests_per_thousand, which means that the true impact of Covid might be worse than what is visible through these numbers | Niger had low life expectancy of 62, indicating towards poorer healthcare infrastructure in the country. It also has a very high extreme_poverty value | Hungary had a high percentage of population older than 65 | Countries with lowest Fatality Rates had a high life expectancy, all these countries had a life expectancy over 70. | . Spain vs Portugal . After having had a look at the global stats, let&#39;s now look at combinations of neighboring countries or regions to understand the variations in Covid deaths based on BCG policy. These would help us make more reliable claims since these neighboring regions would be expected to be similar in economic, demographic, ethnic, social &amp; cultural status, eliminating any differences that can be observed due to these variables. . The very first case that we would be looking at would be Spain vs Portugal, since there is a significant difference in Covid fatalities in these countries despite being neighbors. These countries are also different in terms of their Covid Status, Portugal has BCG vaccine mandatory for all its citizens whereas Spain stopped its vaccination program in 1981. . sppo=covid_data_no_world_bcg.loc[covid_data_no_world_bcg[&#39;location&#39;].isin([&#39;Spain&#39;,&#39;Portugal&#39;])] sp=sppo.loc[sppo[&#39;date&#39;]&gt;=datetime.date(year=2020,month=3,day=10)] sp[&#39;cases_per_million&#39;]=(sp[&#39;total_cases&#39;]/sp[&#39;population&#39;])*1000000 fig = px.line(sp, x=&quot;date&quot;, y=&quot;total_cases&quot;, color=&#39;location&#39;) fig.update_layout( title_text=&quot;Spain vs Portugal - Total Covid Cases&quot;,height=400) fig.show() fig = px.line(sp, x=&quot;date&quot;, y=&quot;cases_per_million&quot;, color=&#39;location&#39;) fig.update_layout( title_text=&quot;Spain vs Portugal - Covid Cases per Million&quot;,height=400) fig.show() fig = px.line(sp, x=&quot;date&quot;, y=&quot;Fatality_Rate&quot;, color=&#39;location&#39;) fig.update_layout( title_text=&quot;Spain vs Portugal - Fatality Rate&quot;,height=400,yaxis_tickformat = &#39;%&#39;) fig.show() . /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy . splo=stringency_index[(stringency_index.location.isin([&#39;Spain&#39;,&#39;Portugal&#39;]))&amp;(stringency_index[&#39;Date&#39;]&gt;=&#39;2020-03-15&#39;)&amp;(stringency_index[&#39;Date&#39;]&lt;=&#39;2020-06-20&#39;)] fig = px.line(splo, x=&quot;Date&quot;, y=&quot;stringency_index&quot;, color=&#39;location&#39;) fig.update_layout( title_text=&quot;Spain vs Portugal - Lockdown Stringency Index&quot;,height=400) fig.show() . As we can see above, there is a big difference in the total number of cases being reported in Spain &amp; Portugal, Portugal reported around 38k cases by 20th June while Spain reported around 245k cases on the same date. However, this difference in the number of cases could be due to the variation in size and population between the two countries, Spain&#39;s population is more than 4 times that of Portugal. . Therefore probably more reliable metric would be total_cases_per_million population, even here Spain has much higher 5280 cases per million by 20 June whereas Portugal has 3770 cases per million, however the difference here is not that huge as the total cases. . Next we look at the total_deaths_per_million and this is where huge difference is noticeable. In Spain the Fatality Rate went from around 2% on mid-March to 12% in June, however in Portugal it only increased from 0% to 4% in the same duration. On June 20 there was a difference of 8% in the Fatality Rate of Spain &amp; Portugal. . This shows that Portugal had lower total_cases_per_million as well as lower total_deaths_per_million compared to Spain. . Lockdown measures in both countries were almost equally strict, with Portugal relaxing its lockdown measures slightly early than Spain . Next we will be diving deeper into this data and looking at hospitalizations &amp; ICU cases in Spain while also looking at fatalities by age group in Portugal. . spain_age_group.loc[spain_age_group[&#39;Age Group&#39;]==&#39;80-89&#39;,&#39;Age Group&#39;]=&#39;80+&#39; spain_age_group.loc[spain_age_group[&#39;Age Group&#39;]==&#39;?90&#39;,&#39;Age Group&#39;]=&#39;80+&#39; spain_age_group=spain_age_group.groupby(&#39;Age Group&#39;).agg({&#39;Cases&#39;:&#39;sum&#39;,&#39;Hospitalization&#39;:&#39;sum&#39;,&#39;ICU&#39;:&#39;sum&#39;,&#39;Deaths&#39;:&#39;sum&#39;}).reset_index() spain_age_group.columns=[&#39;Age Group&#39;,&#39;Cases&#39;,&#39;Hospitalization&#39;,&#39;ICU&#39;,&#39;Deaths&#39;] spain_age_group[&#39;percent_hospitalization&#39;]=spain_age_group[&#39;Hospitalization&#39;]/spain_age_group[&#39;Cases&#39;] spain_age_group[&#39;percent_ICU&#39;]=spain_age_group[&#39;ICU&#39;]/spain_age_group[&#39;Cases&#39;] spain_age_group[&#39;percent_death&#39;]=spain_age_group[&#39;Deaths&#39;]/spain_age_group[&#39;Cases&#39;] . fig = make_subplots(rows=3, cols=1) fig.append_trace(go.Bar( x=spain_age_group[&#39;Age Group&#39;], y=spain_age_group[&#39;percent_hospitalization&#39;],name=&#39;Percent_Hospitalization&#39; ), row=1, col=1) fig.append_trace(go.Bar( x=spain_age_group[&#39;Age Group&#39;], y=spain_age_group[&#39;percent_ICU&#39;],name=&#39;Percent_ICU&#39; ), row=2, col=1) fig.append_trace(go.Bar( x=spain_age_group[&#39;Age Group&#39;], y=spain_age_group[&#39;percent_death&#39;],name=&#39;Percent_Deaths&#39; ), row=3, col=1) fig.update_layout(height=600, width=800, title_text=&quot;Spain - Covid Stats by Age Group&quot;,yaxis_tickformat = &#39;%&#39;) fig.show() . Percentage Hospitalizations for 0-9 age group is high at 28%, however this could be due to infants being born to mothers with Covid-19 or being infected in the hospital, however the good thing is that only 4% of cases in this age group require hospitalization and fatalities are close to zero | In the age-groups of 10-40, hospitalizations are between 10-20% however the number of ICU and deaths are close to zero, indicating that these patients recover with regular hospital care | In the 60+ age group, the number of hospitalizations are very high, more than 40% of the patients in these age groups required hospitalization &amp; more than 15% patients in the 70+ age group succumbed to Covid-19 | One thing that stands out from this chart is that the percentage of ICU cases for 80+ age group is very low compared to 60-69 &amp; 70-79 age groups, however the mortality from this age group is very high, it could be due to scarcity of resources at the peak of pandemic and hospitals prioritizing lower age groups which had a higher chance of survival. Perhaps if the peak had been more spread out, some of these patients could have received necessary healthcare and the fatality rate could have been lowered | Spain started BCG vaccination around 1965, which means that oldest age of vaccinated citizens would be 55 in Spain,and older age groups would have no protection offered from BCG. This coincides with steep rice in Fatality rate as well as we move from younger age groups to 50+ age groups. | . portugal_age_group.loc[portugal_age_group[&#39;Age Group&#39;]==&#39;Oct-19&#39;,&#39;Age Group&#39;]=&#39;10-19&#39; portugal_age_group[&#39;percent_deaths&#39;]=portugal_age_group[&#39;Deaths&#39;]/portugal_age_group[&#39;Cases&#39;] spain_age_group[&#39;Age Group&#39;] spain_age_group.loc[spain_age_group[&#39;Age Group&#39;]==&#39;?90&#39;,&#39;Age Group&#39;]=&#39;80+&#39; fig = go.Figure(data=[ go.Bar(name=&#39;Portugal&#39;, x=portugal_age_group[&#39;Age Group&#39;], y=portugal_age_group[&#39;percent_deaths&#39;]), go.Bar(name=&#39;Spain&#39;, x=spain_age_group[&#39;Age Group&#39;], y=spain_age_group[&#39;percent_death&#39;]) ]) # Change the bar mode fig.update_layout(barmode=&#39;group&#39;,title=&#39;Spain vs Portugal - Percentage of Positive cases by Age Group leading to Deaths&#39;) fig.show() . Next we compare the Fatality Rate between Spain vs Portual across age groups, its very apparent from this chart that Portugal has a lower death rate than Spain across all the age groups, however even in the older age groups Portugal has a lower death rate than Spain. The 80+ age group in both countries would not have received any BCG vaccination and the Fatality Rates for this age group in both countries is similar. . covid_data_no_world_bcg.loc[(covid_data_no_world_bcg[&#39;location&#39;].isin([&#39;Spain&#39;,&#39;Portugal&#39;]))&amp; (covid_data_no_world_bcg[&#39;date&#39;]==datetime.date(year=2020,month=6,day=20))] . iso_code continent location date total_cases new_cases total_deaths new_deaths total_cases_per_million new_cases_per_million ... cvd_death_rate diabetes_prevalence female_smokers male_smokers handwashing_facilities hospital_beds_per_thousand life_expectancy Fatality_Rate mandatory BCG Strain . 16516 PRT | Europe | Portugal | 2020-06-20 | 38464.0 | 375.0 | 1527.0 | 3.0 | 3772.198 | 36.777 | ... | 127.842 | 9.85 | 16.3 | 30.0 | NaN | 3.39 | 82.05 | 0.039699 | no | Japan | . 18574 ESP | Europe | Spain | 2020-06-20 | 245938.0 | 363.0 | 30240.0 | 7.0 | 5260.168 | 7.764 | ... | 99.403 | 7.17 | 27.4 | 31.4 | NaN | 2.97 | 83.56 | 0.122958 | no | Danish | . 2 rows × 37 columns . Ireland - Cork vs Kerry . During my research for this hack, I came across an interesting study for the BCG vaccine here - https://bmcinfectdis.biomedcentral.com/articles/10.1186/s12879-019-4026-z#:~:text=BCG%20vaccination%20policy%20in%20Ireland,as%20of%202016%20%5B10%5D . This was a study conducted in Ireland, to measure the efficacy of BCG vaccine for Tuberculosis, it compared three different regions across two counties in Southern Ireland, these regions were different in BCG coverage of the population. The aim of this study was to examine the impact of three different BCG vaccination policies on observed incidence of TB disease in the South of Ireland over a 13-year period. Study is also interesting in the sense that both these counties are geographically contigous and have a similar ethnic &amp; economic background, belonging to the same country. . We can also look at these counties to check if different rates of BCG coverage also have any correlation with total cases of Covid-19. . ireland_county_data=pd.read_csv(&#39;../input/ireland-covid-data/ireland_cso_data.csv&#39;) ireland_county_daily_data=pd.read_csv(&#39;../input/ireland-covid-data/Covid19CountyStatisticsHPSCIreland.csv&#39;) ireland_covid_stats=pd.read_csv(&#39;../input/ireland-covid-data/Covid19CountyStatisticsHPSCIrelandOpenData.csv&#39;) ireland_covid_stats=ireland_covid_stats[[&#39;CountyName&#39;,&#39;PopulationCensus16&#39;,&#39;Density&#39;]].drop_duplicates(keep=&#39;first&#39;) ireland_county_data.columns=[&#39;County&#39;, &#39;total_deaths&#39;, &#39;median_age_deaths&#39;, &#39;total_cases&#39;,&#39;median_age_cases&#39;] ireland_county_data=ireland_county_data.sort_values(&#39;total_cases&#39;,ascending=False) ireland_county_data=pd.merge(ireland_county_data,ireland_covid_stats,left_on=&#39;County&#39;,right_on=&#39;CountyName&#39;,how=&#39;inner&#39;) ireland_county_data[&#39;total_deaths&#39;]=pd.to_numeric(ireland_county_data[&#39;total_deaths&#39;],errors=&#39;coerce&#39;).fillna(0) ireland_county_data[&#39;Fatality_Rate&#39;]=ireland_county_data[&#39;total_deaths&#39;]/ireland_county_data[&#39;total_cases&#39;] ireland_county_data[&#39;cases_per_million&#39;]=(ireland_county_data[&#39;total_cases&#39;]/ireland_county_data[&#39;PopulationCensus16&#39;])*10000000 ireland_county_data[&#39;deaths_per_million&#39;]=(ireland_county_data[&#39;total_deaths&#39;]/ireland_county_data[&#39;PopulationCensus16&#39;])*10000000 # fig = px.bar(ireland_county_data, x=&#39;CountyName&#39;, y=&#39;ConfirmedCovidCases&#39;) # fig.update_layout(title=&#39;Ireland - Confirmed Cases by County&#39;) # fig.show() colors = [&#39;lightslategray&#39;,] * 26 colors[1] = &#39;blue&#39; colors[18] = &#39;crimson&#39; fig = make_subplots(rows=3, cols=1,subplot_titles=(&quot;Confirmed Covid Cases&quot;, &quot;Covid Fatality Rate&quot;,&quot;Population Density&quot;)) fig.add_trace( go.Bar( x=ireland_county_data[&#39;County&#39;], y=ireland_county_data[&#39;total_cases&#39;],text=ireland_county_data[&#39;total_cases&#39;], marker_color=colors # marker color can be a single color value or an iterable ), row=1, col=1 ) fig.add_trace( go.Bar( x=ireland_county_data[&#39;County&#39;], y=ireland_county_data[&#39;Fatality_Rate&#39;],text=ireland_county_data[&#39;Fatality_Rate&#39;], marker_color=colors # marker color can be a single color value or an iterable ), row=2, col=1 ) fig.add_trace( go.Bar( x=ireland_county_data[&#39;CountyName&#39;], y=ireland_county_data[&#39;Density&#39;],text=ireland_county_data[&#39;Density&#39;], marker_color=colors # marker color can be a single color value or an iterable ), row=3, col=1 ) #fig.update_layout(height=400, width=800, title_text=&quot;Fatailty_Rate&quot;) fig.update_traces(texttemplate=&#39;%{text:.2s}&#39;, textposition=&#39;outside&#39;) fig.update_layout(title_text=&#39;Ireland - Confirmed Cases &amp; Population Density by County&#39;,height=1000) fig.show() . The county level covid confirmed cases data for Ireland shows that majority of the Covid cases happened in the capital city of Dublin. Taking a look at two counties of interest - Cork &amp; Kerry, we see that Cork has 5 times the number of Covid confirmed cases as compared to Kerry, however that could also be due to Cork having twice as much population density as Kerry. Dense population areas are likely to have a greater spread to Covid. Let&#39;s now try and normalize these numbers and look at cases_per_million &amp; deaths_per_million between the two counties &amp; overall growth of Covid. . ireland_county_daily_data[&#39;date&#39;]=pd.to_datetime(ireland_county_daily_data[&#39;TimeStamp&#39;]).dt.date ireland_county_daily_data[&#39;cases_per_million&#39;]=(ireland_county_daily_data[&#39;ConfirmedCovidCases&#39;]/ireland_county_daily_data[&#39;PopulationCensus16&#39;])*10000000 ireland_county_daily_data_cork_kerry=ireland_county_daily_data.loc[(ireland_county_daily_data[&#39;CountyName&#39;]==&#39;Cork&#39;)|(ireland_county_daily_data[&#39;CountyName&#39;]==&#39;Kerry&#39;)] fig = px.line(ireland_county_daily_data_cork_kerry, x=&quot;date&quot;, y=&quot;cases_per_million&quot;, color=&#39;CountyName&#39;) fig.update_layout( title_text=&quot;Cork vs Kerry - Cases per Million&quot;,height=300,width=800) fig.show() k=ireland_county_data.loc[(ireland_county_data[&#39;County&#39;]==&#39;Cork&#39;)|(ireland_county_data[&#39;County&#39;]==&#39;Kerry&#39;)] fig1 = px.bar(k, x=&#39;County&#39;, y=&#39;deaths_per_million&#39;) fig1.update_layout(title=&#39;Cork vs Kerry - Deaths per Million&#39;,height=300) fig1.show() . ireland_county_data.loc[(ireland_county_data[&#39;County&#39;]==&#39;Cork&#39;)|(ireland_county_data[&#39;County&#39;]==&#39;Kerry&#39;)] . County total_deaths median_age_deaths total_cases median_age_cases CountyName PopulationCensus16 Density Fatality_Rate cases_per_million deaths_per_million . 1 Cork | 49.0 | 83 | 1534 | 47 | Cork | 542868 | 72.3 | 0.031943 | 28257.329590 | 902.613527 | . 18 Kerry | 6.0 | 81 | 307 | 48 | Kerry | 147707 | 30.7 | 0.019544 | 20784.390719 | 406.209591 | . As seen above, Cork has a higher cases_per_million &amp; deaths_per_million number than Kerry, which may suggest some evidence that people in Kerry had a higher protection from covid due to mandatory BCG vaccination policy. The cases_per_million in Cork is 1.5 times of the number in Kerry, whereas deaths_per_million was twice that of Kerry. Fatality Rate in Cork is also 1.5 times that of Kerry. This does suggest that Cork was hit much harder duet to Covid than Kerry, but we can&#39;t be completely sure at this stage whether it was due to BCG vaccination policy. . fig=go.Figure() fig.add_trace(go.Violin(y=ireland_county_data[&#39;median_age_cases&#39;],name=&#39;median_age_cases&#39;,box_visible=True,meanline_visible=True)) fig.add_trace(go.Violin(y=ireland_county_data[&#39;median_age_deaths&#39;],name=&#39;median_age_deaths&#39;,box_visible=True,meanline_visible=True)) fig.update_layout(title=&#39;Median age for Cases &amp; Deaths across Counties in Ireland&#39;) fig.update_yaxes(title=&quot;Median Age&quot;) fig.show() . We also looked at difference between Median age of cases &amp; Median age of deaths due to covid across all counties in Ireland. Q1-Q3 range for cases across all counties was 47-51, indicating that similar age groups were infected across all counties in Ireland. Median age of Deaths was much higher than median age of cases, standing at 82. Q1-Q3 range for deaths is 81-84, which again indicates that similar age group suffered most casualties across all counties in Ireland. . Finally, ss we discussed earlier,let&#39;s also look at how much population density plays a role in the overall spread of Covid in Ireland, let&#39;s compare the correlation between population density and the confirmed cases of Covid. . ireland_county_data[[&#39;Density&#39;,&#39;total_cases&#39;,&#39;Fatality_Rate&#39;,&#39;PopulationCensus16&#39;,&#39;cases_per_million&#39;,&#39;deaths_per_million&#39;,&#39;median_age_cases&#39;,&#39;median_age_deaths&#39;]].corr() . Density total_cases Fatality_Rate PopulationCensus16 cases_per_million deaths_per_million median_age_cases median_age_deaths . Density 1.000000 | 0.991922 | 0.108925 | 0.929099 | 0.380472 | 0.362657 | -0.006921 | 0.090499 | . total_cases 0.991922 | 1.000000 | 0.103013 | 0.952770 | 0.417953 | 0.382831 | -0.026089 | 0.137000 | . Fatality_Rate 0.108925 | 0.103013 | 1.000000 | 0.066710 | 0.164158 | 0.671514 | 0.612871 | 0.147199 | . PopulationCensus16 0.929099 | 0.952770 | 0.066710 | 1.000000 | 0.241651 | 0.252242 | -0.063541 | 0.130109 | . cases_per_million 0.380472 | 0.417953 | 0.164158 | 0.241651 | 1.000000 | 0.762674 | -0.136054 | 0.340123 | . deaths_per_million 0.362657 | 0.382831 | 0.671514 | 0.252242 | 0.762674 | 1.000000 | 0.319804 | 0.306367 | . median_age_cases -0.006921 | -0.026089 | 0.612871 | -0.063541 | -0.136054 | 0.319804 | 1.000000 | -0.170363 | . median_age_deaths 0.090499 | 0.137000 | 0.147199 | 0.130109 | 0.340123 | 0.306367 | -0.170363 | 1.000000 | . As seen above, Population Density has a correlation of 0.99 with number of confirmed covid cases within Ireland, which is extremely high. Therefore we cannot reliably say that the difference in total_cases_per_million between Cork &amp; Kerry is only due to difference in BCG vaccination policy. Rather it could also be due to the higher population density in urban areas of Cork. Also, Fatality Rate is also highly correlated with median_age_cases, which is a bit obvious. . Germany - East Germany vs West Germany . This is another interesting case where lot of studies were done to show the difference in spread of Covid across East &amp; West Germany. Divergent BCG vaccination policies existed in the politically divided country (1949–1989) before German reunification in 1990. In East Germany, BCG vaccination programs were established by the communist government in 1951, and soon became compulsory in 1953, leading to near-universal (99.8%) BCG vaccination of newborns by day 3. By contrast, voluntary BCG vaccination (recommended since 1955) was far less common in West Germany, due to low incidence of the disease after the Second World War. In early years, only 7–20% of all newborns became BCG-vaccinated in Western Germany, with almost complete cessation of vaccination between 1975 and 1977. More information is available here - https://www.nature.com/articles/s41375-020-0871-4 . Thankfully I did not have to search a lot to get access to detailed German covid dataset. This is directly available in Kaggle here - https://www.kaggle.com/headsortails/covid19-tracking-germany. We were able to get Daily Age Group &amp; Gender Covid Stats by Province, most detailed out of any country in this notebook. Let&#39;s now dig deep and study how the spread of Covid has evolved with time . . de_covid_data=pd.read_csv(&#39;/kaggle/input/covid19-tracking-germany/covid_de.csv&#39;) germany_province_data=pd.read_csv(&#39;/kaggle/input/hackathon/task_2-Gemany_per_state_stats_20June2020.csv&#39;) id_mapping=pd.read_csv(&#39;/kaggle/input/idmapping/state_id_mapping_de.csv&#39;) uniques=germany_province_data[[&#39;State in Germany (German)&#39;,&#39;East/West&#39;,&#39;Population&#39;]].drop_duplicates() de_covid_data[&#39;date&#39;]=pd.to_datetime(de_covid_data[&#39;date&#39;]).dt.date de_covid_data #germany_province_data #de_covid_data.state.unique() de_covid_data_ew=pd.merge(de_covid_data,uniques,left_on=&#39;state&#39;,right_on=&#39;State in Germany (German)&#39;,how=&#39;left&#39;) #de_covid_data_ew.state.unique() de_covid_data_ew.loc[de_covid_data_ew.state.str.contains(&#39;Baden&#39;),&#39;East/West&#39;]=&#39;West&#39; de_covid_data_ew.loc[de_covid_data_ew.state.str.contains(&#39;Thueringen&#39;),&#39;East/West&#39;]=&#39;East&#39; de_covid_data_ew.loc[de_covid_data_ew.state.str.contains(&#39;Baden&#39;),&#39;Population&#39;]=10879618 de_covid_data_ew.loc[de_covid_data_ew.state.str.contains(&#39;Thueringen&#39;),&#39;Population&#39;]=2170714 de_sum=de_covid_data_ew.groupby([&#39;state&#39;,&#39;East/West&#39;,&#39;date&#39;,&#39;Population&#39;]).agg({&#39;cases&#39;:&#39;sum&#39;,&#39;deaths&#39;:&#39;sum&#39;,&#39;recovered&#39;:&#39;sum&#39;}).reset_index() de_sum.columns=[&#39;state&#39;,&#39;East/West&#39;,&#39;date&#39;,&#39;Population&#39;,&#39;cases&#39;,&#39;deaths&#39;,&#39;recovered&#39;] #de_sum.state.unique() de_sum[&#39;total_cases&#39;]=de_sum.groupby(by=[&#39;state&#39;,&#39;East/West&#39;,&#39;Population&#39;])[&#39;cases&#39;].cumsum() de_sum[&#39;total_deaths&#39;]=de_sum.groupby(by=[&#39;state&#39;,&#39;East/West&#39;,&#39;Population&#39;])[&#39;deaths&#39;].cumsum() #de_sum de_sum[&#39;Fatality_Rate&#39;]=de_sum[&#39;total_deaths&#39;]/de_sum[&#39;total_cases&#39;] de_sum=pd.merge(de_sum,id_mapping,how=&#39;left&#39;) de_304=de_sum.loc[de_sum[&#39;date&#39;]==datetime.date(year=2020,month=4,day=30)] de_305=de_sum.loc[de_sum[&#39;date&#39;]==datetime.date(year=2020,month=5,day=30)] de_236=de_sum.loc[de_sum[&#39;date&#39;]==datetime.date(year=2020,month=6,day=23)] . #de_sum from urllib.request import urlopen import json with urlopen(&#39;https://raw.githubusercontent.com/isellsoap/deutschlandGeoJSON/master/2_bundeslaender/2_hoch.geo.json&#39;) as response: geojson = json.load(response) fig = px.choropleth(de_304, geojson=geojson, color=&quot;Fatality_Rate&quot;, locations=&quot;id&quot;,color_continuous_scale=&quot;Viridis&quot; ,hover_name=&quot;East/West&quot;, ) fig.update_geos(fitbounds=&quot;locations&quot;) fig.update_layout(title=&#39;Germany - 30 April Covid Fatality Rate&#39;,height=400) fig.show() fig1 = px.choropleth(de_305, geojson=geojson, color=&quot;Fatality_Rate&quot;, locations=&quot;id&quot;,color_continuous_scale=&quot;Viridis&quot; ,hover_name=&quot;East/West&quot; ) fig1.update_geos(fitbounds=&quot;locations&quot;) fig1.update_layout(title=&#39;Germany - 30 May Covid Fatality Rate&#39;,height=400) fig1.show() fig2 = px.choropleth(de_236, geojson=geojson, color=&quot;Fatality_Rate&quot;, locations=&quot;id&quot;,color_continuous_scale=&quot;Viridis&quot; ,hover_name=&quot;East/West&quot; ) fig2.update_geos(fitbounds=&quot;locations&quot;) fig2.update_layout(title=&#39;Germany - 23 June Covid Fatality Rate&#39;,height=400) fig2.show() . We looked at the changes in Fatality Rate across German provinces at three different dates - 30 April, 30 May &amp; 23 June to see how it has changed over time. Following patterns emerge - . There is not a big variation in Covid Fatality Rate across German provinces on all three dates. Fatality rates generally lie between 3%-6% | There is not a huge variation in Covid Fatality Rate across East &amp; German provinces | . Let&#39;s now look at distribution of Covid Fatality Rates across provinces to get a better sense of differences across East &amp; West Germany. . germany_concat=pd.concat([de_304,de_305,de_236]).reset_index() germany_concat.date.unique() fig = px.violin(germany_concat, x=&#39;date&#39;, color=&#39;East/West&#39;, y=&#39;Fatality_Rate&#39;,box=True, hover_name=&#39;state&#39;) fig.update_layout(template=&#39;seaborn&#39;,title=&#39;Distribution of Fatality Rates Across East/West Germany&#39;,legend_title_text=&#39;Region&#39;,xaxis = { &#39;tickformat&#39;: &#39;%d-%m&#39;, &#39;tickmode&#39;: &#39;auto&#39;, # &#39;nticks&#39;: value, [where value is the max # of ticks] # &#39;tick0&#39;: value, [where value is the first tick] # &#39;dtick&#39;: value [where value is the step between ticks] },yaxis_tickformat = &#39;%&#39;) fig.show() . As we can see above the median values for Fatality Rates across German provinces is not very different for East &amp; West Germany across the three month period. East Germany provinces however have a slightly lower Fatality Rate on all three months. Let&#39;s now look at daily progression of Covid cases across East/West Germany and fatality rates by age group. . group=de_sum.groupby([&#39;East/West&#39;,&#39;date&#39;]).agg({&#39;total_deaths&#39;:&#39;sum&#39;,&#39;total_cases&#39;:&#39;sum&#39;}).reset_index() reg_pop=germany_province_data.groupby(&#39;East/West&#39;).agg({&#39;Population&#39;:&#39;sum&#39;}).reset_index() group=pd.merge(group,reg_pop,how=&#39;inner&#39;) group[&#39;Fatality Rate&#39;]=group[&#39;total_deaths&#39;]/group[&#39;total_cases&#39;] group[&#39;Deaths_per_Million&#39;]=(group[&#39;total_deaths&#39;]/group[&#39;Population&#39;])*1000000 fig = px.line(group, x=&quot;date&quot;, y=&quot;total_cases&quot;, color=&#39;East/West&#39;) fig.update_layout( title_text=&quot;Germany - Total Cases by Region&quot;,height=300,width=800) fig.show() fig = px.line(group, x=&quot;date&quot;, y=&quot;total_deaths&quot;, color=&#39;East/West&#39;) fig.update_layout( title_text=&quot;Germany - Total Deaths by Region&quot;,height=300,width=800) fig.show() fig = px.line(group, x=&quot;date&quot;, y=&quot;Fatality Rate&quot;, color=&#39;East/West&#39;) fig.update_layout( title_text=&quot;Germany - Fatality Rate by Region&quot;,yaxis_tickformat = &#39;%&#39;,height=300,width=800) fig.show() fig = px.line(group, x=&quot;date&quot;, y=&quot;Deaths_per_Million&quot;, color=&#39;East/West&#39;) fig.update_layout( title_text=&quot;Germany - Deaths per Million by Region&quot;,height=300,width=800) fig.show() . Following things emerge from the charts above - . West Germany has almost 9 times the number of Covid cases reported as compared to East Germany, this difference remains consistent throughout the analysis period. This means that the total spread of virus was much higher in West Germany | Same thing can be noticed for total_deaths as well, West Germany has about 10 times the total number of deaths compared to East Germany, this difference also remains roughly consistent for the analysis period | To normalize the huge difference in total cases &amp; population across Germany, we look at Fatality Rate, which is the total percentage of cases that resulted to death, this number remains fairly consistent for the analysis period as well, with Fatality Rate around 5% for West Germany and 4% for East Germany, which is not a huge difference | Deaths per million, however is twice for West Germany compared to East Germany. | . Difference in Covid confirmed cases and Deaths per Million across East/West Germany may indicate that BCG might provide some sort of protection against the infection as well as reducing the chances of death once a person has been infected. East Germany - which had universal BCG vaccination does much better than West Germany, which had lower coverage of BCG. Let&#39;s now look at Fatality Rate &amp; Deaths per million across age groups in East &amp; West Germany. . de_age=de_covid_data_ew.groupby([&#39;East/West&#39;,&#39;age_group&#39;]).agg({&#39;cases&#39;:&#39;sum&#39;,&#39;deaths&#39;:&#39;sum&#39;}).reset_index() de_age_pop=pd.merge(de_age,reg_pop,how=&#39;inner&#39;) de_age_pop.age_group = de_age_pop.age_group.astype(&#39;str&#39;) de_age_pop[&#39;Fatality_Rate&#39;]=de_age_pop[&#39;deaths&#39;]/de_age_pop[&#39;cases&#39;] de_age_pop[&#39;Deaths_per_Million&#39;]=(de_age_pop[&#39;deaths&#39;]/de_age_pop[&#39;Population&#39;])*1000000 fig=px.bar(de_age_pop, x=&quot;age_group&quot;, y=&quot;Fatality_Rate&quot;, color=&#39;East/West&#39;,barmode=&#39;group&#39;) fig.update_layout(xaxis_type=&#39;category&#39;,yaxis_tickformat = &#39;%&#39;,title_text=&quot;Germany - Fatality Rate Age Group&quot;,height=250,margin=dict(l=20, r=20, t=25, b=25)) fig.show() fig=px.bar(de_age_pop, x=&quot;age_group&quot;, y=&quot;Deaths_per_Million&quot;, color=&#39;East/West&#39;,barmode=&#39;group&#39;) fig.update_layout(xaxis_type=&#39;category&#39;,title_text=&quot;Germany - Deaths per Million by Age Group&quot;,height=250,margin=dict(l=20, r=20, t=25, b=0)) fig.show() . Above charts tell us following - . Fatality Rates across Germany were close to zero for age groups 0-34 | Fatality Rates for age groups 35-59 were close to 1% | Fatality Rates rose up steadily for 60+ age groups, with Fatality rate around 7-8% for 60-79 and 20%+ for 80+ age groups | Similarly Deaths per Million were very high as well for higher age groups. However both the fatality rate and deaths per million were much higher in West Germany compared to East Germany | . germany_province_data=pd.read_csv(&#39;/kaggle/input/hackathon/task_2-Gemany_per_state_stats_20June2020.csv&#39;,thousands=&#39;,&#39;)#Covid stats for Germany provinces germany_province_data[&#39;Deaths&#39;] = germany_province_data[&#39;Deaths&#39;].str.replace(&#39;,&#39;, &#39;&#39;).astype(float) germany_province_data[&#39;cases_per_million&#39;]=germany_province_data[&#39;Cases&#39;]/germany_province_data[&#39;Population&#39;] germany_province_data[&#39;deaths_per_million&#39;]=germany_province_data[&#39;Deaths&#39;]/germany_province_data[&#39;Population&#39;] germany_province_data[&#39;Fatality_Rate&#39;]=germany_province_data[&#39;Deaths&#39;]/germany_province_data[&#39;Cases&#39;] germany_province_data[[&#39;Population Density&#39;,&#39;Fatality_Rate&#39;,&#39;cases_per_million&#39;,&#39;deaths_per_million&#39;,&#39;Population&#39;,&#39;Deaths&#39;,&#39;Cases&#39;]].corr() #germany_province_data . Population Density Fatality_Rate cases_per_million deaths_per_million Population Deaths Cases . Population Density 1.000000 | -0.336534 | 0.277119 | 0.024107 | -0.175727 | -0.168752 | -0.125934 | . Fatality_Rate -0.336534 | 1.000000 | 0.476262 | 0.727513 | 0.196027 | 0.353171 | 0.285968 | . cases_per_million 0.277119 | 0.476262 | 1.000000 | 0.929159 | 0.444594 | 0.685914 | 0.652997 | . deaths_per_million 0.024107 | 0.727513 | 0.929159 | 1.000000 | 0.408068 | 0.681768 | 0.621644 | . Population -0.175727 | 0.196027 | 0.444594 | 0.408068 | 1.000000 | 0.886206 | 0.937322 | . Deaths -0.168752 | 0.353171 | 0.685914 | 0.681768 | 0.886206 | 1.000000 | 0.988924 | . Cases -0.125934 | 0.285968 | 0.652997 | 0.621644 | 0.937322 | 0.988924 | 1.000000 | . Finally, similar to Ireland let&#39;s also look at correlation matrix for different variables in Germany. What is interesting here is that unlike Ireland, total cases per province here are not correlated to the population density. It is likely due to the fact that we are looking at provinces here, which can geographically be quite big in area, whereas for Ireland we were looking at counties, which are much slower geographical units. Therefore even though a province may have few cities with dense population which may have high spread of virus, at an overall level the density for province may be low. . # covid_data_no_world_bcg_1000[&#39;mandatory&#39;==&#39;yes&#39;,&#39;mandatory_flag&#39;]=1 # covid_data_no_world_bcg_1000[&#39;mandatory&#39;==&#39;Unknown&#39;,&#39;mandatory_flag&#39;]=2 # data=covid_data_no_world_bcg_1000 # data[&#39;Test_positivity_Rate&#39;]=data[&#39;total_cases&#39;]/data[&#39;total_tests&#39;] covid_data_no_world_bcg_1000 dummies=pd.get_dummies(covid_data_no_world_bcg_1000[&#39;mandatory&#39;]) covid_data_no_world_bcg_1000_d=pd.concat([covid_data_no_world_bcg_1000,dummies],axis=1) covid_data_no_world_bcg_1000_d . iso_code continent location date total_cases new_cases total_deaths new_deaths total_cases_per_million new_cases_per_million ... male_smokers handwashing_facilities hospital_beds_per_thousand life_expectancy Fatality_Rate mandatory BCG Strain Unknown no yes . 162 AFG | Asia | Afghanistan | 2020-06-20 | 27878.0 | 346.0 | 548.0 | 2.0 | 716.136 | 8.888 | ... | NaN | 37.746 | 0.50 | 64.83 | 0.019657 | yes | Danish | 0 | 0 | 1 | . 267 ALB | Europe | Albania | 2020-06-20 | 1838.0 | 50.0 | 42.0 | 3.0 | 638.682 | 17.374 | ... | 51.2 | NaN | 2.89 | 78.57 | 0.022851 | yes | NA | 0 | 0 | 1 | . 436 DZA | Africa | Algeria | 2020-06-20 | 11504.0 | 119.0 | 825.0 | 14.0 | 262.343 | 2.714 | ... | 30.4 | 83.741 | 1.90 | 76.88 | 0.071714 | yes | NA | 0 | 0 | 1 | . 916 ARG | South America | Argentina | 2020-06-20 | 39557.0 | 4018.0 | 979.0 | 50.0 | 875.237 | 88.902 | ... | 27.7 | NaN | 5.00 | 76.67 | 0.024749 | Unknown | Anlis Malbran | 1 | 0 | 0 | . 1081 ARM | Asia | Armenia | 2020-06-20 | 19157.0 | 459.0 | 319.0 | 10.0 | 6464.896 | 154.898 | ... | 52.1 | 94.043 | 4.20 | 75.09 | 0.016652 | yes | Sofia, Bulgaria/ InterVac Ltd Toronto Canada | 0 | 0 | 1 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 20409 ARE | Asia | United Arab Emirates | 2020-06-20 | 44145.0 | 393.0 | 300.0 | 2.0 | 4463.419 | 39.736 | ... | 37.4 | NaN | 1.20 | 77.97 | 0.006796 | yes | NA | 0 | 0 | 1 | . 20583 GBR | Europe | United Kingdom | 2020-06-20 | 301815.0 | 1346.0 | 42461.0 | 173.0 | 4445.909 | 19.827 | ... | 24.7 | NaN | 2.54 | 81.32 | 0.140686 | no | Danish | 0 | 1 | 0 | . 20757 USA | North America | United States of America | 2020-06-20 | 2220961.0 | 29909.0 | 119112.0 | 678.0 | 6709.798 | 90.359 | ... | 24.6 | NaN | 2.77 | 78.86 | 0.053631 | no | NA | 0 | 1 | 0 | . 20954 VEN | South America | Venezuela | 2020-06-20 | 3591.0 | 107.0 | 30.0 | 2.0 | 126.284 | 3.763 | ... | NaN | NaN | 0.80 | 72.06 | 0.008354 | Unknown | NA | 1 | 0 | 0 | . 21223 ZMB | Africa | Zambia | 2020-06-20 | 1430.0 | 14.0 | 11.0 | 0.0 | 77.785 | 0.762 | ... | 24.7 | 13.938 | 2.00 | 63.89 | 0.007692 | Unknown | NA | 1 | 0 | 0 | . 112 rows × 40 columns . covid_data_no_world_bcg_1000_d.columns . Index([&#39;iso_code&#39;, &#39;continent&#39;, &#39;location&#39;, &#39;date&#39;, &#39;total_cases&#39;, &#39;new_cases&#39;, &#39;total_deaths&#39;, &#39;new_deaths&#39;, &#39;total_cases_per_million&#39;, &#39;new_cases_per_million&#39;, &#39;total_deaths_per_million&#39;, &#39;new_deaths_per_million&#39;, &#39;total_tests&#39;, &#39;new_tests&#39;, &#39;total_tests_per_thousand&#39;, &#39;new_tests_per_thousand&#39;, &#39;new_tests_smoothed&#39;, &#39;new_tests_smoothed_per_thousand&#39;, &#39;tests_units&#39;, &#39;stringency_index&#39;, &#39;population&#39;, &#39;population_density&#39;, &#39;median_age&#39;, &#39;aged_65_older&#39;, &#39;aged_70_older&#39;, &#39;gdp_per_capita&#39;, &#39;extreme_poverty&#39;, &#39;cvd_death_rate&#39;, &#39;diabetes_prevalence&#39;, &#39;female_smokers&#39;, &#39;male_smokers&#39;, &#39;handwashing_facilities&#39;, &#39;hospital_beds_per_thousand&#39;, &#39;life_expectancy&#39;, &#39;Fatality_Rate&#39;, &#39;mandatory&#39;, &#39;BCG Strain &#39;, &#39;Unknown&#39;, &#39;no&#39;, &#39;yes&#39;], dtype=&#39;object&#39;) . Conclusion &amp; Next Steps - . Our initial analysis does suggest that countries with long running universal BCG vaccination programs have been impacted lesser than countries lacking such programs. We also saw that lot of other economic, demographic &amp; cultural factors may play a role in the spread of Covid-19 in a particular country, therefore we cannot reliably make a claim on role of BCG in reducing these deaths on this analysis alone. . Next step would be to perform regression analyses between different countries to determine the contribution of BCG vaccine in lowering the Fatality Rate. I will be performing that analysis in the next iteration of the notebook. Meanwhile please suggest improvements and provide feedback in the comments. Thanks! . References . Ireland&#39;s Covid-19 Data Hub | Ireland County level data | WHO TB Dataset | Research on BCG Vaccine protection from severe coronavirus diseases | Severity of Covid-19 in East &amp; West Germany due to Covid | Covid-19 Insights - Could BCG help fight Covid? Impact of BCG vaccination on incidence of tuberculosis disease in southern Ireland | Further Evidence of a Possible Correlation Between the Severity of Covid-19 and BCG Immunization | History of BCG Vaccine | .",
            "url": "https://arpitsolanki.github.io/fastpagetest/2020/06/30/bcg-effectiveness-in-combating-covid-19.html",
            "relUrl": "/2020/06/30/bcg-effectiveness-in-combating-covid-19.html",
            "date": " • Jun 30, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Title",
            "content": "import os import pandas as pd import requests import json import numpy as np import plotly.express as px import plotly.graph_objects as go from plotly.subplots import make_subplots import xgboost as xgboost import datetime from sklearn.model_selection import train_test_split #Splitting data for model training from sklearn.ensemble import RandomForestClassifier #RF from sklearn.preprocessing import LabelEncoder#Label Encoder from sklearn.preprocessing import OneHotEncoder#One Hot Encoder from sklearn.metrics import confusion_matrix#Confusion Matrix from sklearn.metrics import roc_curve#RoC Curve from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve#Metrics Functions . GW=22 #Fantasy API Calls to pull historic player stats url = &#39;https://fantasy.premierleague.com/api/bootstrap-static/&#39; response = requests.get(url) response = json.loads(response.content) #Fixtures for upcoming game weeks fix_url = &#39;https://fantasy.premierleague.com/api/fixtures?event=&#39;+str(GW) fix_response = requests.get(fix_url) fix_response = json.loads(fix_response.content) . def get(url): response = requests.get(url) return json.loads(response.content) . players = response[&#39;elements&#39;] teams = response[&#39;teams&#39;] events = response[&#39;events&#39;] #fixtures = fix_response[&#39;fixtures&#39;] players_df = pd.DataFrame(players) teams_df = pd.DataFrame(teams) events_df = pd.DataFrame(events) fixtures_df=pd.DataFrame(fix_response) players_df . chance_of_playing_next_round chance_of_playing_this_round code cost_change_event cost_change_event_fall cost_change_start cost_change_start_fall dreamteam_count element_type ep_next ep_this event_points first_name form id in_dreamteam news news_added now_cost photo points_per_game second_name selected_by_percent special squad_number status team team_code total_points transfers_in transfers_in_event transfers_out transfers_out_event value_form value_season web_name minutes goals_scored assists clean_sheets goals_conceded own_goals penalties_saved penalties_missed yellow_cards red_cards saves bonus bps influence creativity threat ict_index influence_rank influence_rank_type creativity_rank creativity_rank_type threat_rank threat_rank_type ict_index_rank ict_index_rank_type corners_and_indirect_freekicks_order corners_and_indirect_freekicks_text direct_freekicks_order direct_freekicks_text penalties_order penalties_text . 0 0.0 | 0.0 | 37605 | 0 | 0 | -3 | 3 | 0 | 3 | 0.0 | 0.0 | 0 | Mesut | 0.0 | 1 | False | Not included in Arsenal&#39;s 25-man Premier Leagu... | 2020-10-20T22:30:18.118477Z | 67 | 37605.jpg | 0.0 | Özil | 0.5 | False | None | u | 1 | 3 | 0 | 3441 | 0 | 53856 | 82 | 0.0 | 0.0 | Özil | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0.0 | 0.0 | 0.0 | 650 | 262 | 650 | 262 | 650 | 262 | 650 | 262 | NaN | | NaN | | NaN | | . 1 0.0 | 0.0 | 39476 | 0 | 0 | -2 | 2 | 0 | 2 | 0.0 | 0.0 | 0 | Sokratis | 0.0 | 2 | False | Left the club by mutual consent on 20/1 | 2020-10-21T10:30:18.546407Z | 48 | 39476.jpg | 0.0 | Papastathopoulos | 0.1 | False | None | u | 1 | 3 | 0 | 10266 | 0 | 18978 | 10 | 0.0 | 0.0 | Sokratis | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0.0 | 0.0 | 0.0 | 607 | 221 | 598 | 221 | 591 | 219 | 610 | 221 | NaN | | NaN | | NaN | | . 2 100.0 | 100.0 | 41270 | 0 | 0 | -1 | 1 | 0 | 2 | 5.3 | 4.8 | 6 | David | 4.8 | 3 | False | | 2020-12-26T18:00:15.638627Z | 54 | 41270.jpg | 2.3 | Luiz Moreira Marinho | 0.8 | False | None | a | 1 | 3 | 28 | 48380 | 3827 | 94758 | 660 | 0.9 | 5.2 | David Luiz | 839 | 0 | 0 | 3 | 10 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 143 | 132.8 | 30.4 | 86.0 | 24.9 | 256 | 98 | 318 | 106 | 212 | 58 | 289 | 98 | NaN | | 4.0 | | NaN | | . 3 75.0 | 50.0 | 54694 | 0 | 0 | -7 | 7 | 1 | 3 | 3.8 | 2.2 | 0 | Pierre-Emerick | 4.5 | 4 | False | Lack of match fitness - 75% chance of playing | 2021-01-23T16:00:22.555453Z | 113 | 54694.jpg | 4.2 | Aubameyang | 6.5 | False | None | d | 1 | 3 | 71 | 562692 | 1665 | 3258367 | 9740 | 0.4 | 6.3 | Aubameyang | 1514 | 5 | 1 | 7 | 16 | 1 | 0 | 0 | 2 | 0 | 0 | 6 | 202 | 272.2 | 226.3 | 519.0 | 101.8 | 133 | 51 | 80 | 57 | 27 | 14 | 42 | 28 | NaN | | NaN | | 1.0 | | . 4 100.0 | 100.0 | 58822 | 0 | 0 | -4 | 4 | 0 | 2 | 5.3 | 4.8 | 5 | Cédric | 4.8 | 5 | False | | 2020-09-23T09:00:14.881983Z | 46 | 58822.jpg | 5.0 | Soares | 0.3 | False | None | a | 1 | 3 | 20 | 14320 | 5333 | 37197 | 495 | 1.0 | 4.3 | Cédric | 275 | 0 | 1 | 2 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | 3 | 71 | 53.6 | 65.7 | 10.0 | 12.9 | 354 | 139 | 240 | 58 | 373 | 140 | 349 | 125 | NaN | | NaN | | NaN | | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 645 NaN | NaN | 448487 | 0 | 0 | 0 | 0 | 0 | 1 | -0.5 | 0.0 | 0 | Andreas | 0.0 | 617 | False | | None | 40 | 448487.jpg | 0.0 | Söndergaard | 0.3 | False | None | a | 20 | 39 | 0 | 25127 | 1863 | 6802 | 841 | 0.0 | 0.0 | Söndergaard | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0.0 | 0.0 | 0.0 | 503 | 53 | 485 | 28 | 460 | 23 | 511 | 53 | NaN | | NaN | | NaN | | . 646 0.0 | NaN | 209353 | 0 | 0 | -1 | 1 | 0 | 4 | 0.0 | 0.5 | 0 | Patrick | 0.5 | 626 | False | Joined Valencia on loan until the end of the s... | 2021-01-31T20:00:27.142575Z | 59 | 209353.jpg | 1.0 | Cutrone | 0.0 | False | None | u | 20 | 39 | 2 | 3443 | 70 | 2779 | 390 | 0.1 | 0.3 | Cutrone | 23 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 5 | 0.0 | 0.0 | 4.0 | 0.2 | 644 | 81 | 645 | 82 | 398 | 61 | 470 | 63 | NaN | | NaN | | NaN | | . 647 NaN | NaN | 465551 | 0 | 0 | 0 | 0 | 0 | 2 | -0.5 | 0.0 | 0 | Nigel | 0.0 | 629 | False | | None | 40 | 465551.jpg | 0.0 | Lonwijk | 0.0 | False | None | a | 20 | 39 | 0 | 782 | 61 | 316 | 82 | 0.0 | 0.0 | Lonwijk | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0.0 | 0.0 | 0.0 | 506 | 195 | 488 | 195 | 463 | 181 | 514 | 195 | NaN | | NaN | | NaN | | . 648 100.0 | 100.0 | 73314 | 0 | 0 | 0 | 0 | 0 | 4 | 1.0 | 1.5 | 2 | Willian José | 1.5 | 642 | False | | 2021-01-26T14:00:25.113370Z | 70 | 73314.jpg | 1.5 | Da Silva | 0.2 | False | None | a | 20 | 39 | 3 | 14442 | 4740 | 2813 | 1510 | 0.2 | 0.4 | Willian José | 108 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 6 | 13.0 | 2.2 | 60.0 | 7.5 | 424 | 48 | 417 | 59 | 261 | 49 | 381 | 51 | NaN | | NaN | | NaN | | . 649 NaN | NaN | 490721 | 0 | 0 | 0 | 0 | 0 | 2 | 0.7 | 1.2 | 0 | Hugo | 0.0 | 649 | False | | None | 40 | 490721.jpg | 0.0 | Bueno | 0.0 | False | None | a | 20 | 39 | 0 | 80 | 80 | 12 | 12 | 0.0 | 0.0 | Bueno | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0.0 | 0.0 | 0.0 | 510 | 199 | 492 | 199 | 467 | 185 | 518 | 199 | NaN | | NaN | | NaN | | . 650 rows × 67 columns . . spi_data = pd.read_csv(&#39;https://projects.fivethirtyeight.com/soccer-api/club/spi_matches_latest.csv&#39;) spi_data=spi_data.loc[(spi_data[&#39;season&#39;]==2020) &amp; (spi_data[&#39;league&#39;]==&#39;Barclays Premier League&#39;)] #spi_data #Team mapping file team_mapping_spi=pd.read_csv(&#39;https://raw.githubusercontent.com/arpitsolanki/FPLBot/main/team_mapping.csv&#39;) #team_mapping_spi #Add team_ids to the 538 dataset to make it compatible with FPL API datasets spi_data_name=pd.merge(left=spi_data,right=team_mapping_spi,how=&#39;inner&#39;,left_on=&#39;team1&#39;,right_on=&#39;team&#39;) spi_data_name=spi_data_name.rename(columns={&quot;id&quot;: &quot;team1_id&quot;}) spi_data_name=pd.merge(left=spi_data_name,right=team_mapping_spi,how=&#39;inner&#39;,left_on=&#39;team2&#39;,right_on=&#39;team&#39;) spi_data_name=spi_data_name.rename(columns={&quot;id&quot;: &quot;team2_id&quot;}) #spi_data_name . players_df . chance_of_playing_next_round chance_of_playing_this_round code cost_change_event cost_change_event_fall cost_change_start cost_change_start_fall dreamteam_count element_type ep_next ep_this event_points first_name form id in_dreamteam news news_added now_cost photo points_per_game second_name selected_by_percent special squad_number status team team_code total_points transfers_in transfers_in_event transfers_out transfers_out_event value_form value_season web_name minutes goals_scored assists clean_sheets goals_conceded own_goals penalties_saved penalties_missed yellow_cards red_cards saves bonus bps influence creativity threat ict_index influence_rank influence_rank_type creativity_rank creativity_rank_type threat_rank threat_rank_type ict_index_rank ict_index_rank_type corners_and_indirect_freekicks_order corners_and_indirect_freekicks_text direct_freekicks_order direct_freekicks_text penalties_order penalties_text . 0 0.0 | 0.0 | 37605 | 0 | 0 | -3 | 3 | 0 | 3 | 0.0 | 0.0 | 0 | Mesut | 0.0 | 1 | False | Not included in Arsenal&#39;s 25-man Premier Leagu... | 2020-10-20T22:30:18.118477Z | 67 | 37605.jpg | 0.0 | Özil | 0.5 | False | None | u | 1 | 3 | 0 | 3441 | 0 | 53856 | 82 | 0.0 | 0.0 | Özil | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0.0 | 0.0 | 0.0 | 650 | 262 | 650 | 262 | 650 | 262 | 650 | 262 | NaN | | NaN | | NaN | | . 1 0.0 | 0.0 | 39476 | 0 | 0 | -2 | 2 | 0 | 2 | 0.0 | 0.0 | 0 | Sokratis | 0.0 | 2 | False | Left the club by mutual consent on 20/1 | 2020-10-21T10:30:18.546407Z | 48 | 39476.jpg | 0.0 | Papastathopoulos | 0.1 | False | None | u | 1 | 3 | 0 | 10266 | 0 | 18978 | 10 | 0.0 | 0.0 | Sokratis | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0.0 | 0.0 | 0.0 | 607 | 221 | 598 | 221 | 591 | 219 | 610 | 221 | NaN | | NaN | | NaN | | . 2 100.0 | 100.0 | 41270 | 0 | 0 | -1 | 1 | 0 | 2 | 5.3 | 4.8 | 6 | David | 4.8 | 3 | False | | 2020-12-26T18:00:15.638627Z | 54 | 41270.jpg | 2.3 | Luiz Moreira Marinho | 0.8 | False | None | a | 1 | 3 | 28 | 48380 | 3827 | 94758 | 660 | 0.9 | 5.2 | David Luiz | 839 | 0 | 0 | 3 | 10 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 143 | 132.8 | 30.4 | 86.0 | 24.9 | 256 | 98 | 318 | 106 | 212 | 58 | 289 | 98 | NaN | | 4.0 | | NaN | | . 3 75.0 | 50.0 | 54694 | 0 | 0 | -7 | 7 | 1 | 3 | 3.8 | 2.2 | 0 | Pierre-Emerick | 4.5 | 4 | False | Lack of match fitness - 75% chance of playing | 2021-01-23T16:00:22.555453Z | 113 | 54694.jpg | 4.2 | Aubameyang | 6.5 | False | None | d | 1 | 3 | 71 | 562692 | 1665 | 3258367 | 9740 | 0.4 | 6.3 | Aubameyang | 1514 | 5 | 1 | 7 | 16 | 1 | 0 | 0 | 2 | 0 | 0 | 6 | 202 | 272.2 | 226.3 | 519.0 | 101.8 | 133 | 51 | 80 | 57 | 27 | 14 | 42 | 28 | NaN | | NaN | | 1.0 | | . 4 100.0 | 100.0 | 58822 | 0 | 0 | -4 | 4 | 0 | 2 | 5.3 | 4.8 | 5 | Cédric | 4.8 | 5 | False | | 2020-09-23T09:00:14.881983Z | 46 | 58822.jpg | 5.0 | Soares | 0.3 | False | None | a | 1 | 3 | 20 | 14320 | 5333 | 37197 | 495 | 1.0 | 4.3 | Cédric | 275 | 0 | 1 | 2 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | 3 | 71 | 53.6 | 65.7 | 10.0 | 12.9 | 354 | 139 | 240 | 58 | 373 | 140 | 349 | 125 | NaN | | NaN | | NaN | | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 645 NaN | NaN | 448487 | 0 | 0 | 0 | 0 | 0 | 1 | -0.5 | 0.0 | 0 | Andreas | 0.0 | 617 | False | | None | 40 | 448487.jpg | 0.0 | Söndergaard | 0.3 | False | None | a | 20 | 39 | 0 | 25127 | 1863 | 6802 | 841 | 0.0 | 0.0 | Söndergaard | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0.0 | 0.0 | 0.0 | 503 | 53 | 485 | 28 | 460 | 23 | 511 | 53 | NaN | | NaN | | NaN | | . 646 0.0 | NaN | 209353 | 0 | 0 | -1 | 1 | 0 | 4 | 0.0 | 0.5 | 0 | Patrick | 0.5 | 626 | False | Joined Valencia on loan until the end of the s... | 2021-01-31T20:00:27.142575Z | 59 | 209353.jpg | 1.0 | Cutrone | 0.0 | False | None | u | 20 | 39 | 2 | 3443 | 70 | 2779 | 390 | 0.1 | 0.3 | Cutrone | 23 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 5 | 0.0 | 0.0 | 4.0 | 0.2 | 644 | 81 | 645 | 82 | 398 | 61 | 470 | 63 | NaN | | NaN | | NaN | | . 647 NaN | NaN | 465551 | 0 | 0 | 0 | 0 | 0 | 2 | -0.5 | 0.0 | 0 | Nigel | 0.0 | 629 | False | | None | 40 | 465551.jpg | 0.0 | Lonwijk | 0.0 | False | None | a | 20 | 39 | 0 | 782 | 61 | 316 | 82 | 0.0 | 0.0 | Lonwijk | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0.0 | 0.0 | 0.0 | 506 | 195 | 488 | 195 | 463 | 181 | 514 | 195 | NaN | | NaN | | NaN | | . 648 100.0 | 100.0 | 73314 | 0 | 0 | 0 | 0 | 0 | 4 | 1.0 | 1.5 | 2 | Willian José | 1.5 | 642 | False | | 2021-01-26T14:00:25.113370Z | 70 | 73314.jpg | 1.5 | Da Silva | 0.2 | False | None | a | 20 | 39 | 3 | 14442 | 4740 | 2813 | 1510 | 0.2 | 0.4 | Willian José | 108 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 6 | 13.0 | 2.2 | 60.0 | 7.5 | 424 | 48 | 417 | 59 | 261 | 49 | 381 | 51 | NaN | | NaN | | NaN | | . 649 NaN | NaN | 490721 | 0 | 0 | 0 | 0 | 0 | 2 | 0.7 | 1.2 | 0 | Hugo | 0.0 | 649 | False | | None | 40 | 490721.jpg | 0.0 | Bueno | 0.0 | False | None | a | 20 | 39 | 0 | 80 | 80 | 12 | 12 | 0.0 | 0.0 | Bueno | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0.0 | 0.0 | 0.0 | 510 | 199 | 492 | 199 | 467 | 185 | 518 | 199 | NaN | | NaN | | NaN | | . 650 rows × 67 columns . players_df_filtered=players_df[[&#39;web_name&#39;,&#39;element_type&#39;,&#39;now_cost&#39;,&#39;selected_by_percent&#39;,&#39;points_per_game&#39;,&#39;team&#39;,&#39;total_points&#39;,&#39;minutes&#39;,&#39;goals_scored&#39;,&#39;assists&#39;,&#39;clean_sheets&#39;,&#39;goals_conceded&#39;,&#39;yellow_cards&#39;,&#39;red_cards&#39;,&#39;bonus&#39;,&#39;chance_of_playing_next_round&#39;]] players_df_filtered=players_df_filtered.loc[players_df_filtered[&#39;minutes&#39;]&gt;300] players_df_filtered[&#39;now_cost_mil&#39;]=players_df_filtered[&#39;now_cost&#39;]/10 players_df_filtered[&#39;ppm&#39;]=players_df_filtered[&#39;total_points&#39;]/players_df_filtered[&#39;now_cost_mil&#39;] players_df_filtered.sort_values(by=&#39;ppm&#39;,ascending=False,inplace=True) . . teams_df_filtered=teams_df[[&#39;id&#39;,&#39;name&#39;,&#39;short_name&#39;,&#39;played&#39;,&#39;points&#39;,&#39;position&#39;,&#39;win&#39;,&#39;draw&#39;,&#39;loss&#39;]] teams_df_filtered_join=teams_df[[&#39;id&#39;,&#39;name&#39;]] . fixtures_df_name=pd.merge(left=fixtures_df,right=teams_df_filtered_join,left_on=&#39;team_a&#39;,right_on=&#39;id&#39;,how=&#39;left&#39;) fixtures_df_name=fixtures_df_name.rename(columns={&quot;name&quot;: &quot;away_team&quot;}) fixtures_df_name=pd.merge(left=fixtures_df_name,right=teams_df_filtered_join,left_on=&#39;team_h&#39;,right_on=&#39;id&#39;,how=&#39;left&#39;) fixtures_df_name=fixtures_df_name.rename(columns={&quot;name&quot;: &quot;home_team&quot;}) fixtures_df_name . code event finished finished_provisional id_x kickoff_time minutes provisional_start_time started team_a team_a_score team_h team_h_score stats team_h_difficulty team_a_difficulty pulse_id id_y away_team id home_team . 0 2128501 | 22 | False | False | 214 | 2021-02-02T18:00:00Z | 0 | False | False | 18 | None | 15 | None | [] | 2 | 2 | 59111 | 18 | West Brom | 15 | Sheffield Utd | . 1 2128502 | 22 | False | False | 215 | 2021-02-02T18:00:00Z | 0 | False | False | 1 | None | 20 | None | [] | 3 | 3 | 59112 | 1 | Arsenal | 20 | Wolves | . 2 2128500 | 22 | False | False | 213 | 2021-02-02T20:15:00Z | 0 | False | False | 16 | None | 13 | None | [] | 3 | 4 | 59110 | 16 | Southampton | 13 | Man Utd | . 3 2128504 | 22 | False | False | 217 | 2021-02-02T20:15:00Z | 0 | False | False | 6 | None | 14 | None | [] | 3 | 3 | 59114 | 6 | Crystal Palace | 14 | Newcastle | . 4 2128497 | 22 | False | False | 210 | 2021-02-03T18:00:00Z | 0 | False | False | 12 | None | 4 | None | [] | 4 | 2 | 59107 | 12 | Man City | 4 | Burnley | . 5 2128498 | 22 | False | False | 211 | 2021-02-03T18:00:00Z | 0 | False | False | 9 | None | 8 | None | [] | 4 | 2 | 59108 | 9 | Leicester | 8 | Fulham | . 6 2128499 | 22 | False | False | 212 | 2021-02-03T19:30:00Z | 0 | False | False | 7 | None | 10 | None | [] | 3 | 3 | 59109 | 7 | Everton | 10 | Leeds | . 7 2128496 | 22 | False | False | 209 | 2021-02-03T20:15:00Z | 0 | False | False | 19 | None | 2 | None | [] | 3 | 3 | 59106 | 19 | West Ham | 2 | Aston Villa | . 8 2128503 | 22 | False | False | 216 | 2021-02-03T20:15:00Z | 0 | False | False | 3 | None | 11 | None | [] | 2 | 5 | 59113 | 3 | Brighton | 11 | Liverpool | . 9 2128505 | 22 | False | False | 218 | 2021-02-04T20:00:00Z | 0 | False | False | 5 | None | 17 | None | [] | 4 | 4 | 59115 | 5 | Chelsea | 17 | Spurs | . df_l=[] for i in range(GW): fix_url = &#39;https://fantasy.premierleague.com/api/fixtures?event=&#39;+str(i+1) fix_response = requests.get(fix_url) fix_response = json.loads(fix_response.content) fixtures_df=pd.DataFrame(fix_response) fixtures_df[&#39;gw&#39;]=i+1 df_l.append(fixtures_df) # print(fix_url) fixtures_df = pd.concat(df_l, axis=0, ignore_index=True) fixtures_df_map=fixtures_df[[&#39;gw&#39;,&#39;kickoff_time&#39;]].copy() fixtures_df_map[&#39;date&#39;]=pd.to_datetime(fixtures_df_map[&#39;kickoff_time&#39;], errors=&#39;coerce&#39;).dt.date del fixtures_df_map[&#39;kickoff_time&#39;] fixtures_df_map=fixtures_df_map.drop_duplicates() #fixtures_df_map . fixtures_df_name_cur_gw=fixtures_df_name[[&#39;home_team&#39;,&#39;away_team&#39;,&#39;id&#39;,&#39;id_y&#39;]] fixtures_df_name_cur_gw.columns=[&#39;home_team&#39;,&#39;away_team&#39;,&#39;home_id&#39;,&#39;away_id&#39;] . spi_data_name_fil=spi_data_name[[&#39;team1&#39;,&#39;team2&#39;,&#39;team1_id&#39;,&#39;team2_id&#39;,&#39;proj_score1&#39;,&#39;proj_score2&#39;]] spi_data_name_fil.columns=[&#39;team1&#39;,&#39;team2&#39;,&#39;home_id&#39;,&#39;away_id&#39;,&#39;proj_score1&#39;,&#39;proj_score2&#39;] spi_gw_scores=pd.merge(left=fixtures_df_name_cur_gw,right=spi_data_name_fil,left_on=[&#39;home_id&#39;,&#39;away_id&#39;],right_on=[&#39;home_id&#39;,&#39;away_id&#39;],how=&#39;inner&#39;) . players_df_filtered_teams=pd.merge(left=players_df_filtered,right=teams_df_filtered_join,how=&#39;inner&#39;,left_on=&#39;team&#39;,right_on=&#39;id&#39;) #players_df_filtered_teams . team_list=[&#39;understat_Arsenal.csv&#39;,&#39;understat_Aston_Villa.csv&#39;,&#39;understat_Brighton.csv&#39;,&#39;understat_Burnley.csv&#39;,&#39;understat_Chelsea.csv&#39;,&#39;understat_Crystal_Palace.csv&#39;,&#39;understat_Everton.csv&#39;,&#39;understat_Fulham.csv&#39;,&#39;understat_Leeds.csv&#39;,&#39;understat_Leicester.csv&#39;,&#39;understat_Liverpool.csv&#39;,&#39;understat_Manchester_City.csv&#39;,&#39;understat_Manchester_United.csv&#39;,&#39;understat_Newcastle_United.csv&#39;,&#39;understat_Sheffield_United.csv&#39;,&#39;understat_Southampton.csv&#39;,&#39;understat_Tottenham.csv&#39;,&#39;understat_West_Bromwich_Albion.csv&#39;,&#39;understat_West_Ham.csv&#39;,&#39;understat_Wolverhampton_Wanderers.csv&#39;] static=&#39;https://raw.githubusercontent.com/vaastav/Fantasy-Premier-League/master/data/2020-21/understat/&#39; df_l=[] for i in range(20): k=static+team_list[i] temp=pd.read_csv(k) # print(temp.shape[0]) temp[&#39;team&#39;]=team_list[i] df_l.append(temp) team_total_data = pd.concat(df_l, axis=0, ignore_index=True) #team_total_data #team_mapping_spi team_total_data_id=pd.merge(left=team_total_data,right=team_mapping_spi,left_on=&#39;team&#39;,right_on=&#39;team_file_name&#39;,how=&#39;left&#39;) team_total_data_id team_total_data_id=team_total_data_id[[&#39;team_y&#39;,&#39;id&#39;,&#39;pts&#39;,&#39;date&#39;,&#39;h_a&#39;,&#39;xG&#39;,&#39;xGA&#39;,&#39;deep&#39;,&#39;deep_allowed&#39;,&#39;scored&#39;,&#39;missed&#39;]] # #team_total_data_id team_total_data_id[&#39;date_new&#39;]=pd.to_datetime(team_total_data_id[&#39;date&#39;], errors=&#39;coerce&#39;).dt.date del team_total_data_id[&#39;date&#39;] team_total_data_id[&#39;cum_pts&#39;]=team_total_data_id.groupby([&#39;team_y&#39;])[&#39;pts&#39;].cumsum() #team_total_data_id team_total_data_id_means = team_total_data_id.join(team_total_data_id.groupby([&#39;id&#39;]).expanding().agg({&#39;xG&#39;:&#39;mean&#39;,&#39;xGA&#39;: &#39;mean&#39;, &#39;deep&#39;: &#39;mean&#39;, &#39;deep_allowed&#39;: &#39;mean&#39;,&#39;scored&#39;:&#39;mean&#39;,&#39;missed&#39;:&#39;mean&#39;}) .reset_index(level=0, drop=True) .add_suffix(&#39;_roll&#39;)) team_total_data_id_means=team_total_data_id_means.groupby([&#39;id&#39;, &#39;date_new&#39;]).last().reset_index() team_total_data_id_means=team_total_data_id_means[[&#39;id&#39;,&#39;date_new&#39;,&#39;xG_roll&#39;,&#39;xGA_roll&#39;,&#39;deep_roll&#39;,&#39;deep_allowed_roll&#39;,&#39;scored_roll&#39;,&#39;missed_roll&#39;]] team_total_data_id_means #Create a league standings table team_total_data_id=pd.merge(left=team_total_data_id,right=fixtures_df_map,left_on=&#39;date_new&#39;,right_on=&#39;date&#39;,how=&#39;inner&#39;) team_total_data_id.sort_values(by=&#39;cum_pts&#39;,inplace=True,ascending=False) team_total_data_id=team_total_data_id[[&#39;cum_pts&#39;,&#39;gw&#39;,&#39;id&#39;,&#39;date_new&#39;]] team_total_data_id[&quot;rank&quot;] = team_total_data_id.groupby(&quot;gw&quot;)[&quot;cum_pts&quot;].rank(&quot;dense&quot;, ascending=False) team_total_data_id.columns=[&#39;cum_pts&#39;,&#39;gw&#39;,&#39;id&#39;,&#39;date_new&#39;,&#39;rank&#39;] #team_total_data_id team_total_data_id=pd.merge(left=team_total_data_id,right=team_total_data_id_means,left_on=[&#39;id&#39;,&#39;date_new&#39;],right_on=[&#39;id&#39;,&#39;date_new&#39;],how=&#39;inner&#39;) del team_total_data_id[&#39;date_new&#39;] team_total_data_id[&#39;xG_diff&#39;]=team_total_data_id[&#39;xG_roll&#39;]-team_total_data_id[&#39;xGA_roll&#39;] team_total_data_id[&#39;deep_diff&#39;]=team_total_data_id[&#39;deep_roll&#39;]/(team_total_data_id[&#39;deep_roll&#39;]+team_total_data_id[&#39;deep_allowed_roll&#39;]) team_total_data_id[&#39;scored_diff&#39;]=team_total_data_id[&#39;scored_roll&#39;]/(team_total_data_id[&#39;scored_roll&#39;]+team_total_data_id[&#39;missed_roll&#39;]) team_total_data_id=team_total_data_id[[&#39;cum_pts&#39;,&#39;gw&#39;,&#39;id&#39;,&#39;rank&#39;,&#39;xG_diff&#39;,&#39;deep_diff&#39;,&#39;scored_diff&#39;]] team_total_data_id #team_total_data_id.to_csv(&#39;team_total_data_id.csv&#39;) #files.download(&#39;team_total_data_id.csv&#39;) . cum_pts gw id rank xG_diff deep_diff scored_diff . 0 44 | 21 | 12 | 1.0 | 1.294208 | 0.750865 | 0.740000 | . 1 41 | 21 | 13 | 2.0 | 0.455679 | 0.614094 | 0.578125 | . 2 41 | 20 | 12 | 1.0 | 1.289870 | 0.761733 | 0.734694 | . 3 40 | 20 | 13 | 2.0 | 0.440155 | 0.607639 | 0.578125 | . 4 40 | 21 | 11 | 3.0 | 0.805659 | 0.804217 | 0.641791 | . ... ... | ... | ... | ... | ... | ... | ... | . 405 0 | 2 | 4 | 3.0 | 0.536675 | 0.300000 | 0.333333 | . 406 0 | 4 | 4 | 8.0 | -0.446754 | 0.510204 | 0.272727 | . 407 0 | 2 | 16 | 3.0 | -0.067990 | 0.818182 | 0.250000 | . 408 0 | 1 | 18 | 2.0 | -2.602813 | 0.666667 | 0.000000 | . 409 0 | 3 | 15 | 6.0 | -0.184315 | 0.511111 | 0.000000 | . 410 rows × 7 columns . #gw_list=[&#39;gw1&#39;,&#39;gw2&#39;,&#39;gw3&#39;,&#39;gw4&#39;,&#39;gw5&#39;,&#39;gw6&#39;,&#39;gw7&#39;,&#39;gw8&#39;,&#39;gw9&#39;,&#39;gw10&#39;,&#39;gw11&#39;,&#39;gw12&#39;,&#39;gw13&#39;,&#39;gw14&#39;,&#39;gw15&#39;] gw_list=[] for i in range(GW-1): gw_str=&#39;gw&#39;+str(i+1) gw_list.append(gw_str) print(gw_list) static=&#39;https://raw.githubusercontent.com/vaastav/Fantasy-Premier-League/master/data/2020-21/gws/&#39; df_l=[] for i in range(len(gw_list)): k=static+gw_list[i]+&#39;.csv&#39; temp=pd.read_csv(k) temp[&#39;gw&#39;]=i+1 df_l.append(temp) # print(k) weekly_data = pd.concat(df_l, axis=0, ignore_index=True) #weekly_data weekly_data_team=pd.merge(left=weekly_data,right=teams_df_filtered_join,left_on=&#39;opponent_team&#39;,right_on=&#39;id&#39;,how=&#39;inner&#39;) weekly_data_team=weekly_data_team.rename(columns={&quot;name_y&quot;: &quot;opponent_team_name&quot;}) weekly_data_team=pd.merge(left=weekly_data_team,right=teams_df_filtered_join,left_on=&#39;team&#39;,right_on=&#39;name&#39;,how=&#39;inner&#39;) weekly_data_team=weekly_data_team.rename(columns={&quot;name_x&quot;: &quot;player_name&quot;,&#39;id_y&#39;:&#39;team_id&#39;}) #weekly_data_team . [&#39;gw1&#39;, &#39;gw2&#39;, &#39;gw3&#39;, &#39;gw4&#39;, &#39;gw5&#39;, &#39;gw6&#39;, &#39;gw7&#39;, &#39;gw8&#39;, &#39;gw9&#39;, &#39;gw10&#39;, &#39;gw11&#39;, &#39;gw12&#39;, &#39;gw13&#39;, &#39;gw14&#39;, &#39;gw15&#39;, &#39;gw16&#39;, &#39;gw17&#39;, &#39;gw18&#39;, &#39;gw19&#39;, &#39;gw20&#39;, &#39;gw21&#39;] . weekly_data_team.gw.max() . 21 . #Add the home and away team columns weekly_data_team[&#39;home_team&#39;] = weekly_data_team[&#39;team_id&#39;] weekly_data_team[&#39;away_team&#39;] = weekly_data_team[&#39;team_id&#39;] weekly_data_team.loc[weekly_data_team[&#39;was_home&#39;] == True, &#39;home_team&#39;] = weekly_data_team.loc[weekly_data_team[&#39;was_home&#39;] == True, &#39;team_id&#39;] weekly_data_team.loc[weekly_data_team[&#39;was_home&#39;] == True, &#39;away_team&#39;] = weekly_data_team.loc[weekly_data_team[&#39;was_home&#39;] == True, &#39;opponent_team&#39;] weekly_data_team.loc[weekly_data_team[&#39;was_home&#39;] == False, &#39;home_team&#39;] = weekly_data_team.loc[weekly_data_team[&#39;was_home&#39;] == False, &#39;opponent_team&#39;] weekly_data_team.loc[weekly_data_team[&#39;was_home&#39;] == False, &#39;away_team&#39;] = weekly_data_team.loc[weekly_data_team[&#39;was_home&#39;] == False, &#39;team_id&#39;] #weekly_data_team weekly_data_team_spi=pd.merge(left=weekly_data_team,right=spi_data_name_fil,left_on=[&#39;home_team&#39;,&#39;away_team&#39;],right_on=[&#39;home_id&#39;,&#39;away_id&#39;],how=&#39;inner&#39;) weekly_data_team_spi #Weekly data remove players who haven&#39;t started yet zero_min=weekly_data_team_spi.groupby([&#39;player_name&#39;,]).agg({&#39;minutes&#39;:&#39;sum&#39;}).reset_index() zero_min=zero_min.loc[zero_min[&#39;minutes&#39;]==0] #zero_min #weekly_data_team_spi.player_name.isin(zero_min[&#39;player_name&#39;]).sum() weekly_data_team_spi_zero=weekly_data_team_spi[~(weekly_data_team_spi.player_name.isin(zero_min[&#39;player_name&#39;]))] # weekly_data_team_spi_zero[&#39;team_id&#39;]=0 # weekly_data_team_spi_zero.loc[:,&#39;team_id&#39;]=weekly_data_team_spi_zero.loc[weekly_data_team_spi_zero[&#39;was_home&#39;]=True,&#39;home_team&#39;] #weekly_data_team_spi_zero . gp=weekly_data.groupby([&#39;name&#39;,&#39;gw&#39;]).agg({&#39;total_points&#39;:&#39;sum&#39;}).reset_index() gp.sort_values(by=&#39;total_points&#39;,ascending=False) . name gw total_points . 5866 John Stones | 19 | 27 | . 4677 Jack Grealish | 4 | 24 | . 4391 Heung-Min Son | 2 | 24 | . 7880 Matheus Pereira | 19 | 24 | . 9798 Riyad Mahrez | 10 | 21 | . ... ... | ... | ... | . 127 Aboubakar Kamara | 6 | -2 | . 3399 Erik Pieters | 2 | -2 | . 7311 Luke Shaw | 4 | -2 | . 662 Andreas Christensen | 2 | -3 | . 6778 Kieran Gibbs | 2 | -4 | . 11984 rows × 3 columns . gp=weekly_data_team_spi_zero.groupby([&#39;total_points&#39;]).size().reset_index(name=&#39;counts&#39;) #gp.sort_values(by=&#39;counts&#39;,ascending=False) fig=px.bar(gp,x=&#39;total_points&#39;,y=&#39;counts&#39;,title=&#39;Distribution of points scored in gameweek by players&#39;) fig.show() . . . weekly_data_team_spi_zero[&#39;point_flag&#39;]=0 weekly_data_team_spi_zero.loc[weekly_data_team_spi_zero[&#39;total_points&#39;]&gt;2,&#39;point_flag&#39;]=1 #weekly_data_team_spi_zero gp=weekly_data_team_spi_zero.groupby([&#39;position&#39;,&#39;point_flag&#39;]).size().reset_index(name=&#39;counts&#39;) gp fig = make_subplots(rows=1, cols=4,specs=[[{&#39;type&#39;:&#39;domain&#39;}, {&#39;type&#39;:&#39;domain&#39;},{&#39;type&#39;:&#39;domain&#39;},{&#39;type&#39;:&#39;domain&#39;}]],subplot_titles=(&quot;GK&quot;,&quot;DEF&quot;,&quot;MID&quot;,&quot;FWD&quot;)) fig.add_trace(go.Pie(labels=gp.loc[gp[&#39;position&#39;]==&#39;GK&#39;,&#39;point_flag&#39;], values=gp.loc[gp[&#39;position&#39;]==&#39;GK&#39;,&#39;counts&#39;], name=&quot;GK&quot;),1, 1) fig.add_trace(go.Pie(labels=gp.loc[gp[&#39;position&#39;]==&#39;DEF&#39;,&#39;point_flag&#39;], values=gp.loc[gp[&#39;position&#39;]==&#39;DEF&#39;,&#39;counts&#39;], name=&quot;DEF&quot;),1, 2) fig.add_trace(go.Pie(labels=gp.loc[gp[&#39;position&#39;]==&#39;MID&#39;,&#39;point_flag&#39;], values=gp.loc[gp[&#39;position&#39;]==&#39;MID&#39;,&#39;counts&#39;], name=&quot;MID&quot;),1, 3) fig.add_trace(go.Pie(labels=gp.loc[gp[&#39;position&#39;]==&#39;FWD&#39;,&#39;point_flag&#39;], values=gp.loc[gp[&#39;position&#39;]==&#39;FWD&#39;,&#39;counts&#39;], name=&quot;FW&quot;),1, 4) fig.update_traces(hole=.4, hoverinfo=&quot;label+percent+name&quot;) fig.update_layout( title_text=&quot;Points Distribution by Position&quot;) fig.show() . /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy /usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy . . . . player_summary=weekly_data_team_spi_zero[[&#39;player_name&#39;,&#39;round&#39;,&#39;team_id&#39;,&#39;total_points&#39;]] team_gp=player_summary.groupby([&#39;team_id&#39;,&#39;round&#39;]).agg({&#39;total_points&#39;:&#39;sum&#39;}).reset_index() team_gp.columns=[&#39;team_id&#39;,&#39;round&#39;,&#39;team_total_points&#39;] team_gp team_gp[&#39;team_total_points_cumsum&#39;] = team_gp.groupby([&#39;team_id&#39;])[&#39;team_total_points&#39;].cumsum() team_gp del team_gp[&#39;team_total_points&#39;] # team_player_gp=player_summary.groupby([&#39;team_id&#39;,&#39;player_name&#39;,&#39;round&#39;]).agg({&#39;total_points&#39;:&#39;sum&#39;}).reset_index() # team_player_gp.columns=[&#39;team_id&#39;,&#39;player_name&#39;,&#39;round&#39;,&#39;team_total_points&#39;] # team_player_gp # from google.colab import files # team_player_gp.to_csv(&#39;team_player_gp.csv&#39;) # files.download(&#39;team_player_gp.csv&#39;) . weekly_data_subset=weekly_data_team_spi_zero[[&#39;player_name&#39;,&#39;gw&#39;,&#39;position&#39;,&#39;team&#39;,&#39;round&#39;,&#39;id_x&#39;,&#39;team_id&#39;,&#39;xP&#39;,&#39;assists&#39;,&#39;bonus&#39;,&#39;clean_sheets&#39;,&#39;goals_scored&#39;,&#39;goals_conceded&#39;,&#39;minutes&#39;,&#39;creativity&#39;,&#39;ict_index&#39;,&#39;influence&#39;,&#39;selected&#39;,&#39;threat&#39;,&#39;yellow_cards&#39;,&#39;red_cards&#39;,&#39;was_home&#39;,&#39;home_team&#39;,&#39;away_team&#39;,&#39;proj_score1&#39;,&#39;proj_score2&#39;,&#39;total_points&#39;,&#39;point_flag&#39;]] weekly_data_subset=weekly_data_subset.rename(columns={&quot;id_x&quot;: &quot;opponent_id&quot;}) #Weekly Cumulative sums for last four weeks weekly_data_subset.sort_values(by=[&#39;player_name&#39;,&#39;gw&#39;],ascending=True,inplace=True) gp_cols=weekly_data_subset[[&#39;player_name&#39;,&#39;gw&#39;,&#39;red_cards&#39;,&#39;yellow_cards&#39;,&#39;xP&#39;,&#39;total_points&#39;,&#39;bonus&#39;,&#39;clean_sheets&#39;,&#39;assists&#39;,&#39;minutes&#39;,&#39;influence&#39;,&#39;creativity&#39;,&#39;threat&#39;,&#39;ict_index&#39;]] #gp_cols=gp_cols.loc[gp_cols.gw&gt;=GW-4] gp_cumsum=gp_cols.groupby([&#39;player_name&#39;,&#39;gw&#39;]).sum().groupby(&#39;player_name&#39;).cumsum().reset_index() #Season rolling numbers #Weekly Mean Sums weekly_rolling_means = weekly_data_subset.join(weekly_data_subset.groupby([&#39;player_name&#39;]).expanding().agg({&#39;minutes&#39;:&#39;mean&#39;,&#39;influence&#39;: &#39;mean&#39;, &#39;creativity&#39;: &#39;mean&#39;, &#39;threat&#39;: &#39;mean&#39;,&#39;ict_index&#39;:&#39;mean&#39;,&#39;selected&#39;:&#39;mean&#39;,&#39;total_points&#39;:&#39;mean&#39;}) .reset_index(level=0, drop=True) .add_suffix(&#39;_roll&#39;)) weekly_rolling_means=weekly_rolling_means.groupby([&#39;round&#39;, &#39;player_name&#39;]).last().reset_index() weekly_rolling_means=weekly_rolling_means[[&#39;player_name&#39;,&#39;gw&#39;,&#39;influence_roll&#39;, &#39;creativity_roll&#39;, &#39;threat_roll&#39;,&#39;ict_index_roll&#39;,&#39;minutes_roll&#39;,&#39;selected_roll&#39;,&#39;total_points_roll&#39;]] weekly_data_subset_new=weekly_data_subset[[&#39;player_name&#39;,&#39;gw&#39;,&#39;position&#39;,&#39;team&#39;,&#39;round&#39;,&#39;team_id&#39;,&#39;opponent_id&#39;,&#39;was_home&#39;,&#39;home_team&#39;,&#39;away_team&#39;,&#39;proj_score1&#39;,&#39;proj_score2&#39;,&#39;point_flag&#39;]].copy() weekly_data_subset_new[&#39;join_key&#39;]=0 gw=weekly_data_subset_new[&#39;gw&#39;] weekly_data_subset_new.loc[:,&#39;join_key&#39;]=gw-1 #Merge cumulative sums weekly_data_subset_new_agg=pd.merge(left=weekly_data_subset_new,right=weekly_rolling_means,left_on=[&#39;player_name&#39;,&#39;join_key&#39;],right_on=[&#39;player_name&#39;,&#39;gw&#39;],how=&#39;inner&#39;) #Merge cumulative means weekly_data_subset_new_agg=pd.merge(left=weekly_data_subset_new_agg,right=gp_cumsum,left_on=[&#39;player_name&#39;,&#39;join_key&#39;],right_on=[&#39;player_name&#39;,&#39;gw&#39;],how=&#39;inner&#39;) #Merge team total ranking stats with home team weekly_data_subset_new_agg_home=pd.merge(left=weekly_data_subset_new_agg,right=team_total_data_id,left_on=[&#39;team_id&#39;,&#39;join_key&#39;],right_on=[&#39;id&#39;,&#39;gw&#39;]) weekly_data_subset_new_agg_home=weekly_data_subset_new_agg_home.rename(columns={&quot;rank&quot;: &quot;team_rank&quot;,&#39;cum_pts&#39;:&#39;team_pts&#39;,&#39;xG_diff&#39;:&#39;xG_diff_team&#39;,&#39;scored_diff&#39;:&#39;scored_diff_team&#39;,&#39;deep_diff&#39;:&#39;deep_diff_team&#39;}) #Merge team total ranking stats with away team weekly_data_subset_new_agg_pts=pd.merge(left=weekly_data_subset_new_agg_home,right=team_total_data_id,left_on=[&#39;opponent_id&#39;,&#39;join_key&#39;],right_on=[&#39;id&#39;,&#39;gw&#39;]) weekly_data_subset_new_agg_pts=weekly_data_subset_new_agg_pts.rename(columns={&quot;rank&quot;: &quot;opponent_rank&quot;,&#39;cum_pts&#39;:&#39;opponent_points&#39;,&#39;xG_diff&#39;:&#39;xG_diff_opponent&#39;,&#39;scored_diff&#39;:&#39;scored_diff_opponent&#39;,&#39;deep_diff&#39;:&#39;deep_diff_opponent&#39;}) #Calculate rank and projected score differences for the upcoming fixture weekly_data_subset_new_agg_pts[&#39;rank_diff&#39;]=weekly_data_subset_new_agg_pts[&#39;team_rank&#39;]-weekly_data_subset_new_agg_pts[&#39;opponent_rank&#39;] weekly_data_subset_new_agg_pts[&#39;proj_score_diff&#39;]=weekly_data_subset_new_agg_pts[&#39;proj_score1&#39;]-weekly_data_subset_new_agg_pts[&#39;proj_score2&#39;] #Merge team total ranking stats with away team weekly_data_subset_new_agg_pts_team=pd.merge(left=weekly_data_subset_new_agg_pts,right=team_gp,left_on=[&#39;team_id&#39;,&#39;join_key&#39;],right_on=[&#39;team_id&#39;,&#39;round&#39;],how=&#39;inner&#39;) weekly_data_subset_new_agg_pts_team[&#39;percent_team_points&#39;]=weekly_data_subset_new_agg_pts_team[&#39;total_points&#39;]/weekly_data_subset_new_agg_pts_team[&#39;team_total_points_cumsum&#39;] # ##del weekly_data_subset_new_agg_pts[&#39;gw&#39;] del weekly_data_subset_new_agg_pts_team[&#39;gw_y&#39;] del weekly_data_subset_new_agg_pts_team[&#39;gw_x&#39;] del weekly_data_subset_new_agg_pts_team[&#39;id_x&#39;] del weekly_data_subset_new_agg_pts_team[&#39;id_y&#39;] del weekly_data_subset_new_agg_pts_team[&#39;join_key&#39;] del weekly_data_subset_new_agg_pts_team[&#39;team_id&#39;] del weekly_data_subset_new_agg_pts_team[&#39;opponent_id&#39;] weekly_data_subset_new_agg_pts_team #weekly_data_subset_new_agg_pts_team.to_csv(&#39;weekly_data_subset_new_agg_pts_team.csv&#39;) #files.download(&#39;weekly_data_subset_new_agg_pts_team.csv&#39;) . player_name position team round_x was_home home_team away_team proj_score1 proj_score2 point_flag influence_roll creativity_roll threat_roll ict_index_roll minutes_roll selected_roll total_points_roll red_cards yellow_cards xP total_points bonus clean_sheets assists minutes influence creativity threat ict_index team_pts team_rank xG_diff_team deep_diff_team scored_diff_team opponent_points gw opponent_rank xG_diff_opponent deep_diff_opponent scored_diff_opponent rank_diff proj_score_diff round_y team_total_points_cumsum percent_team_points . 0 Aaron Connolly | FWD | Brighton | 2 | False | 14 | 3 | 1.28 | 1.13 | 1 | 1.2 | 0.30 | 32.0 | 3.40 | 45.0 | 32205.0 | 1.0 | 0 | 0 | 0.5 | 1 | 0 | 0 | 0 | 45 | 1.2 | 0.3 | 32.0 | 3.4 | 0 | 2.0 | 0.172190 | 0.333333 | 0.25 | 3 | 1 | 1.0 | 0.797665 | 0.666667 | 1.0 | 1.0 | 0.15 | 1 | 27 | 0.037037 | . 1 Adam Lallana | MID | Brighton | 2 | False | 14 | 3 | 1.28 | 1.13 | 0 | 6.8 | 27.20 | 2.0 | 3.60 | 44.0 | 78657.0 | 1.0 | 0 | 0 | 1.2 | 1 | 0 | 0 | 0 | 44 | 6.8 | 27.2 | 2.0 | 3.6 | 0 | 2.0 | 0.172190 | 0.333333 | 0.25 | 3 | 1 | 1.0 | 0.797665 | 0.666667 | 1.0 | 1.0 | 0.15 | 1 | 27 | 0.037037 | . 2 Adam Webster | DEF | Brighton | 2 | False | 14 | 3 | 1.28 | 1.13 | 1 | 14.8 | 11.80 | 1.0 | 2.80 | 90.0 | 187445.0 | 1.0 | 0 | 0 | 0.6 | 1 | 0 | 0 | 0 | 90 | 14.8 | 11.8 | 1.0 | 2.8 | 0 | 2.0 | 0.172190 | 0.333333 | 0.25 | 3 | 1 | 1.0 | 0.797665 | 0.666667 | 1.0 | 1.0 | 0.15 | 1 | 27 | 0.037037 | . 3 Alexis Mac Allister | MID | Brighton | 2 | False | 14 | 3 | 1.28 | 1.13 | 0 | 0.0 | 0.00 | 0.0 | 0.00 | 0.0 | 3939.0 | 0.0 | 0 | 0 | 0.8 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0.0 | 0.0 | 0.0 | 0 | 2.0 | 0.172190 | 0.333333 | 0.25 | 3 | 1 | 1.0 | 0.797665 | 0.666667 | 1.0 | 1.0 | 0.15 | 1 | 27 | 0.000000 | . 4 Alireza Jahanbakhsh | MID | Brighton | 2 | False | 14 | 3 | 1.28 | 1.13 | 0 | 4.4 | 0.70 | 0.0 | 0.50 | 11.0 | 3104.0 | 1.0 | 0 | 0 | 0.8 | 1 | 0 | 0 | 0 | 11 | 4.4 | 0.7 | 0.0 | 0.5 | 0 | 2.0 | 0.172190 | 0.333333 | 0.25 | 3 | 1 | 1.0 | 0.797665 | 0.666667 | 1.0 | 1.0 | 0.15 | 1 | 27 | 0.037037 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 8545 Patrick Bamford | FWD | Leeds | 3 | False | 15 | 10 | 1.40 | 1.05 | 1 | 45.2 | 6.20 | 24.0 | 7.55 | 65.0 | 489813.0 | 10.5 | 0 | 0 | 10.6 | 21 | 3 | 0 | 2 | 130 | 90.4 | 12.4 | 48.0 | 15.1 | 3 | 2.0 | -1.493399 | 0.233333 | 0.50 | 0 | 2 | 3.0 | -0.309657 | 0.375000 | 0.0 | -1.0 | 0.35 | 2 | 92 | 0.228261 | . 8546 Robin Koch | DEF | Leeds | 3 | False | 15 | 10 | 1.40 | 1.05 | 1 | 17.9 | 0.25 | 19.5 | 3.80 | 90.0 | 36835.0 | 0.5 | 0 | 0 | 0.6 | 1 | 0 | 0 | 0 | 180 | 35.8 | 0.5 | 39.0 | 7.6 | 3 | 2.0 | -1.493399 | 0.233333 | 0.50 | 0 | 2 | 3.0 | -0.309657 | 0.375000 | 0.0 | -1.0 | 0.35 | 2 | 92 | 0.010870 | . 8547 Rodrigo Moreno | FWD | Leeds | 3 | False | 15 | 10 | 1.40 | 1.05 | 0 | 0.0 | 0.50 | 2.0 | 0.25 | 36.5 | 467745.0 | 1.0 | 0 | 0 | 1.3 | 2 | 0 | 0 | 0 | 73 | 0.0 | 1.0 | 4.0 | 0.5 | 3 | 2.0 | -1.493399 | 0.233333 | 0.50 | 0 | 2 | 3.0 | -0.309657 | 0.375000 | 0.0 | -1.0 | 0.35 | 2 | 92 | 0.021739 | . 8548 Stuart Dallas | DEF | Leeds | 3 | False | 15 | 10 | 1.40 | 1.05 | 1 | 22.2 | 2.50 | 3.0 | 2.80 | 90.0 | 307651.0 | 2.0 | 0 | 0 | 2.1 | 4 | 0 | 0 | 1 | 180 | 44.4 | 5.0 | 6.0 | 5.6 | 3 | 2.0 | -1.493399 | 0.233333 | 0.50 | 0 | 2 | 3.0 | -0.309657 | 0.375000 | 0.0 | -1.0 | 0.35 | 2 | 92 | 0.043478 | . 8549 Tyler Roberts | MID | Leeds | 3 | False | 15 | 10 | 1.40 | 1.05 | 0 | 6.3 | 7.60 | 5.5 | 1.95 | 36.5 | 5330.5 | 1.0 | 0 | 0 | 0.9 | 2 | 0 | 0 | 0 | 73 | 12.6 | 15.2 | 11.0 | 3.9 | 3 | 2.0 | -1.493399 | 0.233333 | 0.50 | 0 | 2 | 3.0 | -0.309657 | 0.375000 | 0.0 | -1.0 | 0.35 | 2 | 92 | 0.021739 | . 8550 rows × 45 columns . # #weekly_data_subset # weekly_rolling_means = weekly_data_subset.join(weekly_data_subset.groupby([&#39;player_name&#39;]).expanding().agg({&#39;minutes&#39;:&#39;mean&#39;,&#39;influence&#39;: &#39;mean&#39;, &#39;creativity&#39;: &#39;mean&#39;, &#39;threat&#39;: &#39;mean&#39;,&#39;ict_index&#39;:&#39;mean&#39;}) # .reset_index(level=0, drop=True) # .add_suffix(&#39;_roll&#39;)) # weekly_rolling_means=weekly_rolling_means.groupby([&#39;round&#39;, &#39;player_name&#39;]).last().reset_index() # weekly_rolling_means=weekly_rolling_means[[&#39;player_name&#39;,&#39;gw&#39;,&#39;influence_roll&#39;, &#39;creativity_roll&#39;, &#39;threat_roll&#39;,&#39;ict_index_roll&#39;,&#39;minutes_roll&#39;]] # weekly_rolling_means # # k.to_csv(&#39;k.csv&#39;) # # files.download(&#39;k.csv&#39;) gp_cumsum . player_name gw red_cards yellow_cards xP total_points bonus clean_sheets assists minutes influence creativity threat ict_index . 0 Aaron Connolly | 1 | 0 | 0 | 0.5 | 1 | 0 | 0 | 0 | 45 | 1.2 | 0.3 | 32.0 | 3.4 | . 1 Aaron Connolly | 2 | 0 | 0 | 4.5 | 9 | 2 | 1 | 0 | 134 | 36.0 | 11.6 | 55.0 | 10.3 | . 2 Aaron Connolly | 3 | 0 | 0 | 7.2 | 11 | 2 | 1 | 0 | 207 | 36.0 | 23.7 | 63.0 | 12.2 | . 3 Aaron Connolly | 4 | 0 | 0 | 9.9 | 13 | 2 | 1 | 0 | 272 | 39.0 | 24.0 | 67.0 | 12.9 | . 4 Aaron Connolly | 5 | 0 | 0 | 12.9 | 17 | 2 | 1 | 1 | 284 | 56.2 | 34.3 | 69.0 | 15.9 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 9178 Çaglar Söyüncü | 16 | 0 | 1 | 12.4 | 8 | 0 | 1 | 0 | 360 | 83.4 | 24.6 | 44.0 | 15.2 | . 9179 Çaglar Söyüncü | 17 | 0 | 1 | 13.1 | 9 | 0 | 1 | 0 | 371 | 83.4 | 24.6 | 46.0 | 15.4 | . 9180 Çaglar Söyüncü | 19 | 0 | 1 | 15.7 | 10 | 0 | 1 | 0 | 408 | 91.6 | 24.7 | 46.0 | 16.2 | . 9181 Çaglar Söyüncü | 20 | 0 | 1 | 17.0 | 11 | 0 | 1 | 0 | 421 | 98.4 | 25.1 | 46.0 | 16.9 | . 9182 Çaglar Söyüncü | 21 | 0 | 1 | 18.1 | 11 | 0 | 1 | 0 | 466 | 104.0 | 35.6 | 50.0 | 18.9 | . 9183 rows × 14 columns . labelencoder = LabelEncoder() weekly_data_subset_new_agg_pts_team[&#39;position_flag&#39;] = labelencoder.fit_transform(weekly_data_subset_new_agg_pts_team[&#39;position&#39;]) cols = pd.get_dummies(weekly_data_subset_new_agg_pts_team[&#39;position_flag&#39;]) cols.columns = [&#39;pos_0&#39;,&#39;pos_1&#39;,&#39;pos_2&#39;,&#39;pos_3&#39;] weekly_data_subset_new_agg_pts_team1 = pd.concat([weekly_data_subset_new_agg_pts_team, cols], axis=1) #weekly_data_subset_new_agg_pts_team1 . weekly_data_subset_new_agg_pts_team2=weekly_data_subset_new_agg_pts_team1.copy() X=weekly_data_subset_new_agg_pts_team1.copy() #Y=weekly_data_subset_new_agg[&#39;point_flag&#39;] del X[&#39;player_name&#39;] del X[&#39;position&#39;] del X[&#39;team&#39;] #del X[&#39;total_points&#39;] #X_train,X_test,Y_train,Y_test=train_test_split(X, Y,test_size=0.3,random_state=1) max_gw=X[&#39;round_x&#39;].max() print(max_gw) #max_gw=14 X_train=X.loc[X[&#39;round_x&#39;]&lt;max_gw] X_test=X.loc[X[&#39;round_x&#39;]==max_gw] Y_train=X_train[&#39;point_flag&#39;] Y_test=X_test[&#39;point_flag&#39;] del X_train[&#39;point_flag&#39;] del X_test[&#39;point_flag&#39;] del X_train[&#39;round_x&#39;] del X_test[&#39;round_x&#39;] del X_train[&#39;round_y&#39;] del X_test[&#39;round_y&#39;] . 21 . . from sklearn.model_selection import cross_val_score from sklearn.model_selection import RepeatedStratifiedKFold model_rf = RandomForestClassifier(n_estimators=100,max_depth=7, random_state=0,min_samples_split=5) #class_weight=&#39;balanced_subsample&#39; model_rf.fit(X_train,Y_train)#Fitting the model #Generating predictions from Random Fores Models pred_rf=model_rf.predict(X_test) pred_rf_proba=model_rf.predict_proba(X_test) feat_importances = pd.Series(model_rf.feature_importances_, index=X_train.columns) feat_importances=feat_importances.sort_values() feat_importances.plot(kind=&#39;barh&#39;,figsize=(16,16))#Plotting feature importance print(&#39;Model Accuracy&#39;) print(model_rf.score(X_test,Y_test)) . Model Accuracy 0.7873684210526316 . import statistics cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1) # evaluate model scores = cross_val_score(model_rf, X_train, Y_train, scoring=&#39;roc_auc&#39;, cv=cv, n_jobs=-1) # summarize performance print(&#39;Mean ROC AUC: %.3f&#39; % statistics.mean(scores)) . Mean ROC AUC: 0.791 . import plotly.express as px import matplotlib.pyplot as plt def plot_hist(pred): plt.hist(pred[:,1], density=True, bins=30) # density=False would make counts plt.ylabel(&#39;Probability&#39;) plt.xlabel(&#39;Data&#39;) plot_hist(pred_rf_proba) print(pred_rf_proba[:,1].mean()) . 0.2283340878113225 . calc_pred=pred_rf_proba[:,1]&gt;0.16 calc_pred=calc_pred.astype(int) conf_mat = confusion_matrix(Y_test, calc_pred) df_confusion = pd.crosstab(Y_test, calc_pred, rownames=[&#39;Actual&#39;], colnames=[&#39;Predicted&#39;], margins=True) print (df_confusion) #print(conf_mat) # Visualize it as a heatmap import seaborn import matplotlib.pyplot as plt seaborn.heatmap(conf_mat) plt.show() FP = conf_mat.sum(axis=0) - np.diag(conf_mat) FN = conf_mat.sum(axis=1) - np.diag(conf_mat) TP = np.diag(conf_mat) TN = conf_mat.sum() - (FP + FN + TP) TPR = TP/(TP+FN) print(&quot;True Positive Rate&quot;,TPR) . Predicted 0 1 All Actual 0 190 186 376 1 13 86 99 All 203 272 475 . True Positive Rate [0.50531915 0.86868687] . import sklearn.metrics as metrics import matplotlib.pyplot as plt def plot_curve(pred): fpr, tpr, threshold = metrics.roc_curve(Y_test, pred[:,1]) roc_auc = metrics.auc(fpr, tpr) # method I: plt plt.title(&#39;Receiver Operating Characteristic&#39;) plt.plot(fpr, tpr, &#39;b&#39;, label = &#39;AUC = %0.2f&#39; % roc_auc) plt.legend(loc = &#39;lower right&#39;) plt.plot([0, 1], [0, 1],&#39;r--&#39;) plt.xlim([0, 1]) plt.ylim([0, 1]) plt.ylabel(&#39;True Positive Rate&#39;) plt.xlabel(&#39;False Positive Rate&#39;) plt.show() plot_curve(pred_rf_proba) . # print(optimal_proba_cutoff) # roc_predictions=calc_pred=pred_rf_proba[:,1]&gt;0.26 # roc_predictions=roc_predictions.astype(int) #roc_predictions = [1 if i &gt;= optimal_proba_cutoff else 0 for i in predicted_proba[:, -1]] . # print(&quot;Precision Score Before and After Thresholding: {}, {}&quot;.format(precision_score(Y_test, roc_predictions), precision_score(Y_test, roc_predictions))) # print(&quot;Recall Score Before and After Thresholding: {}, {}&quot;.format(recall_score(Y_test, roc_predictions), recall_score(Y_test, roc_predictions))) . XGBoost . from xgboost import XGBClassifier model_xg = XGBClassifier(max_depth=7, # &#39;max_leaves&#39; : 2**4, alpha=0.1, # &#39;lambda&#39; : 0.2, eta=0.1, subsample=0.7, min_child_weight =5, learning_rate=0.1, #default = 0.3, colsample_bytree=0.7, eval_metric=&#39;auc&#39;, objective = &#39;binary:logistic&#39;, grow_policy=&#39;lossguide&#39;, n_estimators=100) model_xg.fit(X_train, Y_train) pred_xg_proba=model_xg.predict_proba(X_test) feat_importances = pd.Series(model_xg.feature_importances_, index=X_train.columns) feat_importances=feat_importances.sort_values() feat_importances.plot(kind=&#39;barh&#39;,figsize=(16,16))#Plotting feature importance . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f2669eeb4a8&gt; . plot_curve(pred_xg_proba) plot_hist(pred_xg_proba) calc_pred=pred_xg_proba[:,1]&gt;0.16 calc_pred=calc_pred.astype(int) conf_mat = confusion_matrix(Y_test, calc_pred) df_confusion = pd.crosstab(Y_test, calc_pred, rownames=[&#39;Actual&#39;], colnames=[&#39;Predicted&#39;], margins=True) print (df_confusion) . Predicted 0 1 All Actual 0 247 129 376 1 30 69 99 All 277 198 475 . X_cols=weekly_data_subset_new_agg_pts_team2[[&#39;player_name&#39;,&#39;position&#39;,&#39;team&#39;,&#39;total_points&#39;,&#39;point_flag&#39;]].copy() X_test_pred=pd.merge(X_test, X_cols, left_index=True, right_index=True) #X_test_pred[&#39;predictions&#39;]=pred_rf_proba[:,1] X_test_pred[&#39;predictions&#39;]=pred_xg_proba[:,1] . X_test_pred.loc[X_test_pred[&#39;predictions&#39;]&gt;0.5].sort_values(by=&#39;predictions&#39;,ascending=False).head(20) . was_home home_team away_team proj_score1 proj_score2 influence_roll creativity_roll threat_roll ict_index_roll minutes_roll selected_roll total_points_roll red_cards yellow_cards xP total_points_x bonus clean_sheets assists minutes influence creativity threat ict_index team_pts team_rank xG_diff_team deep_diff_team scored_diff_team opponent_points gw opponent_rank xG_diff_opponent deep_diff_opponent scored_diff_opponent rank_diff proj_score_diff team_total_points_cumsum percent_team_points position_flag pos_0 pos_1 pos_2 pos_3 player_name position team total_points_y point_flag predictions . 2520 False | 18 | 8 | 1.03 | 1.38 | 21.212500 | 22.781250 | 31.437500 | 7.543750 | 81.250000 | 6.255662e+04 | 3.625000 | 0 | 3 | 55.9 | 58 | 5 | 4 | 3 | 1300 | 339.4 | 364.5 | 503.0 | 120.7 | 13 | 14.0 | -0.590980 | 0.396396 | 0.357143 | 11 | 20 | 15.0 | -1.470378 | 0.285156 | 0.238095 | -1.0 | -0.35 | 633 | 0.091627 | 3 | 0 | 0 | 0 | 1 | Ademola Lookman | MID | Fulham | 58 | 0 | 0.920600 | . 2523 False | 18 | 8 | 1.03 | 1.38 | 17.905263 | 12.752632 | 8.789474 | 3.963158 | 81.105263 | 1.548767e+05 | 2.578947 | 0 | 4 | 37.7 | 49 | 4 | 4 | 3 | 1541 | 340.2 | 242.3 | 167.0 | 75.3 | 13 | 14.0 | -0.590980 | 0.396396 | 0.357143 | 11 | 20 | 15.0 | -1.470378 | 0.285156 | 0.238095 | -1.0 | -0.35 | 633 | 0.077409 | 3 | 0 | 0 | 0 | 1 | André-Frank Zambo Anguissa | MID | Fulham | 49 | 0 | 0.901406 | . 2542 False | 18 | 8 | 1.03 | 1.38 | 20.720000 | 1.880000 | 5.933333 | 2.873333 | 90.000000 | 1.159773e+04 | 3.266667 | 0 | 1 | 33.3 | 49 | 5 | 4 | 1 | 1350 | 310.8 | 28.2 | 89.0 | 43.1 | 13 | 14.0 | -0.590980 | 0.396396 | 0.357143 | 11 | 20 | 15.0 | -1.470378 | 0.285156 | 0.238095 | -1.0 | -0.35 | 633 | 0.077409 | 0 | 1 | 0 | 0 | 0 | Tosin Adarabioyo | DEF | Fulham | 49 | 0 | 0.839237 | . 6921 False | 5 | 4 | 1.91 | 0.58 | 14.852632 | 21.536842 | 4.000000 | 4.036842 | 90.000000 | 4.007800e+04 | 3.000000 | 0 | 4 | 47.2 | 57 | 2 | 7 | 3 | 1710 | 282.2 | 409.2 | 76.0 | 76.7 | 22 | 11.0 | -0.695852 | 0.356061 | 0.351351 | 30 | 20 | 7.0 | 0.667273 | 0.587549 | 0.589286 | 4.0 | 1.33 | 716 | 0.079609 | 3 | 0 | 0 | 0 | 1 | Ashley Westwood | MID | Burnley | 57 | 0 | 0.828182 | . 2529 False | 18 | 8 | 1.03 | 1.38 | 14.893333 | 1.233333 | 0.866667 | 1.706667 | 76.066667 | 1.557933e+03 | 2.400000 | 1 | 2 | 20.6 | 36 | 2 | 4 | 0 | 1141 | 223.4 | 18.5 | 13.0 | 25.6 | 13 | 14.0 | -0.590980 | 0.396396 | 0.357143 | 11 | 20 | 15.0 | -1.470378 | 0.285156 | 0.238095 | -1.0 | -0.35 | 633 | 0.056872 | 0 | 1 | 0 | 0 | 0 | Joachim Andersen | DEF | Fulham | 36 | 0 | 0.797265 | . 2528 False | 18 | 8 | 1.03 | 1.38 | 9.400000 | 15.521053 | 18.789474 | 4.368421 | 67.315789 | 9.510263e+03 | 2.421053 | 0 | 1 | 40.4 | 46 | 4 | 3 | 0 | 1279 | 178.6 | 294.9 | 357.0 | 83.0 | 13 | 14.0 | -0.590980 | 0.396396 | 0.357143 | 11 | 20 | 15.0 | -1.470378 | 0.285156 | 0.238095 | -1.0 | -0.35 | 633 | 0.072670 | 3 | 0 | 0 | 0 | 1 | Ivan Ricardo Neves Abreu Cavaleiro | MID | Fulham | 46 | 1 | 0.749120 | . 6518 True | 6 | 20 | 1.19 | 1.16 | 20.620000 | 12.030000 | 33.850000 | 6.655000 | 76.000000 | 1.464735e+06 | 4.950000 | 0 | 3 | 93.3 | 99 | 11 | 3 | 3 | 1520 | 412.4 | 240.6 | 677.0 | 133.1 | 23 | 10.0 | -0.572657 | 0.477912 | 0.400000 | 23 | 20 | 10.0 | -0.315068 | 0.348214 | 0.420000 | 0.0 | 0.03 | 727 | 0.136176 | 3 | 0 | 0 | 0 | 1 | Wilfried Zaha | MID | Crystal Palace | 99 | 0 | 0.744352 | . 2538 False | 18 | 8 | 1.03 | 1.38 | 17.087500 | 7.968750 | 3.250000 | 2.825000 | 89.000000 | 2.107606e+04 | 3.250000 | 0 | 1 | 39.1 | 52 | 3 | 4 | 0 | 1424 | 273.4 | 127.5 | 52.0 | 45.2 | 13 | 14.0 | -0.590980 | 0.396396 | 0.357143 | 11 | 20 | 15.0 | -1.470378 | 0.285156 | 0.238095 | -1.0 | -0.35 | 633 | 0.082148 | 0 | 1 | 0 | 0 | 0 | Ola Aina | DEF | Fulham | 52 | 0 | 0.727088 | . 3759 False | 16 | 2 | 1.25 | 1.44 | 33.200000 | 46.522222 | 45.055556 | 12.466667 | 89.833333 | 2.448694e+06 | 6.277778 | 0 | 4 | 113.2 | 113 | 12 | 9 | 10 | 1617 | 597.6 | 837.4 | 811.0 | 224.4 | 29 | 8.0 | 0.778199 | 0.536765 | 0.611111 | 29 | 20 | 8.0 | -0.319173 | 0.451327 | 0.529412 | 0.0 | -0.19 | 920 | 0.122826 | 3 | 0 | 0 | 0 | 1 | Jack Grealish | MID | Aston Villa | 113 | 1 | 0.708945 | . 3756 False | 16 | 2 | 1.25 | 1.44 | 12.066667 | 10.983333 | 5.444444 | 2.861111 | 82.833333 | 2.084678e+04 | 2.388889 | 1 | 2 | 38.6 | 43 | 0 | 8 | 2 | 1491 | 217.2 | 197.7 | 98.0 | 51.5 | 29 | 8.0 | 0.778199 | 0.536765 | 0.611111 | 29 | 20 | 8.0 | -0.319173 | 0.451327 | 0.529412 | 0.0 | -0.19 | 920 | 0.046739 | 3 | 0 | 0 | 0 | 1 | Douglas Luiz Soares de Paulo | MID | Aston Villa | 43 | 1 | 0.704342 | . 5645 False | 7 | 14 | 1.63 | 0.79 | 12.370000 | 11.700000 | 9.750000 | 3.385000 | 54.750000 | 3.779905e+04 | 2.400000 | 0 | 1 | 44.8 | 48 | 4 | 2 | 1 | 1095 | 247.4 | 234.0 | 195.0 | 67.7 | 19 | 12.0 | -0.657516 | 0.286290 | 0.358491 | 33 | 20 | 6.0 | 0.062796 | 0.452174 | 0.568627 | 6.0 | 0.84 | 662 | 0.072508 | 3 | 0 | 0 | 0 | 1 | Miguel Almirón | MID | Newcastle | 48 | 1 | 0.700847 | . 2913 False | 6 | 20 | 1.19 | 1.16 | 12.500000 | 10.130000 | 18.750000 | 4.145000 | 59.400000 | 2.698630e+05 | 3.000000 | 0 | 2 | 59.4 | 60 | 5 | 6 | 2 | 1188 | 250.0 | 202.6 | 375.0 | 82.9 | 23 | 10.0 | -0.315068 | 0.348214 | 0.420000 | 23 | 20 | 10.0 | -0.572657 | 0.477912 | 0.400000 | 0.0 | 0.03 | 763 | 0.078637 | 3 | 0 | 0 | 0 | 1 | Daniel Castelo Podence | MID | Wolves | 60 | 0 | 0.700754 | . 2522 False | 18 | 8 | 1.03 | 1.38 | 27.442105 | 0.000000 | 0.000000 | 2.731579 | 85.263158 | 1.203639e+05 | 3.578947 | 0 | 0 | 50.7 | 68 | 7 | 4 | 0 | 1620 | 521.4 | 0.0 | 0.0 | 51.9 | 13 | 14.0 | -0.590980 | 0.396396 | 0.357143 | 11 | 20 | 15.0 | -1.470378 | 0.285156 | 0.238095 | -1.0 | -0.35 | 633 | 0.107425 | 2 | 0 | 0 | 1 | 0 | Alphonse Areola | GK | Fulham | 68 | 0 | 0.680518 | . 3769 False | 16 | 2 | 1.25 | 1.44 | 23.788889 | 17.772222 | 49.333333 | 9.055556 | 90.000000 | 5.276981e+05 | 4.611111 | 0 | 1 | 81.6 | 83 | 6 | 9 | 4 | 1620 | 428.2 | 319.9 | 888.0 | 163.0 | 29 | 8.0 | 0.778199 | 0.536765 | 0.611111 | 29 | 20 | 8.0 | -0.319173 | 0.451327 | 0.529412 | 0.0 | -0.19 | 920 | 0.090217 | 1 | 0 | 1 | 0 | 0 | Ollie Watkins | FWD | Aston Villa | 83 | 0 | 0.679663 | . 6081 True | 5 | 4 | 1.91 | 0.58 | 7.810000 | 10.765000 | 7.900000 | 2.650000 | 25.050000 | 2.235575e+04 | 1.550000 | 0 | 0 | 39.5 | 31 | 1 | 2 | 1 | 501 | 156.2 | 215.3 | 158.0 | 53.0 | 30 | 7.0 | 0.667273 | 0.587549 | 0.589286 | 22 | 20 | 11.0 | -0.695852 | 0.356061 | 0.351351 | -4.0 | 1.33 | 939 | 0.033014 | 3 | 0 | 0 | 0 | 1 | Callum Hudson-Odoi | MID | Chelsea | 31 | 1 | 0.672173 | . 439 True | 3 | 17 | 1.23 | 1.48 | 11.910000 | 19.860000 | 8.150000 | 3.990000 | 44.650000 | 2.893990e+04 | 2.450000 | 0 | 1 | 51.7 | 49 | 6 | 3 | 2 | 893 | 238.2 | 397.2 | 163.0 | 79.8 | 18 | 13.0 | 0.251112 | 0.593496 | 0.431373 | 33 | 20 | 6.0 | 0.275229 | 0.354260 | 0.629630 | 7.0 | -0.25 | 737 | 0.066486 | 3 | 0 | 0 | 0 | 1 | Pascal Groß | MID | Brighton | 49 | 1 | 0.667477 | . 6498 True | 6 | 20 | 1.19 | 1.16 | 15.340000 | 20.665000 | 7.450000 | 4.355000 | 67.150000 | 1.467164e+05 | 2.900000 | 0 | 0 | 52.7 | 58 | 6 | 4 | 3 | 1343 | 306.8 | 413.3 | 149.0 | 87.1 | 23 | 10.0 | -0.572657 | 0.477912 | 0.400000 | 23 | 20 | 10.0 | -0.315068 | 0.348214 | 0.420000 | 0.0 | 0.03 | 727 | 0.079780 | 3 | 0 | 0 | 0 | 1 | Andros Townsend | MID | Crystal Palace | 58 | 0 | 0.660697 | . 6940 False | 5 | 4 | 1.91 | 0.58 | 28.789474 | 0.526316 | 0.000000 | 2.926316 | 85.263158 | 8.227975e+05 | 5.000000 | 0 | 0 | 87.2 | 95 | 17 | 7 | 0 | 1620 | 547.0 | 10.0 | 0.0 | 55.6 | 22 | 11.0 | -0.695852 | 0.356061 | 0.351351 | 30 | 20 | 7.0 | 0.667273 | 0.587549 | 0.589286 | 4.0 | 1.33 | 716 | 0.132682 | 2 | 0 | 0 | 1 | 0 | Nick Pope | GK | Burnley | 95 | 1 | 0.656792 | . 5168 True | 16 | 2 | 1.25 | 1.44 | 24.968421 | 26.857895 | 6.736842 | 5.847368 | 90.000000 | 7.082940e+05 | 4.526316 | 0 | 3 | 77.3 | 86 | 8 | 8 | 5 | 1710 | 474.4 | 510.3 | 128.0 | 111.1 | 29 | 8.0 | -0.319173 | 0.451327 | 0.529412 | 29 | 20 | 8.0 | 0.778199 | 0.536765 | 0.611111 | 0.0 | -0.19 | 871 | 0.098737 | 3 | 0 | 0 | 0 | 1 | James Ward-Prowse | MID | Southampton | 86 | 0 | 0.645985 | . 6079 True | 5 | 4 | 1.91 | 0.58 | 18.150000 | 16.200000 | 11.200000 | 4.525000 | 71.250000 | 1.622360e+06 | 4.250000 | 0 | 2 | 92.3 | 85 | 7 | 7 | 4 | 1425 | 363.0 | 324.0 | 224.0 | 90.5 | 30 | 7.0 | 0.667273 | 0.587549 | 0.589286 | 22 | 20 | 11.0 | -0.695852 | 0.356061 | 0.351351 | -4.0 | 1.33 | 939 | 0.090522 | 0 | 1 | 0 | 0 | 0 | Benjamin Chilwell | DEF | Chelsea | 85 | 0 | 0.622765 | . X_test_pred.to_csv(&#39;df.csv&#39;) #files.download(&#39;df.csv&#39;) . . fixtures_df1=fixtures_df[[&#39;event&#39;,&#39;team_h&#39;,&#39;team_a&#39;]] max_week=weekly_data_subset[&#39;round&#39;].max() print(max_week) #UNCOMMENT THIS LATER #pred_data=weekly_data_subset.loc[weekly_data_subset[&#39;round&#39;]==max_week] pred_data=weekly_data_subset fixtures_df1=fixtures_df1.loc[fixtures_df1[&#39;event&#39;]==max_week+1] #fixtures_df1=fixtures_df1.loc[fixtures_df1[&#39;event&#39;]==max_week] pred_data=pred_data[[&#39;player_name&#39;,&#39;position&#39;,&#39;team&#39;,&#39;team_id&#39;,&#39;round&#39;]].reset_index(drop=True) pred_data=pred_data.drop_duplicates(subset=[&#39;player_name&#39;,&#39;position&#39;,&#39;team&#39;,&#39;team_id&#39;]) pred_data[&#39;round&#39;]=16 print(pred_data.shape) pred_data #fixtures_df pred_data=pd.merge(left=pred_data,right=fixtures_df1,left_on=&#39;team_id&#39;,right_on=&#39;team_h&#39;,how=&#39;left&#39;) pred_data=pd.merge(left=pred_data,right=fixtures_df1,left_on=&#39;team_id&#39;,right_on=&#39;team_a&#39;,how=&#39;left&#39;) pred_data.loc[pred_data[&#39;team_h_x&#39;].isna(),&#39;team_h_x&#39;]=pred_data.loc[pred_data[&#39;team_h_x&#39;].isna(),&#39;team_h_y&#39;] pred_data.loc[pred_data[&#39;team_a_x&#39;].isna(),&#39;team_a_x&#39;]=pred_data.loc[pred_data[&#39;team_a_x&#39;].isna(),&#39;team_a_y&#39;] pred_data=pred_data[[&#39;player_name&#39;,&#39;position&#39;,&#39;team&#39;,&#39;team_id&#39;,&#39;team_h_x&#39;,&#39;team_a_x&#39;,&#39;round&#39;]] pred_data=pred_data.rename(columns={&quot;round&quot;: &quot;gw&quot;,&quot;team_h_x&quot;: &quot;home_team&quot;,&quot;team_a_x&quot;:&quot;away_team&quot;}) # #weekly_data_subset_new=weekly_data_subset[[&#39;player_name&#39;,&#39;gw&#39;,&#39;position&#39;,&#39;team&#39;,&#39;round&#39;,&#39;team_id&#39;,&#39;opponent_id&#39;,&#39;selected&#39;,&#39;was_home&#39;,&#39;home_team&#39;,&#39;away_team&#39;,&#39;proj_score1&#39;,&#39;proj_score2&#39;,&#39;point_flag&#39;]].copy() # #Home Flag pred_data[&#39;was_home&#39;]=0 pred_data.loc[pred_data[&#39;home_team&#39;]==pred_data[&#39;team_id&#39;],&#39;was_home&#39;]=1 #TOBECHANGED pred_data[&#39;gw&#39;]=GW-1 pred_data[&#39;opponent_id&#39;]=0 pred_data[&#39;opponent_id&#39;]=pred_data[&#39;home_team&#39;] pred_data.loc[pred_data[&#39;was_home&#39;]==1,&#39;opponent_id&#39;]=pred_data.loc[pred_data[&#39;was_home&#39;]==1,&#39;away_team&#39;] #pred_data #Rolling means dataset. Take latest available record for a player to account for empty gameweeks or covid cancellations weekly_rolling_means_latest_stats=weekly_rolling_means.sort_values(by=&#39;gw&#39;,ascending=False).groupby(&#39;player_name&#39;).head(1) weekly_rolling_means_latest_stats[&#39;gw&#39;]=max_week pred_data_roll=pd.merge(left=pred_data,right=weekly_rolling_means_latest_stats,left_on=[&#39;player_name&#39;,&#39;gw&#39;],right_on=[&#39;player_name&#39;,&#39;gw&#39;],how=&#39;inner&#39;) # #Merge cumulative means gp_cumsum_latest_stats=gp_cumsum.sort_values(by=&#39;gw&#39;,ascending=False).groupby(&#39;player_name&#39;).head(1) gp_cumsum_latest_stats[&#39;gw&#39;]=max_week pred_data_roll_cum=pd.merge(left=pred_data_roll,right=gp_cumsum_latest_stats,left_on=[&#39;player_name&#39;,&#39;gw&#39;],right_on=[&#39;player_name&#39;,&#39;gw&#39;],how=&#39;inner&#39;) #pred_data_roll_cum # # #Merge team total ranking stats with home team #Calculate latest availalbe team stats for the team. Useful when teams have blank gameweeks and are not playing in the game latest_rank=team_total_data_id.sort_values(by=&#39;gw&#39;,ascending=False).groupby(&#39;id&#39;).head(1) latest_rank[&#39;gw&#39;]=max_week pred_data_roll_cum_team=pd.merge(left=pred_data_roll_cum,right=latest_rank,left_on=[&#39;team_id&#39;,&#39;gw&#39;],right_on=[&#39;id&#39;,&#39;gw&#39;]) pred_data_roll_cum_team=pred_data_roll_cum_team.rename(columns={&quot;rank&quot;: &quot;team_rank&quot;,&#39;cum_pts&#39;:&#39;team_pts&#39;,&#39;xG_diff&#39;:&#39;xG_diff_team&#39;,&#39;scored_diff&#39;:&#39;scored_diff_team&#39;,&#39;deep_diff&#39;:&#39;deep_diff_team&#39;}) # # #Merge team total ranking stats with away team pred_data_roll_cum_team=pd.merge(left=pred_data_roll_cum_team,right=latest_rank,left_on=[&#39;opponent_id&#39;,&#39;gw&#39;],right_on=[&#39;id&#39;,&#39;gw&#39;]) pred_data_roll_cum_team=pred_data_roll_cum_team.rename(columns={&quot;rank&quot;: &quot;opponent_rank&quot;,&#39;cum_pts&#39;:&#39;opponent_points&#39;,&#39;xG_diff&#39;:&#39;xG_diff_opponent&#39;,&#39;scored_diff&#39;:&#39;scored_diff_opponent&#39;,&#39;deep_diff&#39;:&#39;deep_diff_opponent&#39;}) pred_data_roll_cum_team # #Merge team total ranking stats with away team team_gp_latest=team_gp.sort_values(by=&#39;round&#39;,ascending=False).groupby(&#39;team_id&#39;).head(1) team_gp_latest[&#39;round&#39;]=max_week pred_data_roll_cum_team_pts=pd.merge(left=pred_data_roll_cum_team,right=team_gp_latest,left_on=[&#39;team_id&#39;,&#39;gw&#39;],right_on=[&#39;team_id&#39;,&#39;round&#39;],how=&#39;inner&#39;) pred_data_roll_cum_team_pts[&#39;percent_team_points&#39;]=pred_data_roll_cum_team_pts[&#39;total_points&#39;]/pred_data_roll_cum_team_pts[&#39;team_total_points_cumsum&#39;] pred_data_roll_cum_team_pts[&#39;gw&#39;]=max_week+1 pred_data_roll_cum_team_pts_spi=pd.merge(left=pred_data_roll_cum_team_pts,right=spi_data_name_fil,left_on=[&#39;home_team&#39;,&#39;away_team&#39;],right_on=[&#39;home_id&#39;,&#39;away_id&#39;],how=&#39;inner&#39;) # #Calculate rank and projected score differences for the upcoming fixture pred_data_roll_cum_team_pts_spi[&#39;rank_diff&#39;]=pred_data_roll_cum_team_pts_spi[&#39;team_rank&#39;]-pred_data_roll_cum_team_pts_spi[&#39;opponent_rank&#39;] pred_data_roll_cum_team_pts_spi[&#39;proj_score_diff&#39;]=pred_data_roll_cum_team_pts_spi[&#39;proj_score1&#39;]-pred_data_roll_cum_team_pts_spi[&#39;proj_score2&#39;] #pred_data_roll_cum_team_pts_spi . 21 (486, 5) . pred_data_roll_cum_team_pts_spi.shape . (486, 51) . # pred_data_roll.loc[pred_data_roll.influence_roll.isna()] team_gp . team_id round team_total_points_cumsum . 0 1 | 1 | 82 | . 1 1 | 2 | 128 | . 2 1 | 3 | 151 | . 3 1 | 4 | 196 | . 4 1 | 5 | 221 | . ... ... | ... | ... | . 394 20 | 17 | 651 | . 395 20 | 18 | 679 | . 396 20 | 19 | 712 | . 397 20 | 20 | 763 | . 398 20 | 21 | 786 | . 399 rows × 3 columns . pred_data_roll_cum_team_pts_spi[&#39;position_flag&#39;] = labelencoder.fit_transform(pred_data_roll_cum_team_pts_spi[&#39;position&#39;]) cols = pd.get_dummies(pred_data_roll_cum_team_pts_spi[&#39;position_flag&#39;]) cols.columns = [&#39;pos_0&#39;,&#39;pos_1&#39;,&#39;pos_2&#39;,&#39;pos_3&#39;] pred_data_roll_cum_team_pts_spi1 = pd.concat([pred_data_roll_cum_team_pts_spi, cols], axis=1) pred_data_roll_cum_team_pts_spi1 pred_data_roll_cum_team_pts_spi1.drop([&#39;player_name&#39;,&#39;position&#39;,&#39;team&#39;,&#39;team1&#39;,&#39;team2&#39;,&#39;away_id&#39;,&#39;home_id&#39;,&#39;id_x&#39;,&#39;id_y&#39;,&#39;opponent_id&#39;,&#39;team_id&#39;,&#39;round&#39;],axis=1,inplace=True) #Reorder columns in the test data to be in the same order as train data pred_data_roll_cum_team_pts_spi1=pred_data_roll_cum_team_pts_spi1[X_train.columns] proba_rf=model_rf.predict_proba(pred_data_roll_cum_team_pts_spi1) proba_xg=model_xg.predict_proba(pred_data_roll_cum_team_pts_spi1) #pred_data_roll_cum_team_pts_spi[&#39;predicted&#39;]=proba_rf[:,1] #pred_data_roll_cum_team_pts_spi[&#39;predicted&#39;]=proba_xg[:,1] pred_data_roll_cum_team_pts_spi[&#39;predicted&#39;]=0.7*proba_rf[:,1]+0.3*proba_xg[:,1] . pred_data_roll_cum_team_pts_spi.team.unique() . array([&#39;Brighton&#39;, &#39;Liverpool&#39;, &#39;West Ham&#39;, &#39;Aston Villa&#39;, &#39;Sheffield Utd&#39;, &#39;West Brom&#39;, &#39;Man Utd&#39;, &#39;Southampton&#39;, &#39;Everton&#39;, &#39;Leeds&#39;, &#39;Fulham&#39;, &#39;Leicester&#39;, &#39;Wolves&#39;, &#39;Arsenal&#39;, &#39;Newcastle&#39;, &#39;Crystal Palace&#39;, &#39;Chelsea&#39;, &#39;Spurs&#39;, &#39;Burnley&#39;, &#39;Man City&#39;], dtype=object) . pred_data_roll_cum_team_pts_spi.sort_values(by=&#39;predicted&#39;,ascending=False).head(15) . player_name position team team_id home_team away_team gw was_home opponent_id influence_roll creativity_roll threat_roll ict_index_roll minutes_roll selected_roll total_points_roll red_cards yellow_cards xP total_points bonus clean_sheets assists minutes influence creativity threat ict_index team_pts id_x team_rank xG_diff_team deep_diff_team scored_diff_team opponent_points id_y opponent_rank xG_diff_opponent deep_diff_opponent scored_diff_opponent round team_total_points_cumsum percent_team_points team1 team2 home_id away_id proj_score1 proj_score2 rank_diff proj_score_diff position_flag predicted . 466 Ederson Santana de Moraes | GK | Man City | 12 | 4.0 | 12.0 | 22 | 0 | 4.0 | 13.740000 | 0.000000 | 0.000000 | 1.380000 | 85.500000 | 4.609512e+05 | 4.400000 | 0 | 1 | 110.1 | 88 | 1 | 12 | 0 | 1710 | 274.8 | 0.0 | 0.0 | 27.6 | 44 | 12 | 1.0 | 1.294208 | 0.750865 | 0.740000 | 22 | 4 | 12.0 | -0.713549 | 0.336770 | 0.333333 | 21 | 1134 | 0.077601 | Burnley | Manchester City | 4 | 12 | 0.49 | 2.25 | -11.0 | -1.76 | 2 | 0.730635 | . 471 Ilkay Gündogan | MID | Man City | 12 | 4.0 | 12.0 | 22 | 0 | 4.0 | 19.790000 | 17.685000 | 16.500000 | 5.400000 | 56.250000 | 1.693185e+05 | 4.150000 | 0 | 0 | 104.5 | 83 | 12 | 9 | 0 | 1125 | 395.8 | 353.7 | 330.0 | 108.0 | 44 | 12 | 1.0 | 1.294208 | 0.750865 | 0.740000 | 22 | 4 | 12.0 | -0.713549 | 0.336770 | 0.333333 | 21 | 1134 | 0.073192 | Burnley | Manchester City | 4 | 12 | 0.49 | 2.25 | -11.0 | -1.76 | 3 | 0.690731 | . 481 Riyad Mahrez | MID | Man City | 12 | 4.0 | 12.0 | 22 | 0 | 4.0 | 15.350000 | 21.205000 | 22.650000 | 5.915000 | 47.100000 | 3.575458e+05 | 3.500000 | 0 | 0 | 101.7 | 70 | 7 | 7 | 2 | 942 | 307.0 | 424.1 | 453.0 | 118.3 | 44 | 12 | 1.0 | 1.294208 | 0.750865 | 0.740000 | 22 | 4 | 12.0 | -0.713549 | 0.336770 | 0.333333 | 21 | 1134 | 0.061728 | Burnley | Manchester City | 4 | 12 | 0.49 | 2.25 | -11.0 | -1.76 | 3 | 0.688607 | . 244 Ademola Lookman | MID | Fulham | 8 | 8.0 | 9.0 | 22 | 1 | 9.0 | 20.341176 | 22.500000 | 31.647059 | 7.447059 | 81.764706 | 6.473088e+04 | 3.529412 | 0 | 3 | 59.3 | 60 | 5 | 4 | 3 | 1390 | 345.8 | 382.5 | 538.0 | 126.6 | 14 | 8 | 14.0 | -0.535142 | 0.414847 | 0.369565 | 39 | 9 | 4.0 | 0.349518 | 0.556034 | 0.596774 | 21 | 671 | 0.089419 | Fulham | Leicester City | 8 | 9 | 0.97 | 1.54 | 10.0 | -0.57 | 3 | 0.667287 | . 473 João Pedro Cavaco Cancelo | DEF | Man City | 12 | 4.0 | 12.0 | 22 | 0 | 4.0 | 16.610000 | 21.850000 | 9.850000 | 4.835000 | 63.950000 | 4.679078e+05 | 4.300000 | 0 | 3 | 104.4 | 86 | 13 | 9 | 2 | 1279 | 332.2 | 437.0 | 197.0 | 96.7 | 44 | 12 | 1.0 | 1.294208 | 0.750865 | 0.740000 | 22 | 4 | 12.0 | -0.713549 | 0.336770 | 0.333333 | 21 | 1134 | 0.075838 | Burnley | Manchester City | 4 | 12 | 0.49 | 2.25 | -11.0 | -1.76 | 0 | 0.666357 | . 320 Bukayo Saka | MID | Arsenal | 1 | 20.0 | 1.0 | 22 | 0 | 20.0 | 17.828571 | 18.304762 | 30.714286 | 6.685714 | 71.571429 | 3.791516e+05 | 3.857143 | 0 | 0 | 77.1 | 81 | 8 | 6 | 3 | 1503 | 374.4 | 384.4 | 645.0 | 140.4 | 31 | 1 | 8.0 | 0.226947 | 0.570370 | 0.565217 | 23 | 20 | 11.0 | -0.343772 | 0.346320 | 0.411765 | 21 | 929 | 0.087191 | Wolverhampton | Arsenal | 20 | 1 | 1.06 | 1.35 | -3.0 | -0.29 | 3 | 0.627423 | . 482 Rodrigo Hernandez | MID | Man City | 12 | 4.0 | 12.0 | 22 | 0 | 4.0 | 15.350000 | 14.055000 | 9.300000 | 3.875000 | 77.100000 | 3.570875e+04 | 2.300000 | 0 | 3 | 71.5 | 46 | 3 | 8 | 1 | 1542 | 307.0 | 281.1 | 186.0 | 77.5 | 44 | 12 | 1.0 | 1.294208 | 0.750865 | 0.740000 | 22 | 4 | 12.0 | -0.713549 | 0.336770 | 0.333333 | 21 | 1134 | 0.040564 | Burnley | Manchester City | 4 | 12 | 0.49 | 2.25 | -11.0 | -1.76 | 3 | 0.615653 | . 390 Wilfried Zaha | MID | Crystal Palace | 6 | 14.0 | 6.0 | 22 | 0 | 14.0 | 19.638095 | 12.276190 | 33.333333 | 6.528571 | 76.666667 | 1.450886e+06 | 4.809524 | 0 | 4 | 96.3 | 101 | 11 | 4 | 3 | 1610 | 412.4 | 257.8 | 700.0 | 137.1 | 26 | 6 | 10.0 | -0.501680 | 0.484375 | 0.409836 | 22 | 14 | 12.0 | -0.572762 | 0.290076 | 0.381818 | 21 | 786 | 0.128499 | Newcastle | Crystal Palace | 14 | 6 | 1.25 | 1.07 | -2.0 | 0.18 | 3 | 0.599962 | . 96 Aaron Ramsdale | GK | Sheffield Utd | 15 | 15.0 | 18.0 | 22 | 1 | 18.0 | 22.876190 | 0.476190 | 0.190476 | 2.352381 | 90.000000 | 2.368946e+05 | 2.523810 | 0 | 1 | 46.3 | 53 | 2 | 1 | 0 | 1890 | 480.4 | 10.0 | 4.0 | 49.4 | 8 | 15 | 16.0 | -0.550331 | 0.437037 | 0.260870 | 12 | 18 | 15.0 | -1.425397 | 0.277567 | 0.253731 | 21 | 540 | 0.098148 | Sheffield United | West Bromwich Albion | 15 | 18 | 1.52 | 0.81 | 1.0 | 0.71 | 2 | 0.590660 | . 480 Raheem Sterling | MID | Man City | 12 | 4.0 | 12.0 | 22 | 0 | 4.0 | 19.280000 | 15.505000 | 40.200000 | 7.490000 | 71.900000 | 4.356275e+05 | 4.850000 | 0 | 1 | 122.4 | 97 | 9 | 9 | 6 | 1438 | 385.6 | 310.1 | 804.0 | 149.8 | 44 | 12 | 1.0 | 1.294208 | 0.750865 | 0.740000 | 22 | 4 | 12.0 | -0.713549 | 0.336770 | 0.333333 | 21 | 1134 | 0.085538 | Burnley | Manchester City | 4 | 12 | 0.49 | 2.25 | -11.0 | -1.76 | 3 | 0.584465 | . 472 John Stones | DEF | Man City | 12 | 4.0 | 12.0 | 22 | 0 | 4.0 | 13.160000 | 1.815000 | 4.300000 | 1.925000 | 49.500000 | 3.379436e+05 | 3.850000 | 0 | 0 | 112.5 | 77 | 7 | 9 | 0 | 990 | 263.2 | 36.3 | 86.0 | 38.5 | 44 | 12 | 1.0 | 1.294208 | 0.750865 | 0.740000 | 22 | 4 | 12.0 | -0.713549 | 0.336770 | 0.333333 | 21 | 1134 | 0.067901 | Burnley | Manchester City | 4 | 12 | 0.49 | 2.25 | -11.0 | -1.76 | 0 | 0.581161 | . 277 James Maddison | MID | Leicester | 9 | 8.0 | 9.0 | 22 | 0 | 8.0 | 18.495238 | 25.485714 | 17.285714 | 6.119048 | 61.476190 | 3.354671e+05 | 4.238095 | 0 | 3 | 103.6 | 89 | 7 | 7 | 5 | 1291 | 388.4 | 535.2 | 363.0 | 128.5 | 39 | 9 | 4.0 | 0.349518 | 0.556034 | 0.596774 | 14 | 8 | 14.0 | -0.535142 | 0.414847 | 0.369565 | 21 | 944 | 0.094280 | Fulham | Leicester City | 8 | 9 | 0.97 | 1.54 | -10.0 | -0.57 | 3 | 0.564810 | . 53 Aaron Cresswell | DEF | West Ham | 19 | 2.0 | 19.0 | 22 | 0 | 2.0 | 19.685714 | 23.147619 | 2.523810 | 4.547619 | 90.000000 | 7.535033e+05 | 4.571429 | 0 | 0 | 103.4 | 96 | 11 | 7 | 8 | 1890 | 413.4 | 486.1 | 53.0 | 95.5 | 35 | 19 | 5.0 | 0.238656 | 0.384314 | 0.534483 | 32 | 2 | 7.0 | 0.661975 | 0.511945 | 0.618182 | 21 | 947 | 0.101373 | Aston Villa | West Ham United | 2 | 19 | 1.66 | 1.23 | -2.0 | 0.43 | 0 | 0.561478 | . 83 Jack Grealish | MID | Aston Villa | 2 | 2.0 | 19.0 | 22 | 1 | 19.0 | 32.894737 | 45.036842 | 43.105263 | 12.094737 | 89.842105 | 2.477127e+06 | 6.263158 | 0 | 4 | 118.7 | 119 | 12 | 10 | 11 | 1707 | 625.0 | 855.7 | 819.0 | 229.8 | 32 | 2 | 7.0 | 0.661975 | 0.511945 | 0.618182 | 35 | 19 | 5.0 | 0.238656 | 0.384314 | 0.534483 | 21 | 984 | 0.120935 | Aston Villa | West Ham United | 2 | 19 | 1.66 | 1.23 | 2.0 | 0.43 | 3 | 0.549574 | . 319 Bernd Leno | GK | Arsenal | 1 | 20.0 | 1.0 | 22 | 0 | 20.0 | 20.819048 | 0.000000 | 0.000000 | 2.080952 | 90.000000 | 6.512634e+05 | 4.238095 | 0 | 0 | 92.6 | 89 | 6 | 8 | 0 | 1890 | 437.2 | 0.0 | 0.0 | 43.7 | 31 | 1 | 8.0 | 0.226947 | 0.570370 | 0.565217 | 23 | 20 | 11.0 | -0.343772 | 0.346320 | 0.411765 | 21 | 929 | 0.095802 | Wolverhampton | Arsenal | 20 | 1 | 1.06 | 1.35 | -3.0 | -0.29 | 2 | 0.547207 | . players_df_100=players_df.loc[(players_df[&#39;chance_of_playing_next_round&#39;]!=0)&amp;(players_df[&#39;chance_of_playing_next_round&#39;]!=75)&amp;(players_df[&#39;chance_of_playing_next_round&#39;]!=25)&amp;(players_df[&#39;chance_of_playing_next_round&#39;]!=50)] players_df_100=players_df_100[[&#39;first_name&#39;,&#39;second_name&#39;,&#39;photo&#39;,&#39;code&#39;,&#39;team&#39;]] #players_df_100 players_df_100[&#39;web_name&#39;]=players_df_100[&#39;first_name&#39;]+&#39; &#39;+players_df_100[&#39;second_name&#39;] pred_data_roll_cum_team_pts_spi_100=pd.merge(left=pred_data_roll_cum_team_pts_spi,right=players_df_100,left_on=[&#39;player_name&#39;,&#39;team_id&#39;],right_on=[&#39;web_name&#39;,&#39;team&#39;],how=&#39;inner&#39;) del pred_data_roll_cum_team_pts_spi_100[&#39;team_y&#39;] pred_data_roll_cum_team_pts_spi_100 . player_name position team_x team_id home_team away_team gw was_home opponent_id influence_roll creativity_roll threat_roll ict_index_roll minutes_roll selected_roll total_points_roll red_cards yellow_cards xP total_points bonus clean_sheets assists minutes influence creativity threat ict_index team_pts id_x team_rank xG_diff_team deep_diff_team scored_diff_team opponent_points id_y opponent_rank xG_diff_opponent deep_diff_opponent scored_diff_opponent round team_total_points_cumsum percent_team_points team1 team2 home_id away_id proj_score1 proj_score2 rank_diff proj_score_diff position_flag predicted first_name second_name photo code web_name . 0 Aaron Connolly | FWD | Brighton | 3 | 11.0 | 3.0 | 22 | 0 | 11.0 | 4.704762 | 2.890476 | 11.190476 | 1.871429 | 27.952381 | 35626.095238 | 1.476190 | 0 | 0 | 26.8 | 31 | 2 | 1 | 1 | 587 | 98.8 | 60.7 | 235.0 | 39.3 | 21 | 3 | 13.0 | 0.305884 | 0.611722 | 0.442308 | 40 | 11 | 3.0 | 0.805659 | 0.804217 | 0.641791 | 21 | 800 | 0.038750 | Liverpool | Brighton and Hove Albion | 11 | 3 | 2.09 | 0.77 | 10.0 | 1.32 | 1 | 0.134720 | Aaron | Connolly | 233425.jpg | 233425 | Aaron Connolly | . 1 Adam Lallana | MID | Brighton | 3 | 11.0 | 3.0 | 22 | 0 | 11.0 | 4.800000 | 9.390476 | 5.571429 | 1.957143 | 36.904762 | 32346.238095 | 1.333333 | 0 | 0 | 20.3 | 28 | 0 | 3 | 1 | 775 | 100.8 | 197.2 | 117.0 | 41.1 | 21 | 3 | 13.0 | 0.305884 | 0.611722 | 0.442308 | 40 | 11 | 3.0 | 0.805659 | 0.804217 | 0.641791 | 21 | 800 | 0.035000 | Liverpool | Brighton and Hove Albion | 11 | 3 | 2.09 | 0.77 | 10.0 | 1.32 | 3 | 0.169970 | Adam | Lallana | 39155.jpg | 39155 | Adam Lallana | . 2 Adam Webster | DEF | Brighton | 3 | 11.0 | 3.0 | 22 | 0 | 11.0 | 14.809524 | 3.742857 | 9.619048 | 2.814286 | 85.714286 | 138536.428571 | 2.523810 | 0 | 3 | 41.5 | 53 | 0 | 6 | 0 | 1800 | 311.0 | 78.6 | 202.0 | 59.1 | 21 | 3 | 13.0 | 0.305884 | 0.611722 | 0.442308 | 40 | 11 | 3.0 | 0.805659 | 0.804217 | 0.641791 | 21 | 800 | 0.066250 | Liverpool | Brighton and Hove Albion | 11 | 3 | 2.09 | 0.77 | 10.0 | 1.32 | 0 | 0.248905 | Adam | Webster | 110735.jpg | 110735 | Adam Webster | . 3 Andi Zeqiri | FWD | Brighton | 3 | 11.0 | 3.0 | 22 | 0 | 11.0 | 0.023529 | 0.300000 | 3.705882 | 0.400000 | 3.705882 | 3268.647059 | 0.117647 | 0 | 0 | 1.6 | 2 | 0 | 0 | 0 | 63 | 0.4 | 5.1 | 63.0 | 6.8 | 21 | 3 | 13.0 | 0.305884 | 0.611722 | 0.442308 | 40 | 11 | 3.0 | 0.805659 | 0.804217 | 0.641791 | 21 | 800 | 0.002500 | Liverpool | Brighton and Hove Albion | 11 | 3 | 2.09 | 0.77 | 10.0 | 1.32 | 1 | 0.049812 | Andi | Zeqiri | 204676.jpg | 204676 | Andi Zeqiri | . 4 Ben White | DEF | Brighton | 3 | 11.0 | 3.0 | 22 | 0 | 11.0 | 13.114286 | 5.695238 | 3.000000 | 2.190476 | 83.761905 | 97500.333333 | 2.619048 | 0 | 2 | 41.7 | 55 | 2 | 6 | 0 | 1759 | 275.4 | 119.6 | 63.0 | 46.0 | 21 | 3 | 13.0 | 0.305884 | 0.611722 | 0.442308 | 40 | 11 | 3.0 | 0.805659 | 0.804217 | 0.641791 | 21 | 800 | 0.068750 | Liverpool | Brighton and Hove Albion | 11 | 3 | 2.09 | 0.77 | 10.0 | 1.32 | 0 | 0.237101 | Ben | White | 198869.jpg | 198869 | Ben White | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 365 Raheem Sterling | MID | Man City | 12 | 4.0 | 12.0 | 22 | 0 | 4.0 | 19.280000 | 15.505000 | 40.200000 | 7.490000 | 71.900000 | 435627.550000 | 4.850000 | 0 | 1 | 122.4 | 97 | 9 | 9 | 6 | 1438 | 385.6 | 310.1 | 804.0 | 149.8 | 44 | 12 | 1.0 | 1.294208 | 0.750865 | 0.740000 | 22 | 4 | 12.0 | -0.713549 | 0.336770 | 0.333333 | 21 | 1134 | 0.085538 | Burnley | Manchester City | 4 | 12 | 0.49 | 2.25 | -11.0 | -1.76 | 3 | 0.584465 | Raheem | Sterling | 103955.jpg | 103955 | Raheem Sterling | . 366 Riyad Mahrez | MID | Man City | 12 | 4.0 | 12.0 | 22 | 0 | 4.0 | 15.350000 | 21.205000 | 22.650000 | 5.915000 | 47.100000 | 357545.800000 | 3.500000 | 0 | 0 | 101.7 | 70 | 7 | 7 | 2 | 942 | 307.0 | 424.1 | 453.0 | 118.3 | 44 | 12 | 1.0 | 1.294208 | 0.750865 | 0.740000 | 22 | 4 | 12.0 | -0.713549 | 0.336770 | 0.333333 | 21 | 1134 | 0.061728 | Burnley | Manchester City | 4 | 12 | 0.49 | 2.25 | -11.0 | -1.76 | 3 | 0.688607 | Riyad | Mahrez | 103025.jpg | 103025 | Riyad Mahrez | . 367 Rodrigo Hernandez | MID | Man City | 12 | 4.0 | 12.0 | 22 | 0 | 4.0 | 15.350000 | 14.055000 | 9.300000 | 3.875000 | 77.100000 | 35708.750000 | 2.300000 | 0 | 3 | 71.5 | 46 | 3 | 8 | 1 | 1542 | 307.0 | 281.1 | 186.0 | 77.5 | 44 | 12 | 1.0 | 1.294208 | 0.750865 | 0.740000 | 22 | 4 | 12.0 | -0.713549 | 0.336770 | 0.333333 | 21 | 1134 | 0.040564 | Burnley | Manchester City | 4 | 12 | 0.49 | 2.25 | -11.0 | -1.76 | 3 | 0.615653 | Rodrigo | Hernandez | 220566.jpg | 220566 | Rodrigo Hernandez | . 368 Rúben Santos Gato Alves Dias | DEF | Man City | 12 | 4.0 | 12.0 | 22 | 0 | 4.0 | 20.033333 | 1.788889 | 9.111111 | 3.100000 | 88.833333 | 451309.166667 | 5.055556 | 0 | 2 | 118.4 | 91 | 9 | 12 | 1 | 1599 | 360.6 | 32.2 | 164.0 | 55.8 | 44 | 12 | 1.0 | 1.294208 | 0.750865 | 0.740000 | 22 | 4 | 12.0 | -0.713549 | 0.336770 | 0.333333 | 21 | 1134 | 0.080247 | Burnley | Manchester City | 4 | 12 | 0.49 | 2.25 | -11.0 | -1.76 | 0 | 0.536733 | Rúben Santos | Gato Alves Dias | 171314.jpg | 171314 | Rúben Santos Gato Alves Dias | . 369 Zack Steffen | GK | Man City | 12 | 4.0 | 12.0 | 22 | 0 | 4.0 | 0.480000 | 0.000000 | 0.000000 | 0.050000 | 4.500000 | 5586.100000 | 0.100000 | 0 | 0 | 27.1 | 2 | 0 | 0 | 0 | 90 | 9.6 | 0.0 | 0.0 | 1.0 | 44 | 12 | 1.0 | 1.294208 | 0.750865 | 0.740000 | 22 | 4 | 12.0 | -0.713549 | 0.336770 | 0.333333 | 21 | 1134 | 0.001764 | Burnley | Manchester City | 4 | 12 | 0.49 | 2.25 | -11.0 | -1.76 | 2 | 0.028291 | Zack | Steffen | 164484.jpg | 164484 | Zack Steffen | . 370 rows × 58 columns . players_df.loc[players_df[&#39;web_name&#39;]==&#39;Kane&#39;] . chance_of_playing_next_round chance_of_playing_this_round code cost_change_event cost_change_event_fall cost_change_start cost_change_start_fall dreamteam_count element_type ep_next ep_this event_points first_name form id in_dreamteam news news_added now_cost photo points_per_game second_name selected_by_percent special squad_number status team team_code total_points transfers_in transfers_in_event transfers_out transfers_out_event value_form value_season web_name minutes goals_scored assists clean_sheets goals_conceded own_goals penalties_saved penalties_missed yellow_cards red_cards saves bonus bps influence creativity threat ict_index influence_rank influence_rank_type creativity_rank creativity_rank_type threat_rank threat_rank_type ict_index_rank ict_index_rank_type corners_and_indirect_freekicks_order corners_and_indirect_freekicks_text direct_freekicks_order direct_freekicks_text penalties_order penalties_text . 519 0.0 | 0.0 | 78830 | -1 | 1 | 6 | -6 | 6 | 4 | 0.0 | 0.0 | 0 | Harry | 4.5 | 388 | True | Ankle injury - Unknown return date | 2021-01-28T23:00:26.163676Z | 111 | 78830.jpg | 7.5 | Kane | 22.9 | False | None | i | 17 | 6 | 143 | 4479590 | 2439 | 4187537 | 650925 | 0.4 | 12.9 | Kane | 1654 | 12 | 11 | 6 | 17 | 0 | 0 | 0 | 1 | 0 | 0 | 26 | 512 | 763.4 | 371.2 | 792.0 | 192.4 | 2 | 1 | 28 | 1 | 9 | 5 | 5 | 1 | NaN | | 1.0 | | 1.0 | | . from google.colab import files pred_data_roll_cum_team_pts_spi_100.to_csv(&#39;pred.csv&#39;) files.download(&#39;pred.csv&#39;) . # team_list=[] # gk=pred_data_roll_cum_team_pts_spi.loc[pred_data_roll_cum_team_pts_spi[&#39;position&#39;]==&#39;GK&#39;,[&#39;player_name&#39;,&#39;position&#39;,&#39;team_id&#39;,&#39;gw&#39;]].head(1) # team_list.append(gk) # defender=pred_data_roll_cum_team_pts_spi.loc[pred_data_roll_cum_team_pts_spi[&#39;position&#39;]==&#39;DEF&#39;,[&#39;player_name&#39;,&#39;position&#39;,&#39;team_id&#39;,&#39;gw&#39;]].head(3) # team_list.append(defender) # midfielder=pred_data_roll_cum_team_pts_spi.loc[pred_data_roll_cum_team_pts_spi[&#39;position&#39;]==&#39;MID&#39;,[&#39;player_name&#39;,&#39;position&#39;,&#39;team_id&#39;,&#39;gw&#39;]].head(4) # team_list.append(midfielder) # forward=pred_data_roll_cum_team_pts_spi.loc[pred_data_roll_cum_team_pts_spi[&#39;position&#39;]==&#39;FWD&#39;,[&#39;player_name&#39;,&#39;position&#39;,&#39;team_id&#39;,&#39;gw&#39;]].head(3) # team_list.append(forward) # team_list . pred_data_roll_cum_team_pts_spi_100.sort_values(by=&#39;predicted&#39;,ascending=False,inplace=True) pred_data_roll_cum_team_pts_spi_100[&#39;team&#39;]=pred_data_roll_cum_team_pts_spi_100[&#39;team_x&#39;] team_list=pred_data_roll_cum_team_pts_spi_100.team.unique() team_frame=pd.DataFrame({&#39;team&#39;:team_list}) team_frame[&#39;count&#39;]=0 loop_df=pred_data_roll_cum_team_pts_spi_100[[&#39;player_name&#39;,&#39;position&#39;,&#39;team&#39;]] loop_df=loop_df.reset_index(drop=True) #loop_df form=[1,3,4,3] form_type=[&#39;GK&#39;,&#39;DEF&#39;,&#39;MID&#39;,&#39;FWD&#39;] player_list=[] k=0 j=0 for i in range(4): j=0 # for j in range(form[i]): while True: temp=loop_df.loc[loop_df.position==form_type[i]].head(1) team_name=temp.iloc[0][&#39;team&#39;] player=temp.iloc[0][&#39;player_name&#39;] #print(player,team_name) team_frame.loc[team_frame.team==team_name,&#39;count&#39;]=team_frame.loc[team_frame.team==team_name,&#39;count&#39;]+1 chk= team_frame.loc[team_frame.team==team_name] cnt=chk.iloc[0][&#39;count&#39;] # print(player) # print(cnt) if cnt&lt;=3: player_list.append(player) else : j=j-1 loop_df=loop_df.loc[loop_df.player_name!=player] j=j+1 if(j&gt;=form[i]): break # print(j) # loop_df=loop_df.drop(loop_df.head(1).index) # loop_df=loop_df.reset_index(drop=True) player_list . [&#39;Ederson Santana de Moraes&#39;, &#39;João Pedro Cavaco Cancelo&#39;, &#39;John Stones&#39;, &#39;Aaron Cresswell&#39;, &#39;Ademola Lookman&#39;, &#39;Wilfried Zaha&#39;, &#39;James Maddison&#39;, &#39;Jack Grealish&#39;, &#39;Ollie Watkins&#39;, &#39;Callum Wilson&#39;, &#39;Dominic Calvert-Lewin&#39;] . output=pred_data_roll_cum_team_pts_spi_100.loc[pred_data_roll_cum_team_pts_spi_100.player_name.isin(player_list)] output=output[[&#39;player_name&#39;,&#39;position&#39;,&#39;team_id&#39;,&#39;gw&#39;]] output . player_name position team_id gw . 353 Ederson Santana de Moraes | GK | 12 | 22 | . 182 Ademola Lookman | MID | 8 | 22 | . 360 João Pedro Cavaco Cancelo | DEF | 12 | 22 | . 289 Wilfried Zaha | MID | 6 | 22 | . 359 John Stones | DEF | 12 | 22 | . 209 James Maddison | MID | 9 | 22 | . 36 Aaron Cresswell | DEF | 19 | 22 | . 60 Jack Grealish | MID | 2 | 22 | . 69 Ollie Watkins | FWD | 2 | 22 | . 255 Callum Wilson | FWD | 14 | 22 | . 155 Dominic Calvert-Lewin | FWD | 7 | 22 | . Optimization . !pip install pulp . Requirement already satisfied: pulp in /usr/local/lib/python3.6/dist-packages (2.4) Requirement already satisfied: amply&gt;=0.1.2 in /usr/local/lib/python3.6/dist-packages (from pulp) (0.1.4) Requirement already satisfied: docutils&gt;=0.3 in /usr/local/lib/python3.6/dist-packages (from amply&gt;=0.1.2-&gt;pulp) (0.16) Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from amply&gt;=0.1.2-&gt;pulp) (2.4.7) . # import pulp # def select_team(expected_scores, prices, positions, clubs, total_budget=1000, sub_factor=0.2): # num_players = len(expected_scores) # print(num_players) # model = pulp.LpProblem(&quot;Constrained value maximisation&quot;, pulp.LpMaximize) # decisions = [ # pulp.LpVariable(&quot;x{}&quot;.format(i), lowBound=0, upBound=1, cat=&#39;Integer&#39;) # for i in range(num_players) # ] # captain_decisions = [ # pulp.LpVariable(&quot;y{}&quot;.format(i), lowBound=0, upBound=1, cat=&#39;Integer&#39;) # for i in range(num_players) # ] # sub_decisions = [ # pulp.LpVariable(&quot;z{}&quot;.format(i), lowBound=0, upBound=1, cat=&#39;Integer&#39;) # for i in range(num_players) # ] # # objective function: # model += sum((captain_decisions[i] + decisions[i] + sub_decisions[i]*sub_factor) * expected_scores[i] # for i in range(num_players)), &quot;Objective&quot; # # cost constraint # model += sum((decisions[i] + sub_decisions[i]) * prices[i] for i in range(num_players)) &lt;= total_budget # total cost # # position constraints # # 1 starting goalkeeper # model += sum(decisions[i] for i in range(num_players) if positions[i] == 1) == 1 # # 2 total goalkeepers # model += sum(decisions[i] + sub_decisions[i] for i in range(num_players) if positions[i] == 1) == 2 # # 3-5 starting defenders # model += sum(decisions[i] for i in range(num_players) if positions[i] == 2) &gt;= 3 # model += sum(decisions[i] for i in range(num_players) if positions[i] == 2) &lt;= 5 # # 5 total defenders # model += sum(decisions[i] + sub_decisions[i] for i in range(num_players) if positions[i] == 2) == 5 # # 3-5 starting midfielders # model += sum(decisions[i] for i in range(num_players) if positions[i] == 3) &gt;= 3 # model += sum(decisions[i] for i in range(num_players) if positions[i] == 3) &lt;= 5 # # 5 total midfielders # model += sum(decisions[i] + sub_decisions[i] for i in range(num_players) if positions[i] == 3) == 5 # # 1-3 starting attackers # model += sum(decisions[i] for i in range(num_players) if positions[i] == 4) &gt;= 1 # model += sum(decisions[i] for i in range(num_players) if positions[i] == 4) &lt;= 3 # # 3 total attackers # model += sum(decisions[i] + sub_decisions[i] for i in range(num_players) if positions[i] == 4) == 3 # # club constraint # for club_id in np.unique(clubs): # model += sum(decisions[i] + sub_decisions[i] for i in range(num_players) if clubs[i] == club_id) &lt;= 3 # max 3 players # model += sum(decisions) == 11 # total team size # model += sum(captain_decisions) == 1 # 1 captain # for i in range(num_players): # model += (decisions[i] - captain_decisions[i]) &gt;= 0 # captain must also be on team # model += (decisions[i] + sub_decisions[i]) &lt;= 1 # subs must not be on team # model.solve() # print(&quot;Total expected score = {}&quot;.format(model.objective.value())) # return decisions, captain_decisions, sub_decisions . cost_df=players_df[[&#39;now_cost&#39;,&#39;first_name&#39;,&#39;second_name&#39;]].copy() cost_df[&#39;web_name&#39;]=cost_df[&#39;first_name&#39;]+&#39; &#39;+cost_df[&#39;second_name&#39;] #cost_df pred_data_roll_cum_team_pts_spi_cost=pd.merge(left=pred_data_roll_cum_team_pts_spi,right=cost_df,left_on=[&#39;player_name&#39;],right_on=[&#39;web_name&#39;],how=&#39;inner&#39;) pred_data_roll_cum_team_pts_spi_cost # expected_scores=pred_data_roll_cum_team_pts_spi_cost[&#39;predicted&#39;] # prices=pred_data_roll_cum_team_pts_spi_cost[&#39;now_cost&#39;] # positions=pred_data_roll_cum_team_pts_spi_cost[&#39;position&#39;] # clubs=pred_data_roll_cum_team_pts_spi_cost[&#39;team_id&#39;] # decision,captain_decision,sub_decisions=select_team(expected_scores.values, prices.values, positions.values, clubs.values, total_budget=100,sub_factor=0.2) # #expected_scores.values . player_name position team team_id home_team away_team gw was_home opponent_id influence_roll creativity_roll threat_roll ict_index_roll minutes_roll selected_roll total_points_roll red_cards yellow_cards xP total_points bonus clean_sheets assists minutes influence creativity threat ict_index team_pts id_x team_rank xG_diff_team deep_diff_team scored_diff_team opponent_points id_y opponent_rank xG_diff_opponent deep_diff_opponent scored_diff_opponent round team_total_points_cumsum percent_team_points team1 team2 home_id away_id proj_score1 proj_score2 rank_diff proj_score_diff position_flag predicted now_cost first_name second_name web_name . 0 Aaron Connolly | FWD | Brighton | 3 | 11.0 | 3.0 | 22 | 0 | 11.0 | 4.704762 | 2.890476 | 11.190476 | 1.871429 | 27.952381 | 35626.095238 | 1.476190 | 0 | 0 | 26.8 | 31 | 2 | 1 | 1 | 587 | 98.8 | 60.7 | 235.0 | 39.3 | 21 | 3 | 13.0 | 0.305884 | 0.611722 | 0.442308 | 40 | 11 | 3.0 | 0.805659 | 0.804217 | 0.641791 | 21 | 800 | 0.038750 | Liverpool | Brighton and Hove Albion | 11 | 3 | 2.09 | 0.77 | 10.0 | 1.32 | 1 | 0.134720 | 52 | Aaron | Connolly | Aaron Connolly | . 1 Adam Lallana | MID | Brighton | 3 | 11.0 | 3.0 | 22 | 0 | 11.0 | 4.800000 | 9.390476 | 5.571429 | 1.957143 | 36.904762 | 32346.238095 | 1.333333 | 0 | 0 | 20.3 | 28 | 0 | 3 | 1 | 775 | 100.8 | 197.2 | 117.0 | 41.1 | 21 | 3 | 13.0 | 0.305884 | 0.611722 | 0.442308 | 40 | 11 | 3.0 | 0.805659 | 0.804217 | 0.641791 | 21 | 800 | 0.035000 | Liverpool | Brighton and Hove Albion | 11 | 3 | 2.09 | 0.77 | 10.0 | 1.32 | 3 | 0.169970 | 62 | Adam | Lallana | Adam Lallana | . 2 Adam Webster | DEF | Brighton | 3 | 11.0 | 3.0 | 22 | 0 | 11.0 | 14.809524 | 3.742857 | 9.619048 | 2.814286 | 85.714286 | 138536.428571 | 2.523810 | 0 | 3 | 41.5 | 53 | 0 | 6 | 0 | 1800 | 311.0 | 78.6 | 202.0 | 59.1 | 21 | 3 | 13.0 | 0.305884 | 0.611722 | 0.442308 | 40 | 11 | 3.0 | 0.805659 | 0.804217 | 0.641791 | 21 | 800 | 0.066250 | Liverpool | Brighton and Hove Albion | 11 | 3 | 2.09 | 0.77 | 10.0 | 1.32 | 0 | 0.248905 | 44 | Adam | Webster | Adam Webster | . 3 Alexis Mac Allister | MID | Brighton | 3 | 11.0 | 3.0 | 22 | 0 | 11.0 | 4.961905 | 4.876190 | 4.333333 | 1.409524 | 21.428571 | 3277.619048 | 1.285714 | 0 | 1 | 20.1 | 27 | 3 | 3 | 1 | 450 | 104.2 | 102.4 | 91.0 | 29.6 | 21 | 3 | 13.0 | 0.305884 | 0.611722 | 0.442308 | 40 | 11 | 3.0 | 0.805659 | 0.804217 | 0.641791 | 21 | 800 | 0.033750 | Liverpool | Brighton and Hove Albion | 11 | 3 | 2.09 | 0.77 | 10.0 | 1.32 | 3 | 0.132521 | 53 | Alexis | Mac Allister | Alexis Mac Allister | . 4 Alireza Jahanbakhsh | MID | Brighton | 3 | 11.0 | 3.0 | 22 | 0 | 11.0 | 2.447619 | 4.500000 | 6.809524 | 1.371429 | 11.857143 | 2905.714286 | 0.619048 | 0 | 2 | 8.2 | 13 | 0 | 0 | 1 | 249 | 51.4 | 94.5 | 143.0 | 28.8 | 21 | 3 | 13.0 | 0.305884 | 0.611722 | 0.442308 | 40 | 11 | 3.0 | 0.805659 | 0.804217 | 0.641791 | 21 | 800 | 0.016250 | Liverpool | Brighton and Hove Albion | 11 | 3 | 2.09 | 0.77 | 10.0 | 1.32 | 3 | 0.100761 | 54 | Alireza | Jahanbakhsh | Alireza Jahanbakhsh | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 481 Riyad Mahrez | MID | Man City | 12 | 4.0 | 12.0 | 22 | 0 | 4.0 | 15.350000 | 21.205000 | 22.650000 | 5.915000 | 47.100000 | 357545.800000 | 3.500000 | 0 | 0 | 101.7 | 70 | 7 | 7 | 2 | 942 | 307.0 | 424.1 | 453.0 | 118.3 | 44 | 12 | 1.0 | 1.294208 | 0.750865 | 0.740000 | 22 | 4 | 12.0 | -0.713549 | 0.336770 | 0.333333 | 21 | 1134 | 0.061728 | Burnley | Manchester City | 4 | 12 | 0.49 | 2.25 | -11.0 | -1.76 | 3 | 0.688607 | 81 | Riyad | Mahrez | Riyad Mahrez | . 482 Rodrigo Hernandez | MID | Man City | 12 | 4.0 | 12.0 | 22 | 0 | 4.0 | 15.350000 | 14.055000 | 9.300000 | 3.875000 | 77.100000 | 35708.750000 | 2.300000 | 0 | 3 | 71.5 | 46 | 3 | 8 | 1 | 1542 | 307.0 | 281.1 | 186.0 | 77.5 | 44 | 12 | 1.0 | 1.294208 | 0.750865 | 0.740000 | 22 | 4 | 12.0 | -0.713549 | 0.336770 | 0.333333 | 21 | 1134 | 0.040564 | Burnley | Manchester City | 4 | 12 | 0.49 | 2.25 | -11.0 | -1.76 | 3 | 0.615653 | 53 | Rodrigo | Hernandez | Rodrigo Hernandez | . 483 Rúben Santos Gato Alves Dias | DEF | Man City | 12 | 4.0 | 12.0 | 22 | 0 | 4.0 | 20.033333 | 1.788889 | 9.111111 | 3.100000 | 88.833333 | 451309.166667 | 5.055556 | 0 | 2 | 118.4 | 91 | 9 | 12 | 1 | 1599 | 360.6 | 32.2 | 164.0 | 55.8 | 44 | 12 | 1.0 | 1.294208 | 0.750865 | 0.740000 | 22 | 4 | 12.0 | -0.713549 | 0.336770 | 0.333333 | 21 | 1134 | 0.080247 | Burnley | Manchester City | 4 | 12 | 0.49 | 2.25 | -11.0 | -1.76 | 0 | 0.536733 | 60 | Rúben Santos | Gato Alves Dias | Rúben Santos Gato Alves Dias | . 484 Sergio Agüero | FWD | Man City | 12 | 4.0 | 12.0 | 22 | 0 | 4.0 | 0.360000 | 1.845000 | 3.250000 | 0.520000 | 7.000000 | 113363.150000 | 0.300000 | 0 | 0 | 9.6 | 6 | 0 | 1 | 0 | 140 | 7.2 | 36.9 | 65.0 | 10.4 | 44 | 12 | 1.0 | 1.294208 | 0.750865 | 0.740000 | 22 | 4 | 12.0 | -0.713549 | 0.336770 | 0.333333 | 21 | 1134 | 0.005291 | Burnley | Manchester City | 4 | 12 | 0.49 | 2.25 | -11.0 | -1.76 | 1 | 0.055155 | 103 | Sergio | Agüero | Sergio Agüero | . 485 Zack Steffen | GK | Man City | 12 | 4.0 | 12.0 | 22 | 0 | 4.0 | 0.480000 | 0.000000 | 0.000000 | 0.050000 | 4.500000 | 5586.100000 | 0.100000 | 0 | 0 | 27.1 | 2 | 0 | 0 | 0 | 90 | 9.6 | 0.0 | 0.0 | 1.0 | 44 | 12 | 1.0 | 1.294208 | 0.750865 | 0.740000 | 22 | 4 | 12.0 | -0.713549 | 0.336770 | 0.333333 | 21 | 1134 | 0.001764 | Burnley | Manchester City | 4 | 12 | 0.49 | 2.25 | -11.0 | -1.76 | 2 | 0.028291 | 44 | Zack | Steffen | Zack Steffen | . 486 rows × 57 columns . . #output=pd.concat(team_list) output[&#39;web_name&#39;] = output[&#39;player_name&#39;].str.split(&#39; &#39;).str[1] player_photo=players_df[[&#39;first_name&#39;,&#39;second_name&#39;,&#39;photo&#39;,&#39;code&#39;,&#39;team&#39;]].copy() player_photo[&#39;web_name&#39;]=player_photo[&#39;first_name&#39;]+&#39; &#39;+player_photo[&#39;second_name&#39;] player_photo output_join=pd.merge(left=output,right=player_photo,left_on=[&#39;player_name&#39;,&#39;team_id&#39;],right_on=[&#39;web_name&#39;,&#39;team&#39;],how=&#39;left&#39;) output_join=output_join[[&#39;player_name&#39;,&#39;position&#39;,&#39;photo&#39;,&#39;gw&#39;]] output_join[&#39;new_photo&#39;]=output_join[&#39;photo&#39;].str.split(&#39;.&#39;).str[0] del output_join[&#39;photo&#39;] #files.download(&#39;output.csv&#39;) #output_join custom_dict = {&#39;GK&#39;: 0, &#39;DEF&#39;: 1, &#39;MID&#39;: 2, &#39;FWD&#39;: 3} output_join.sort_values(by=[&#39;position&#39;], key=lambda x: x.map(custom_dict),inplace=True) output_join.to_csv(&#39;output.csv&#39;,index=False) . output_file=pd.read_csv(&#39;https://raw.githubusercontent.com/arpitsolanki/FPLBot/main/output.csv&#39;) # output_file final_output=output_join.append(output_file, ignore_index=True) final_output.to_csv(&#39;output.csv&#39;,index=False) files.download(&#39;output.csv&#39;) . last_gw_team=output_file.loc[output_file.gw==GW-1] #last_gw_team=output_file.loc[output_file.gw==17] last_gw_team weekly_data_last=weekly_data_team[[&#39;player_name&#39;,&#39;total_points&#39;,&#39;team_id&#39;,&#39;gw&#39;,&#39;position&#39;]] weekly_data_last=weekly_data_last.loc[weekly_data_last.gw==GW-1] #weekly_data_last=weekly_data_last.loc[weekly_data_last.gw==17] last_gw_team_pts=pd.merge(left=last_gw_team,right=weekly_data_last,left_on=[&#39;player_name&#39;,&#39;gw&#39;,&#39;position&#39;],right_on=[&#39;player_name&#39;,&#39;gw&#39;,&#39;position&#39;],how=&#39;inner&#39;) last_gw_team_pts last_gw_team_pts_old=pd.read_csv(&#39;https://raw.githubusercontent.com/arpitsolanki/FPLBot/main/gw_points_history.csv&#39;) # output_file last_gw_team_pts=last_gw_team_pts_old.append(last_gw_team_pts, ignore_index=True) del last_gw_team_pts[&#39;team_id&#39;] last_gw_team_pts.to_csv(&#39;gw_points_history.csv&#39;,index=False) files.download(&#39;gw_points_history.csv&#39;) #Dream Team past GW weekly_data_last.sort_values(by=[&#39;total_points&#39;],ascending=False,inplace=True) weekly_data_last.head(10) dream_team_list=[] gk=weekly_data_last.loc[weekly_data_last[&#39;position&#39;]==&#39;GK&#39;,[&#39;player_name&#39;,&#39;position&#39;,&#39;team_id&#39;,&#39;total_points&#39;]].head(1) dream_team_list.append(gk) defender=weekly_data_last.loc[weekly_data_last[&#39;position&#39;]==&#39;DEF&#39;,[&#39;player_name&#39;,&#39;position&#39;,&#39;team_id&#39;,&#39;total_points&#39;]].head(3) dream_team_list.append(defender) midfielder=weekly_data_last.loc[weekly_data_last[&#39;position&#39;]==&#39;MID&#39;,[&#39;player_name&#39;,&#39;position&#39;,&#39;team_id&#39;,&#39;total_points&#39;]].head(4) dream_team_list.append(midfielder) forward=weekly_data_last.loc[weekly_data_last[&#39;position&#39;]==&#39;FWD&#39;,[&#39;player_name&#39;,&#39;position&#39;,&#39;team_id&#39;,&#39;total_points&#39;]].head(3) dream_team_list.append(forward) last_gw_dream_team=pd.concat(dream_team_list) last_gw_dream_team.to_csv(&#39;last_gw_dream_team.csv&#39;,index=False) last_gw_dream_team=pd.merge(left=last_gw_dream_team,right=player_photo,left_on=[&#39;player_name&#39;,&#39;team_id&#39;],right_on=[&#39;web_name&#39;,&#39;team&#39;],how=&#39;left&#39;) last_gw_dream_team[&#39;new_photo&#39;]=last_gw_dream_team[&#39;code&#39;] last_gw_dream_team=last_gw_dream_team[[&#39;player_name&#39;,&#39;position&#39;,&#39;new_photo&#39;,&#39;total_points&#39;]] last_gw_dream_team files.download(&#39;last_gw_dream_team.csv&#39;) . avg_score_df=events_df.loc[events_df.id&lt;=GW] avg_score_df=avg_score_df[[&#39;id&#39;,&#39;average_entry_score&#39;]] avg_score_df.to_csv(&#39;avg_score_df.csv&#39;,index=False) files.download(&#39;avg_score_df.csv&#39;) . # img=output_join.iloc[0,2] # img_path=&#39;https://resources.premierleague.com/premierleague/photos/players/110x140/p&#39;+img+&#39;.png&#39; # print(img_path) # from skimage import io # io.imshow(io.imread(img_path)) # #io.show() #import plotly import skimage #skimage.io.show() #from skimage import io print(seaborn.__version__) . 0.11.1 .",
            "url": "https://arpitsolanki.github.io/fastpagetest/2020/02/01/Fantasy-League.html",
            "relUrl": "/2020/02/01/Fantasy-League.html",
            "date": " • Feb 1, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://arpitsolanki.github.io/fastpagetest/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://arpitsolanki.github.io/fastpagetest/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://arpitsolanki.github.io/fastpagetest/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}